{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e75f208",
   "metadata": {},
   "source": [
    "تفعيل البيئة الافتراضية \n",
    "\n",
    "yoloenv\\Scripts\\activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07de5640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from opencv-python) (2.2.1)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02890d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install playsound\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a1812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# افتح الكاميرا (0 تعني الكاميرا الأساسية)\n",
    "cap = cv2.VideoCapture(\"VID-20250422-WA0005.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # قراءة فريم من الكاميرا\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Video Playback\", frame)\n",
    "\n",
    "    # اضغط على \"q\" للإغلاق\n",
    "    if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdd2443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.114-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numpy<=2.1.1,>=1.23.0 (from ultralytics)\n",
      "  Using cached numpy-2.1.1-cp313-cp313-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (1.15.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (6.1.1)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch>=1.8.0->ultralytics)\n",
      "  Using cached setuptools-79.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.8.0->ultralytics)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached ultralytics-8.3.114-py3-none-any.whl (983 kB)\n",
      "Using cached numpy-2.1.1-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-79.0.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: py-cpuinfo, mpmath, urllib3, tqdm, sympy, setuptools, pyyaml, numpy, networkx, MarkupSafe, idna, fsspec, charset-normalizer, certifi, requests, jinja2, torch, ultralytics-thop, torchvision, seaborn, ultralytics\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.1\n",
      "    Uninstalling numpy-2.2.1:\n",
      "      Successfully uninstalled numpy-2.2.1\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 fsspec-2025.3.2 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.1 py-cpuinfo-9.0.0 pyyaml-6.0.2 requests-2.32.3 seaborn-0.13.2 setuptools-79.0.0 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 ultralytics-8.3.114 ultralytics-thop-2.0.14 urllib3-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b03b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:32<00:00, 200kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 77.9ms\n",
      "Speed: 4.6ms preprocess, 77.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 59.3ms\n",
      "Speed: 1.4ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.1ms\n",
      "Speed: 3.1ms preprocess, 46.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.8ms\n",
      "Speed: 1.0ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.3ms\n",
      "Speed: 1.3ms preprocess, 49.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.1ms\n",
      "Speed: 1.3ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.7ms\n",
      "Speed: 1.1ms preprocess, 46.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.2ms\n",
      "Speed: 1.3ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.1ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.1ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.1ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.3ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 40.3ms\n",
      "Speed: 1.5ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.4ms\n",
      "Speed: 1.4ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 43.3ms\n",
      "Speed: 1.3ms preprocess, 43.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.4ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.5ms\n",
      "Speed: 1.2ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.1ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.8ms\n",
      "Speed: 0.9ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.2ms\n",
      "Speed: 1.3ms preprocess, 39.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.9ms\n",
      "Speed: 1.3ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 0.9ms preprocess, 38.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.3ms preprocess, 41.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 1.3ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.5ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.3ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.7ms\n",
      "Speed: 1.3ms preprocess, 42.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.3ms preprocess, 41.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.4ms\n",
      "Speed: 1.4ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.8ms\n",
      "Speed: 1.6ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.6ms\n",
      "Speed: 1.4ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 44.1ms\n",
      "Speed: 1.4ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.6ms\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.1ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 36.5ms\n",
      "Speed: 1.4ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.3ms\n",
      "Speed: 1.3ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.5ms\n",
      "Speed: 1.3ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.1ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.3ms\n",
      "Speed: 0.9ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.5ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.2ms\n",
      "Speed: 1.4ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.2ms preprocess, 38.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.8ms\n",
      "Speed: 0.9ms preprocess, 35.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.6ms\n",
      "Speed: 1.4ms preprocess, 38.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.6ms\n",
      "Speed: 1.3ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.7ms\n",
      "Speed: 1.2ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.8ms\n",
      "Speed: 0.9ms preprocess, 39.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.6ms\n",
      "Speed: 0.9ms preprocess, 37.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.5ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.2ms\n",
      "Speed: 1.3ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 61.6ms\n",
      "Speed: 1.7ms preprocess, 61.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.7ms\n",
      "Speed: 1.3ms preprocess, 35.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.3ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 36.9ms\n",
      "Speed: 0.9ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 0.9ms preprocess, 38.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 0.9ms preprocess, 38.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.4ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 suitcase, 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.6ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.1ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.2ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.1ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.6ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.1ms\n",
      "Speed: 1.2ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.3ms preprocess, 41.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.3ms\n",
      "Speed: 1.3ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.8ms\n",
      "Speed: 1.2ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 45.2ms\n",
      "Speed: 1.4ms preprocess, 45.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.1ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.3ms\n",
      "Speed: 1.2ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 38.3ms\n",
      "Speed: 1.4ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 1.3ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.2ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.1ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 30.9ms\n",
      "Speed: 1.3ms preprocess, 30.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.4ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.2ms preprocess, 39.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 40.6ms\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.2ms\n",
      "Speed: 1.3ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.0ms\n",
      "Speed: 0.9ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.1ms\n",
      "Speed: 0.9ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.3ms\n",
      "Speed: 1.3ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 36.7ms\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 42.1ms\n",
      "Speed: 1.3ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.6ms\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.3ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.4ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.0ms\n",
      "Speed: 0.9ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 0.9ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.2ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.8ms\n",
      "Speed: 1.3ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.2ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 0.9ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.0ms preprocess, 39.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.2ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 41.4ms\n",
      "Speed: 1.5ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 38.3ms\n",
      "Speed: 1.5ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.4ms\n",
      "Speed: 1.4ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.1ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 38.0ms\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.3ms\n",
      "Speed: 0.9ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.6ms\n",
      "Speed: 1.1ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.4ms\n",
      "Speed: 0.9ms preprocess, 51.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 38.1ms\n",
      "Speed: 1.3ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.3ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.5ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 41.3ms\n",
      "Speed: 0.9ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 0.9ms preprocess, 39.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.0ms\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.3ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 36.9ms\n",
      "Speed: 1.2ms preprocess, 36.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.1ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.3ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.1ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.4ms preprocess, 39.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.4ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.0ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 baseball glove, 43.5ms\n",
      "Speed: 1.3ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.8ms\n",
      "Speed: 2.5ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.2ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.5ms\n",
      "Speed: 0.9ms preprocess, 39.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.0ms\n",
      "Speed: 1.3ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.5ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 62.0ms\n",
      "Speed: 1.8ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.6ms\n",
      "Speed: 1.5ms preprocess, 39.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.7ms\n",
      "Speed: 1.3ms preprocess, 44.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.4ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.5ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.2ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.3ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.4ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 0.9ms preprocess, 39.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 36.9ms\n",
      "Speed: 0.9ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.1ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 banana, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 banana, 47.4ms\n",
      "Speed: 1.7ms preprocess, 47.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.8ms\n",
      "Speed: 1.2ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 50.4ms\n",
      "Speed: 1.9ms preprocess, 50.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.4ms\n",
      "Speed: 1.6ms preprocess, 48.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.3ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.1ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.5ms\n",
      "Speed: 1.3ms preprocess, 47.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.9ms\n",
      "Speed: 1.5ms preprocess, 49.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 remote, 40.6ms\n",
      "Speed: 0.9ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 0.9ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.3ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 0.9ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.4ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 0.9ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.4ms\n",
      "Speed: 1.1ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.3ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 0.9ms preprocess, 40.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.2ms\n",
      "Speed: 1.3ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 45.2ms\n",
      "Speed: 1.1ms preprocess, 45.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.8ms\n",
      "Speed: 1.1ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.3ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.4ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.4ms\n",
      "Speed: 1.1ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 0.9ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.1ms\n",
      "Speed: 0.9ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.4ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.3ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 1.1ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 34.1ms\n",
      "Speed: 1.3ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.5ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.1ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.4ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.2ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.0ms\n",
      "Speed: 1.4ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.1ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.6ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.0ms\n",
      "Speed: 1.3ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.4ms preprocess, 36.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 0.9ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 0.9ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 banana, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.4ms\n",
      "Speed: 1.4ms preprocess, 43.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.3ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.5ms\n",
      "Speed: 1.4ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.5ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.4ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.3ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 0.9ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 0.9ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 54.2ms\n",
      "Speed: 1.5ms preprocess, 54.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.5ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.3ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.3ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 cup, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.4ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.1ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 0.9ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.3ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.2ms\n",
      "Speed: 1.0ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 40.2ms\n",
      "Speed: 1.1ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 35.3ms\n",
      "Speed: 0.9ms preprocess, 35.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 45.6ms\n",
      "Speed: 0.9ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 49.6ms\n",
      "Speed: 1.6ms preprocess, 49.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 49.8ms\n",
      "Speed: 1.3ms preprocess, 49.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 46.6ms\n",
      "Speed: 1.2ms preprocess, 46.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.6ms\n",
      "Speed: 1.5ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.3ms\n",
      "Speed: 1.7ms preprocess, 46.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 45.8ms\n",
      "Speed: 1.4ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 43.9ms\n",
      "Speed: 1.2ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 45.5ms\n",
      "Speed: 1.4ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 49.4ms\n",
      "Speed: 1.3ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 46.6ms\n",
      "Speed: 1.1ms preprocess, 46.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 44.6ms\n",
      "Speed: 1.1ms preprocess, 44.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 59.1ms\n",
      "Speed: 1.2ms preprocess, 59.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 44.1ms\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.0ms\n",
      "Speed: 1.6ms preprocess, 51.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.7ms\n",
      "Speed: 1.4ms preprocess, 49.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.1ms\n",
      "Speed: 1.4ms preprocess, 48.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.2ms\n",
      "Speed: 1.2ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.9ms\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.6ms\n",
      "Speed: 1.1ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.0ms\n",
      "Speed: 1.3ms preprocess, 45.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.4ms\n",
      "Speed: 1.4ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.0ms\n",
      "Speed: 1.2ms preprocess, 43.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.1ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 toothbrush, 42.9ms\n",
      "Speed: 1.3ms preprocess, 42.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 41.5ms\n",
      "Speed: 1.1ms preprocess, 41.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 0.9ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.3ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 0.9ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 45.2ms\n",
      "Speed: 1.3ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.6ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 0.9ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.4ms\n",
      "Speed: 1.3ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.2ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.3ms\n",
      "Speed: 1.2ms preprocess, 48.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.5ms\n",
      "Speed: 1.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.5ms\n",
      "Speed: 1.4ms preprocess, 46.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 0.9ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.4ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 0.9ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.9ms\n",
      "Speed: 1.4ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.1ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.2ms\n",
      "Speed: 1.4ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.3ms preprocess, 38.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 58.5ms\n",
      "Speed: 1.3ms preprocess, 58.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.5ms\n",
      "Speed: 1.8ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 0.9ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.6ms\n",
      "Speed: 1.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.9ms\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 34.2ms\n",
      "Speed: 1.4ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.3ms\n",
      "Speed: 1.0ms preprocess, 36.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 0.9ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.4ms\n",
      "Speed: 1.2ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.4ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 0.9ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.5ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.1ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 41.4ms\n",
      "Speed: 1.1ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.3ms preprocess, 41.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.5ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 41.3ms\n",
      "Speed: 1.2ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.3ms preprocess, 39.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.1ms preprocess, 40.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 45.8ms\n",
      "Speed: 1.3ms preprocess, 45.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.5ms\n",
      "Speed: 1.2ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 chair, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.5ms\n",
      "Speed: 0.9ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 69.8ms\n",
      "Speed: 2.7ms preprocess, 69.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 43.8ms\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 42.8ms\n",
      "Speed: 1.1ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.6ms\n",
      "Speed: 1.5ms preprocess, 49.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.3ms\n",
      "Speed: 1.1ms preprocess, 49.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 43.9ms\n",
      "Speed: 1.2ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 47.4ms\n",
      "Speed: 1.4ms preprocess, 47.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.3ms\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.1ms\n",
      "Speed: 1.2ms preprocess, 51.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 57.3ms\n",
      "Speed: 2.0ms preprocess, 57.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 55.6ms\n",
      "Speed: 1.3ms preprocess, 55.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 57.9ms\n",
      "Speed: 1.6ms preprocess, 57.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 54.3ms\n",
      "Speed: 1.4ms preprocess, 54.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.4ms\n",
      "Speed: 1.5ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.2ms\n",
      "Speed: 1.6ms preprocess, 47.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 42.4ms\n",
      "Speed: 1.4ms preprocess, 42.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 40.5ms\n",
      "Speed: 1.6ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 0.9ms preprocess, 39.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.0ms\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.4ms\n",
      "Speed: 1.1ms preprocess, 45.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.1ms\n",
      "Speed: 1.6ms preprocess, 46.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.2ms\n",
      "Speed: 1.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.9ms\n",
      "Speed: 1.5ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.2ms\n",
      "Speed: 1.5ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bed, 41.9ms\n",
      "Speed: 1.4ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.8ms\n",
      "Speed: 1.1ms preprocess, 39.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 41.3ms\n",
      "Speed: 1.5ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.3ms preprocess, 41.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 42.7ms\n",
      "Speed: 1.1ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bed, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.7ms\n",
      "Speed: 1.1ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 45.5ms\n",
      "Speed: 1.4ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.3ms\n",
      "Speed: 1.4ms preprocess, 43.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.4ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.4ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.8ms\n",
      "Speed: 1.0ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.9ms\n",
      "Speed: 1.5ms preprocess, 42.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.8ms\n",
      "Speed: 1.1ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.6ms\n",
      "Speed: 1.4ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.3ms\n",
      "Speed: 1.1ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.2ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.2ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.4ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.3ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.1ms preprocess, 40.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.4ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.4ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.3ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.6ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.2ms\n",
      "Speed: 1.4ms preprocess, 37.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.2ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.3ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.4ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.2ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.1ms preprocess, 39.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.2ms\n",
      "Speed: 0.9ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.3ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.5ms preprocess, 38.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 38.3ms\n",
      "Speed: 1.4ms preprocess, 38.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.8ms\n",
      "Speed: 1.2ms preprocess, 36.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.3ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 0.9ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.4ms\n",
      "Speed: 1.0ms preprocess, 36.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.0ms\n",
      "Speed: 1.1ms preprocess, 36.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 46.9ms\n",
      "Speed: 1.3ms preprocess, 46.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.3ms preprocess, 42.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.5ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 56.6ms\n",
      "Speed: 1.0ms preprocess, 56.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 43.2ms\n",
      "Speed: 1.3ms preprocess, 43.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 toothbrush, 42.6ms\n",
      "Speed: 1.5ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.6ms\n",
      "Speed: 1.3ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.6ms\n",
      "Speed: 1.2ms preprocess, 47.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.1ms\n",
      "Speed: 1.4ms preprocess, 47.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 1.4ms preprocess, 38.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.4ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.2ms\n",
      "Speed: 1.2ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.5ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 0.9ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.3ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 0.9ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.4ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.2ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.4ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.4ms preprocess, 41.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.3ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.5ms\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 0.9ms preprocess, 38.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.2ms\n",
      "Speed: 1.6ms preprocess, 43.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.2ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.4ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 37.6ms\n",
      "Speed: 1.1ms preprocess, 37.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 0.9ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.4ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.0ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.3ms\n",
      "Speed: 2.1ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.1ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.6ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.3ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.6ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.4ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.4ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.9ms\n",
      "Speed: 1.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.5ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.3ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bed, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.3ms preprocess, 39.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.5ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.3ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.4ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.4ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.5ms\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.1ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 toothbrushs, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 0.9ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 0.9ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 47.5ms\n",
      "Speed: 1.3ms preprocess, 47.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.2ms\n",
      "Speed: 1.5ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 54.4ms\n",
      "Speed: 1.0ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.4ms preprocess, 39.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 1.3ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.4ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.1ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.6ms\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 0.9ms preprocess, 39.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.5ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 49.4ms\n",
      "Speed: 1.1ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 0.9ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.3ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.1ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 0.9ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 59.4ms\n",
      "Speed: 1.6ms preprocess, 59.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.4ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 0.9ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.3ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 0.9ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 33.5ms\n",
      "Speed: 1.3ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 0.9ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 0.9ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.4ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.2ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 0.9ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.4ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.5ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.3ms\n",
      "Speed: 1.5ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.8ms\n",
      "Speed: 1.0ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.2ms\n",
      "Speed: 1.3ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 54.8ms\n",
      "Speed: 1.8ms preprocess, 54.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.9ms\n",
      "Speed: 0.9ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 1.1ms preprocess, 37.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.2ms\n",
      "Speed: 1.6ms preprocess, 44.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 0.9ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 0.9ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.1ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.1ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 0.9ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 0.9ms preprocess, 38.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.7ms\n",
      "Speed: 1.5ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.1ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 54.0ms\n",
      "Speed: 0.9ms preprocess, 54.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.6ms\n",
      "Speed: 1.5ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.6ms\n",
      "Speed: 1.3ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.4ms\n",
      "Speed: 1.3ms preprocess, 42.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.2ms\n",
      "Speed: 1.4ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 46.8ms\n",
      "Speed: 1.1ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 48.4ms\n",
      "Speed: 1.1ms preprocess, 48.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.1ms\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 1.6ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.5ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 0.9ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.5ms\n",
      "Speed: 0.9ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.1ms\n",
      "Speed: 0.9ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.2ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.3ms\n",
      "Speed: 1.1ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.3ms\n",
      "Speed: 1.4ms preprocess, 44.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.1ms\n",
      "Speed: 1.3ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 vase, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 53.8ms\n",
      "Speed: 1.0ms preprocess, 53.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.9ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 35.8ms\n",
      "Speed: 1.3ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 1.0ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.0ms\n",
      "Speed: 1.4ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 handbag, 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.8ms\n",
      "Speed: 0.9ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 0.9ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 cup, 38.6ms\n",
      "Speed: 1.1ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 cup, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.4ms\n",
      "Speed: 1.4ms preprocess, 37.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.1ms preprocess, 41.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.4ms preprocess, 37.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.3ms\n",
      "Speed: 0.9ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.8ms\n",
      "Speed: 1.3ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.1ms\n",
      "Speed: 0.9ms preprocess, 43.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.2ms preprocess, 39.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.3ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.3ms\n",
      "Speed: 0.9ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 61.6ms\n",
      "Speed: 1.3ms preprocess, 61.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.1ms\n",
      "Speed: 1.3ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 1.5ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 44.1ms\n",
      "Speed: 1.4ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.9ms\n",
      "Speed: 1.4ms preprocess, 41.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.1ms\n",
      "Speed: 1.4ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.3ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.5ms preprocess, 39.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 50.0ms\n",
      "Speed: 1.7ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.4ms preprocess, 40.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.0ms\n",
      "Speed: 1.3ms preprocess, 45.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.0ms\n",
      "Speed: 1.1ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 51.7ms\n",
      "Speed: 1.3ms preprocess, 51.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 2.4ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.4ms\n",
      "Speed: 1.4ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.3ms\n",
      "Speed: 1.0ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.4ms preprocess, 39.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.3ms\n",
      "Speed: 1.3ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.3ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.6ms\n",
      "Speed: 1.4ms preprocess, 37.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 0.9ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 52.6ms\n",
      "Speed: 1.0ms preprocess, 52.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.5ms\n",
      "Speed: 1.3ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.7ms\n",
      "Speed: 1.3ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.6ms\n",
      "Speed: 0.9ms preprocess, 41.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 37.8ms\n",
      "Speed: 0.9ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.0ms\n",
      "Speed: 1.3ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.3ms\n",
      "Speed: 0.9ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.8ms\n",
      "Speed: 0.9ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.2ms\n",
      "Speed: 1.4ms preprocess, 43.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 43.3ms\n",
      "Speed: 1.1ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.1ms\n",
      "Speed: 1.5ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 42.0ms\n",
      "Speed: 1.6ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.0ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 0.9ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 36.7ms\n",
      "Speed: 1.3ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.8ms\n",
      "Speed: 1.0ms preprocess, 38.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# حملي النموذج الجاهز (YOLOv8 صغير وسريع)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# حملي الفيديو يلي بدك تشتغلي عليه\n",
    "cap = cv2.VideoCapture(\"barhom.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # استخدام YOLO على كل فريم\n",
    "    results = model(frame, imgsz=640, conf=0.4)\n",
    "\n",
    "    # عرض الفريم مع الصناديق (Bounding Boxes)\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow(\"YOLO Detection\", annotated_frame)\n",
    "\n",
    "    # اضغطي \"q\" لإيقاف العرض\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac03784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [31 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "          ~~~~^^\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "        File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-vxvsx2y1\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-vxvsx2y1\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 301, in _get_build_requires\n",
      "          self.run_setup()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "        File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-vxvsx2y1\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "          ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-vxvsx2y1\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "          exec(code, locals())\n",
      "          ~~~~^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 6, in <module>\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\inspect.py\", line 1256, in getsource\n",
      "          lines, lnum = getsourcelines(object)\n",
      "                        ~~~~~~~~~~~~~~^^^^^^^^\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\inspect.py\", line 1238, in getsourcelines\n",
      "          lines, lnum = findsource(object)\n",
      "                        ~~~~~~~~~~^^^^^^^^\n",
      "        File \"C:\\Program Files\\Python313\\Lib\\inspect.py\", line 1078, in findsource\n",
      "          raise OSError('could not get source code')\n",
      "      OSError: could not get source code\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting playsound\n",
      "  Using cached playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91dedaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.6.1-cp313-cp313-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   - -------------------------------------- 0.5/10.6 MB 113.8 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   -- ------------------------------------- 0.8/10.6 MB 111.0 kB/s eta 0:01:29\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   --- ------------------------------------ 1.0/10.6 MB 113.4 kB/s eta 0:01:25\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 112.6 kB/s eta 0:01:23\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 115.1 kB/s eta 0:01:19\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------ --------------------------------- 1.8/10.6 MB 118.4 kB/s eta 0:01:15\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   ------- -------------------------------- 2.1/10.6 MB 115.9 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   -------- ------------------------------- 2.4/10.6 MB 112.1 kB/s eta 0:01:14\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   --------- ------------------------------ 2.6/10.6 MB 103.7 kB/s eta 0:01:18\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 93.0 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 93.0 kB/s eta 0:01:21\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------ --------------------------- 3.4/10.6 MB 93.4 kB/s eta 0:01:18\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 3.7/10.6 MB 93.5 kB/s eta 0:01:15\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   -------------- ------------------------- 3.9/10.6 MB 92.9 kB/s eta 0:01:12\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   --------------- ------------------------ 4.2/10.6 MB 91.8 kB/s eta 0:01:10\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 91.4 kB/s eta 0:01:08\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 93.8 kB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 93.8 kB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 93.8 kB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 93.8 kB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 93.8 kB/s eta 0:01:03\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------ --------------------- 5.0/10.6 MB 99.4 kB/s eta 0:00:57\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 5.2/10.6 MB 102.3 kB/s eta 0:00:53\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   -------------------- ------------------- 5.5/10.6 MB 108.0 kB/s eta 0:00:48\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   --------------------- ------------------ 5.8/10.6 MB 109.1 kB/s eta 0:00:45\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 126.2 kB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 127.7 kB/s eta 0:00:34\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 6.6/10.6 MB 126.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   ------------------------- -------------- 6.8/10.6 MB 127.3 kB/s eta 0:00:30\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 7.1/10.6 MB 130.3 kB/s eta 0:00:28\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 7.3/10.6 MB 131.6 kB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 129.0 kB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 124.5 kB/s eta 0:00:23\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 8.1/10.6 MB 114.0 kB/s eta 0:00:22\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   ------------------------------- -------- 8.4/10.6 MB 111.4 kB/s eta 0:00:21\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 8.7/10.6 MB 114.5 kB/s eta 0:00:18\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.9/10.6 MB 118.8 kB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 121.6 kB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 123.8 kB/s eta 0:00:10\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.7/10.6 MB 123.5 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 10.0/10.6 MB 123.5 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 10.2/10.6 MB 126.9 kB/s eta 0:00:04\n",
      "   ---------------------------------------  10.5/10.6 MB 128.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  10.5/10.6 MB 128.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  10.5/10.6 MB 128.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  10.5/10.6 MB 128.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 10.6/10.6 MB 129.2 kB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1059c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 237.9ms\n",
      "Speed: 2.1ms preprocess, 237.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 215.0ms\n",
      "Speed: 2.3ms preprocess, 215.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 1 book, 182.9ms\n",
      "Speed: 1.2ms preprocess, 182.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 166.8ms\n",
      "Speed: 1.1ms preprocess, 166.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 183.7ms\n",
      "Speed: 1.2ms preprocess, 183.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 187.7ms\n",
      "Speed: 0.8ms preprocess, 187.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 175.9ms\n",
      "Speed: 1.0ms preprocess, 175.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 176.2ms\n",
      "Speed: 1.1ms preprocess, 176.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 2 chairs, 181.1ms\n",
      "Speed: 1.2ms preprocess, 181.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 169.9ms\n",
      "Speed: 0.8ms preprocess, 169.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 165.5ms\n",
      "Speed: 0.8ms preprocess, 165.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 198.9ms\n",
      "Speed: 1.2ms preprocess, 198.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 173.7ms\n",
      "Speed: 1.0ms preprocess, 173.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 171.7ms\n",
      "Speed: 0.8ms preprocess, 171.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 210.3ms\n",
      "Speed: 1.0ms preprocess, 210.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 171.4ms\n",
      "Speed: 0.9ms preprocess, 171.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 169.7ms\n",
      "Speed: 1.5ms preprocess, 169.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 164.5ms\n",
      "Speed: 1.3ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 167.9ms\n",
      "Speed: 1.2ms preprocess, 167.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 178.1ms\n",
      "Speed: 0.8ms preprocess, 178.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 177.0ms\n",
      "Speed: 1.1ms preprocess, 177.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 157.1ms\n",
      "Speed: 1.0ms preprocess, 157.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 156.1ms\n",
      "Speed: 1.3ms preprocess, 156.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 178.2ms\n",
      "Speed: 0.8ms preprocess, 178.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 177.3ms\n",
      "Speed: 0.9ms preprocess, 177.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 174.8ms\n",
      "Speed: 1.2ms preprocess, 174.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 bed, 172.0ms\n",
      "Speed: 1.0ms preprocess, 172.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: bed\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 161.0ms\n",
      "Speed: 1.1ms preprocess, 161.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 145.4ms\n",
      "Speed: 1.0ms preprocess, 145.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 154.5ms\n",
      "Speed: 1.0ms preprocess, 154.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 167.5ms\n",
      "Speed: 1.1ms preprocess, 167.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 scissors, 151.1ms\n",
      "Speed: 0.9ms preprocess, 151.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: scissors\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 178.2ms\n",
      "Speed: 1.0ms preprocess, 178.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 168.9ms\n",
      "Speed: 1.2ms preprocess, 168.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 166.8ms\n",
      "Speed: 1.0ms preprocess, 166.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 152.8ms\n",
      "Speed: 1.1ms preprocess, 152.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 171.3ms\n",
      "Speed: 1.2ms preprocess, 171.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 155.3ms\n",
      "Speed: 1.0ms preprocess, 155.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 137.6ms\n",
      "Speed: 1.0ms preprocess, 137.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 167.8ms\n",
      "Speed: 1.1ms preprocess, 167.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 149.4ms\n",
      "Speed: 1.0ms preprocess, 149.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 139.0ms\n",
      "Speed: 0.8ms preprocess, 139.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 130.1ms\n",
      "Speed: 0.9ms preprocess, 130.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 166.7ms\n",
      "Speed: 0.8ms preprocess, 166.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 162.0ms\n",
      "Speed: 1.2ms preprocess, 162.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 168.3ms\n",
      "Speed: 1.1ms preprocess, 168.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 178.2ms\n",
      "Speed: 1.1ms preprocess, 178.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 163.1ms\n",
      "Speed: 1.1ms preprocess, 163.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 170.1ms\n",
      "Speed: 0.9ms preprocess, 170.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 152.2ms\n",
      "Speed: 1.0ms preprocess, 152.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 173.4ms\n",
      "Speed: 1.1ms preprocess, 173.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 157.9ms\n",
      "Speed: 1.0ms preprocess, 157.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 banana, 1 chair, 1 book, 168.2ms\n",
      "Speed: 1.2ms preprocess, 168.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: banana\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 166.6ms\n",
      "Speed: 1.0ms preprocess, 166.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 175.2ms\n",
      "Speed: 1.0ms preprocess, 175.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 157.6ms\n",
      "Speed: 1.0ms preprocess, 157.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 171.4ms\n",
      "Speed: 1.2ms preprocess, 171.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 168.7ms\n",
      "Speed: 1.1ms preprocess, 168.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 154.8ms\n",
      "Speed: 1.2ms preprocess, 154.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 152.2ms\n",
      "Speed: 0.9ms preprocess, 152.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 160.6ms\n",
      "Speed: 0.8ms preprocess, 160.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 164.3ms\n",
      "Speed: 1.1ms preprocess, 164.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 131.7ms\n",
      "Speed: 0.9ms preprocess, 131.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 153.1ms\n",
      "Speed: 1.1ms preprocess, 153.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 149.1ms\n",
      "Speed: 0.9ms preprocess, 149.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 161.2ms\n",
      "Speed: 0.8ms preprocess, 161.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 176.3ms\n",
      "Speed: 1.1ms preprocess, 176.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 193.9ms\n",
      "Speed: 1.5ms preprocess, 193.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 173.8ms\n",
      "Speed: 1.5ms preprocess, 173.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 1 book, 178.7ms\n",
      "Speed: 1.0ms preprocess, 178.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "Detected: book\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 169.8ms\n",
      "Speed: 1.3ms preprocess, 169.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 162.9ms\n",
      "Speed: 1.1ms preprocess, 162.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 161.5ms\n",
      "Speed: 1.0ms preprocess, 161.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 163.0ms\n",
      "Speed: 1.1ms preprocess, 163.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n",
      "\n",
      "0: 640x384 1 person, 1 chair, 159.8ms\n",
      "Speed: 1.2ms preprocess, 159.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Detected: person\n",
      "Detected: chair\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import winsound\n",
    "\n",
    "# تحميل النموذج الجديد\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# فتح الفيديو\n",
    "cap = cv2.VideoCapture(\"barhom.mp4\")\n",
    "\n",
    "# الفئات الخطيرة يلي بدنا نراقبها\n",
    "danger_labels = [\"knife\", \"scissors\", \"fire\", \"spoon\", \"fork\"]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # تحليل الفريم\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    detected_labels = []\n",
    "\n",
    "    # رسم الصناديق للكائنات المكتشفة\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        label = model.names[cls_id]\n",
    "        print(f\"Detected: {label}\")\n",
    "\n",
    "        # رسم الصندوق والاسم\n",
    "        xyxy = box.xyxy[0].tolist()\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} ({conf:.2f})\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # التنبيه إذا الكائن خطير\n",
    "        if label.lower() in danger_labels:\n",
    "            if label not in detected_labels:\n",
    "                winsound.Beep(1000, 1000)\n",
    "                detected_labels.append(label)\n",
    "\n",
    "    # عرض الفريم\n",
    "    cv2.imshow(\"Monitoring\", frame)\n",
    "\n",
    "    # الخروج بالضغط على q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.123 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.114  Python-3.13.1 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=C:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml, epochs=30, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/train, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\train\\train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:30<00:00, 186kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 3.80.7 MB/s, size: 41.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\train\\labels.cache... 9438 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9438/9438 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 2.30.9 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\valid\\labels.cache... 899 images, 0 backgrounds, 0 corrupt: 100%|██████████| 899/899 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "model.train(data=\"C:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml\",\n",
    "             epochs=30,\n",
    "             batch=8,\n",
    "             imgsz=640, \n",
    "             save=True, \n",
    "             project='runs/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4c1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.114  Python-3.13.1 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=C:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml, epochs=30, time=None, patience=100, batch=2, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train_lowmem4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train_lowmem4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 3.50.6 MB/s, size: 41.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\train\\labels.cache... 9438 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9438/9438 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 3.21.3 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\valid\\labels.cache... 899 images, 0 backgrounds, 0 corrupt: 100%|██████████| 899/899 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train_lowmem4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train_lowmem4\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      1.09G      1.576      2.037      1.851          4        416:  22%|██▏       | 1056/4719 [03:37<12:34,  4.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# نموذج متوسط الحجم\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# مناسب لـ 8GB RAM + RTX 2050\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_lowmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\model.py:790\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\trainer.py:210\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\trainer.py:384\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m    383\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 384\u001b[0m     loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:119\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:301\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m    300\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\utils\\loss.py:214\u001b[0m, in \u001b[0;36mv8DetectionLoss.__call__\u001b[1;34m(self, preds, batch)\u001b[0m\n\u001b[0;32m    212\u001b[0m dtype \u001b[38;5;241m=\u001b[39m pred_scores\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    213\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m pred_scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 214\u001b[0m imgsz \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# image size (h,w)\u001b[39;00m\n\u001b[0;32m    215\u001b[0m anchor_points, stride_tensor \u001b[38;5;241m=\u001b[39m make_anchors(feats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Targets\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")  # نموذج متوسط الحجم\n",
    "\n",
    "model.train(\n",
    "    data=\"C:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml\",\n",
    "    epochs=30,\n",
    "    imgsz=416,\n",
    "    batch=2,  # مناسب لـ 8GB RAM + RTX 2050\n",
    "    name=\"train_lowmem\",\n",
    "    amp=False,\n",
    "    cache=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea279487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "             ~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\cfg\\__init__.py\", line 909, in entrypoint\n",
      "    check_dict_alignment(full_args_dict, {a: \"\"})\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\cfg\\__init__.py\", line 499, in check_dict_alignment\n",
      "    raise SyntaxError(string + CLI_HELP_MSG) from e\n",
      "SyntaxError: '\u001b[31m\u001b[1mruns/train/train_lowmem3\u001b[0m' is not a valid YOLO argument. \n",
      "\n",
      "    Arguments received: ['yolo', 'detect', 'train', 'resume', 'runs/train/train_lowmem3']. Ultralytics 'yolo' commands use the following syntax:\n",
      "\n",
      "        yolo TASK MODE ARGS\n",
      "\n",
      "        Where   TASK (optional) is one of frozenset({'classify', 'obb', 'segment', 'pose', 'detect'})\n",
      "                MODE (required) is one of frozenset({'predict', 'train', 'export', 'benchmark', 'track', 'val'})\n",
      "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
      "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
      "\n",
      "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
      "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
      "\n",
      "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
      "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
      "\n",
      "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
      "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
      "\n",
      "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
      "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
      "\n",
      "    5. Ultralytics solutions usage\n",
      "        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n",
      "\n",
      "    6. Run special commands:\n",
      "        yolo help\n",
      "        yolo checks\n",
      "        yolo version\n",
      "        yolo settings\n",
      "        yolo copy-cfg\n",
      "        yolo cfg\n",
      "        yolo solutions help\n",
      "\n",
      "    Docs: https://docs.ultralytics.com\n",
      "    Solutions: https://docs.ultralytics.com/solutions/\n",
      "    Community: https://community.ultralytics.com\n",
      "    GitHub: https://github.com/ultralytics/ultralytics\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!yolo detect train resume runs/train/train_lowmem3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c684c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.114  Python-3.13.1 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=runs\\detect\\train_lowmem3\\weights\\last.pt, data=C:/Users/User/baby_monitor_ai/Fall_Detection.v4/data.yaml, epochs=30, time=None, patience=100, batch=2, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train_lowmem3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=runs\\detect\\train_lowmem3\\weights\\last.pt, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train_lowmem3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 4.10.7 MB/s, size: 41.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\train\\labels.cache... 9438 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9438/9438 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 4.10.9 MB/s, size: 56.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\valid\\labels.cache... 899 images, 0 backgrounds, 0 corrupt: 100%|██████████| 899/899 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train_lowmem3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Resuming training runs\\detect\\train_lowmem3\\weights\\last.pt from epoch 21 to 30 total epochs\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train_lowmem3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      1.21G       1.23      1.143      1.591          2        416: 100%|██████████| 4719/4719 [12:21<00:00,  6.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.774      0.777      0.825      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      1.34G      1.181      1.047      1.554          2        416: 100%|██████████| 4719/4719 [12:20<00:00,  6.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:27<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.772      0.789      0.829      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      1.41G      1.143     0.9878      1.527          2        416: 100%|██████████| 4719/4719 [12:18<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.794      0.776      0.842      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      1.41G      1.111     0.9357      1.491          2        416: 100%|██████████| 4719/4719 [12:14<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.782      0.821      0.849       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      1.41G      1.087     0.8828      1.468          2        416: 100%|██████████| 4719/4719 [12:19<00:00,  6.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.794      0.821      0.852      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      1.41G      1.067     0.8559      1.451          2        416: 100%|██████████| 4719/4719 [12:20<00:00,  6.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.791      0.802      0.839      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      1.41G      1.037     0.8055      1.424          2        416: 100%|██████████| 4719/4719 [12:19<00:00,  6.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:28<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.804      0.805      0.848      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      1.41G      1.001     0.7674      1.398          2        416: 100%|██████████| 4719/4719 [12:18<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:27<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.814      0.795      0.857      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      1.41G     0.9825      0.727      1.378          2        416: 100%|██████████| 4719/4719 [12:18<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:27<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.801      0.802      0.859      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      1.41G     0.9602     0.6946      1.358          2        416: 100%|██████████| 4719/4719 [12:16<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:27<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.807      0.818      0.865      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 2.147 hours.\n",
      "Optimizer stripped from runs\\detect\\train_lowmem3\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from runs\\detect\\train_lowmem3\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating runs\\detect\\train_lowmem3\\weights\\best.pt...\n",
      "Ultralytics 8.3.114  Python-3.13.1 torch-2.7.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 225/225 [00:23<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        899        899      0.803       0.82      0.864      0.521\n",
      "Speed: 0.3ms preprocess, 17.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train_lowmem3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002C71037C9B0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.98276,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,\n",
       "            0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,\n",
       "            0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97938,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,\n",
       "            0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,\n",
       "            0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97744,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.97203,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,\n",
       "            0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,     0.96988,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,\n",
       "             0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9682,      0.9654,      0.9654,      0.9654,      0.9654,      0.9654,      0.9654,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,     0.96333,\n",
       "            0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.96226,     0.95988,     0.95988,     0.95988,     0.95988,\n",
       "            0.95988,     0.95732,     0.95732,     0.95732,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95498,\n",
       "            0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,\n",
       "            0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,\n",
       "            0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,\n",
       "            0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95498,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,\n",
       "            0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,\n",
       "            0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,\n",
       "            0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95492,     0.95325,     0.95325,     0.95325,     0.95325,     0.95152,     0.95152,     0.94872,     0.94872,     0.94872,     0.94872,     0.94872,\n",
       "            0.94872,     0.94872,     0.94872,     0.94872,     0.94872,     0.94872,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94563,     0.94423,     0.94423,     0.94423,     0.94423,     0.94297,     0.94297,     0.94297,     0.94297,     0.94297,     0.94297,\n",
       "            0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94227,     0.94096,     0.94096,     0.94096,     0.94096,     0.93956,     0.93956,     0.93956,     0.93956,     0.93636,     0.93636,     0.93571,     0.93571,\n",
       "            0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,      0.9344,      0.9344,      0.9344,     0.93146,     0.93146,     0.93146,     0.93068,     0.93068,     0.93068,     0.93068,     0.93068,     0.93068,     0.93068,     0.93068,     0.92919,\n",
       "            0.92771,     0.92542,     0.92542,     0.92542,     0.92542,     0.92542,     0.92542,     0.92542,     0.92542,     0.92399,     0.92321,     0.92321,     0.92321,     0.92321,     0.92321,     0.92321,     0.92321,     0.92027,     0.91887,     0.91776,     0.91776,     0.91776,     0.91776,\n",
       "            0.91653,     0.91653,     0.91396,     0.91396,     0.91396,     0.91276,     0.91276,     0.91158,     0.91158,     0.91158,     0.91111,     0.91111,     0.91111,     0.91111,     0.91111,     0.91111,     0.91111,     0.90981,     0.90752,     0.90752,     0.90752,     0.90752,     0.90752,\n",
       "            0.90683,     0.90683,     0.90683,     0.90683,     0.90683,     0.90615,     0.90615,     0.90615,     0.90615,     0.90615,     0.90615,     0.90274,     0.90274,     0.90274,     0.90274,     0.90274,     0.90274,     0.90226,     0.90226,     0.90226,     0.90226,     0.90226,     0.90226,\n",
       "                0.9,         0.9,         0.9,         0.9,     0.89881,     0.89691,     0.89691,     0.89691,     0.89691,     0.89691,     0.89535,     0.89535,     0.89535,     0.89535,     0.89535,     0.89535,     0.89535,     0.89535,      0.8942,     0.89177,     0.89109,     0.89109,     0.89109,\n",
       "            0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,     0.89109,      0.8903,      0.8903,      0.8903,      0.8892,     0.88719,     0.88719,     0.88719,     0.88643,     0.88643,     0.88643,     0.88643,     0.88446,\n",
       "            0.88446,     0.88446,     0.88356,     0.88356,     0.88315,     0.88315,     0.88315,     0.88315,     0.88315,     0.88315,     0.87989,     0.87989,     0.87936,     0.87936,     0.87936,     0.87936,     0.87834,     0.87834,     0.87533,     0.87533,     0.87533,     0.87335,     0.87335,\n",
       "            0.87254,     0.87254,     0.86945,     0.86945,     0.86945,     0.86866,     0.86866,     0.86856,     0.86856,     0.86856,     0.86856,     0.86856,     0.86856,     0.86607,     0.86607,     0.86607,     0.86607,     0.86607,     0.86607,     0.86565,     0.86565,     0.86565,     0.86565,\n",
       "            0.86364,     0.86364,     0.86289,     0.86289,     0.86216,     0.86216,     0.86017,     0.85714,      0.8552,     0.85327,     0.84531,     0.84531,     0.84531,     0.84401,     0.84401,     0.84401,     0.84401,     0.84135,     0.84135,     0.84053,     0.83971,     0.83971,     0.83829,\n",
       "            0.83829,     0.83829,      0.8355,     0.83216,     0.83216,     0.83216,     0.83197,     0.83197,     0.83197,     0.83197,     0.83197,     0.83023,     0.82373,     0.82319,     0.82319,     0.81963,     0.81612,      0.8149,      0.8149,      0.8149,      0.8149,      0.8132,      0.8132,\n",
       "             0.8132,      0.8132,      0.8132,      0.8118,      0.8118,      0.8118,     0.81111,     0.81042,     0.80748,     0.80748,     0.80748,     0.80504,     0.80371,     0.80371,     0.80326,     0.80326,     0.80326,     0.80087,     0.79935,     0.79871,     0.79807,     0.79318,     0.79237,\n",
       "            0.79237,     0.79237,     0.79237,     0.79237,     0.79175,     0.79031,     0.78804,     0.78601,     0.78601,     0.78542,     0.78157,     0.78099,     0.78099,     0.77823,     0.77823,     0.77607,     0.77236,     0.76253,       0.762,     0.75996,     0.75944,     0.75743,     0.75743,\n",
       "            0.75542,      0.7527,        0.75,     0.74733,     0.74468,     0.74421,     0.74302,     0.74067,     0.74067,     0.74067,     0.73975,     0.73975,     0.73789,     0.73491,     0.73491,     0.72829,     0.72516,       0.725,       0.725,       0.725,     0.71821,     0.71821,     0.71585,\n",
       "            0.71506,     0.71506,     0.71338,      0.7041,     0.70275,     0.70275,     0.70275,     0.70239,     0.69406,     0.69304,     0.69304,     0.69304,     0.69271,     0.68966,     0.68966,     0.68696,     0.68696,     0.68372,      0.6714,     0.67056,     0.66364,        0.65,     0.64149,\n",
       "            0.64127,     0.64003,     0.63729,     0.63729,     0.62674,     0.62222,     0.61591,     0.61527,     0.61094,     0.61078,     0.60563,     0.60458,     0.60398,     0.60398,      0.5955,     0.58811,     0.57795,     0.57795,     0.57582,     0.57531,     0.55924,     0.55429,     0.55017,\n",
       "            0.55017,     0.53445,     0.53445,     0.53402,     0.53402,     0.52622,      0.5193,     0.50946,     0.50914,     0.50851,     0.50851,      0.5024,     0.46251,     0.44877,     0.44877,     0.44015,     0.40258,     0.40133,     0.39765,     0.39681,     0.39681,     0.38889,     0.36193,\n",
       "            0.35199,     0.34553,     0.34273,     0.34121,     0.32998,     0.32533,     0.32058,     0.32058,      0.3194,     0.31823,     0.30318,     0.29909,     0.27967,     0.27299,      0.2594,     0.24174,     0.23802,     0.23802,     0.23448,     0.23099,     0.22774,     0.22563,     0.22501,\n",
       "            0.21481,     0.21322,     0.19499,     0.19057,     0.19057,     0.18865,      0.1885,     0.18646,     0.18244,     0.17882,     0.17619,     0.17061,      0.1312,     0.12174,     0.12174,      0.1109,      0.1105,     0.10629,    0.094045,    0.092773,    0.092567,    0.090657,    0.083102,\n",
       "           0.075547,    0.067993,    0.060438,    0.052883,    0.045328,    0.037774,    0.030219,    0.022664,    0.015109,   0.0075547,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.1689,     0.16898,     0.23958,     0.28813,      0.3227,      0.3512,     0.37335,     0.39404,     0.41121,     0.42686,     0.44183,     0.45666,     0.46877,     0.48089,     0.49091,     0.50135,     0.50856,     0.51426,     0.52256,     0.53013,     0.53726,     0.54454,     0.55168,\n",
       "              0.558,     0.56235,      0.5655,      0.5702,     0.57563,     0.58123,      0.5885,     0.59174,     0.59584,     0.59899,     0.60464,     0.60682,     0.61104,     0.61439,      0.6184,      0.6229,     0.62585,     0.63069,     0.63412,     0.63799,     0.64184,     0.64647,     0.65092,\n",
       "             0.6545,     0.65749,     0.65832,     0.66121,     0.66335,      0.6655,     0.66714,     0.66856,     0.67103,       0.673,     0.67522,     0.67723,      0.6761,     0.67917,     0.68238,     0.68374,     0.68622,     0.68921,     0.69106,     0.69123,     0.69472,     0.69603,     0.69851,\n",
       "             0.7017,     0.70213,     0.70381,      0.7051,     0.70701,       0.707,     0.70822,      0.7088,     0.71063,     0.71172,     0.71379,     0.71472,     0.71511,     0.71773,      0.7195,     0.72033,     0.72141,     0.72327,     0.72528,     0.72615,     0.72615,     0.72603,     0.72663,\n",
       "            0.72717,     0.72812,     0.72997,     0.72976,     0.73003,     0.73128,     0.73242,      0.7325,     0.73225,     0.73249,     0.73367,     0.73477,     0.73562,     0.73681,     0.73695,     0.73816,     0.73962,     0.73985,     0.74014,     0.74073,     0.74163,     0.74284,     0.74411,\n",
       "            0.74572,     0.74644,      0.7464,     0.74726,     0.74777,     0.74843,     0.74821,     0.74797,      0.7495,     0.75047,     0.75234,     0.75352,     0.75509,     0.75639,     0.75757,     0.75923,     0.76005,     0.76101,     0.76229,     0.76428,      0.7646,     0.76591,     0.76627,\n",
       "            0.76601,     0.76649,     0.76783,     0.76936,     0.76992,     0.77191,      0.7727,     0.77298,     0.77404,     0.77485,     0.77523,     0.77571,     0.77524,     0.77557,     0.77707,     0.77608,     0.77662,     0.77691,     0.77785,     0.77771,     0.77738,     0.77659,     0.77695,\n",
       "            0.77688,     0.77727,     0.77843,     0.77881,     0.77926,     0.77968,     0.78116,     0.78194,     0.78163,     0.78118,     0.78082,     0.78145,     0.78166,     0.78257,     0.78288,     0.78306,     0.78323,      0.7834,     0.78369,     0.78428,     0.78467,     0.78524,     0.78574,\n",
       "            0.78629,     0.78646,     0.78738,     0.78728,     0.78671,     0.78711,     0.78698,     0.78686,     0.78673,      0.7866,     0.78671,     0.78689,     0.78777,      0.7879,     0.78998,     0.79053,     0.79078,     0.79105,     0.79084,     0.79024,     0.78995,     0.79013,     0.79064,\n",
       "            0.79118,     0.79138,     0.79173,     0.79184,     0.79363,     0.79446,     0.79512,     0.79525,     0.79505,     0.79485,     0.79457,     0.79458,     0.79522,     0.79576,     0.79638,     0.79652,     0.79666,     0.79652,     0.79619,     0.79601,     0.79547,     0.79518,     0.79561,\n",
       "            0.79653,     0.79611,     0.79633,     0.79652,      0.7963,     0.79648,     0.79702,     0.79731,     0.79712,     0.79765,     0.79871,     0.79834,     0.79824,     0.79846,     0.79878,      0.7992,      0.7997,     0.80032,     0.80026,      0.8007,     0.80121,     0.80106,     0.80134,\n",
       "            0.80145,     0.80155,     0.80166,     0.80207,     0.80178,     0.80149,     0.80185,     0.80165,     0.80146,     0.80126,     0.80176,     0.80189,     0.80202,     0.80235,     0.80195,     0.80256,     0.80283,     0.80336,     0.80365,     0.80436,     0.80489,      0.8057,     0.80679,\n",
       "            0.80706,     0.80708,     0.80671,     0.80674,     0.80697,     0.80732,     0.80813,     0.80824,     0.80829,     0.80852,     0.80916,     0.80863,     0.80905,     0.80918,     0.80931,     0.80949,     0.80941,     0.80918,     0.80956,     0.80975,     0.81006,     0.81111,     0.81092,\n",
       "            0.81062,     0.81024,     0.81088,     0.81159,     0.81153,     0.81135,     0.81117,     0.81132,     0.81136,     0.81149,     0.81162,     0.81167,     0.81144,     0.81122,     0.81085,     0.81016,     0.80956,     0.80919,     0.80939,     0.80974,     0.81065,     0.81082,     0.81096,\n",
       "             0.8111,     0.81164,     0.81175,     0.81186,     0.81197,     0.81167,     0.81164,     0.81149,     0.81148,     0.81144,     0.81123,     0.81103,     0.81174,     0.81124,     0.81172,     0.81188,     0.81204,     0.81243,     0.81177,     0.81149,     0.81136,     0.81141,     0.81112,\n",
       "            0.81048,     0.81068,     0.81092,     0.81123,     0.81107,     0.81116,     0.81124,     0.81133,     0.81142,     0.81174,     0.81122,     0.81032,     0.81046,     0.81083,     0.81149,      0.8117,     0.81113,     0.81145,     0.81101,     0.81121,      0.8111,     0.81021,     0.81058,\n",
       "            0.81082,     0.80988,     0.80945,     0.80925,     0.80905,     0.80846,     0.80788,      0.8078,     0.80828,     0.80888,     0.80795,     0.80749,     0.80742,     0.80777,     0.80738,     0.80859,     0.80889,     0.80865,     0.80841,     0.80917,     0.80938,     0.80953,     0.80967,\n",
       "            0.80998,     0.80971,     0.80883,     0.80919,     0.80895,     0.80932,      0.8096,     0.80984,     0.81032,      0.8109,     0.81118,     0.81155,     0.81167,     0.81138,     0.81124,     0.81174,     0.81143,      0.8111,     0.81079,      0.8099,      0.8097,     0.80951,     0.80909,\n",
       "            0.80873,       0.808,     0.80843,     0.80869,     0.80943,     0.80961,     0.80992,     0.81002,     0.81012,     0.81021,     0.81031,     0.81017,      0.8099,     0.80958,     0.80877,     0.80831,     0.80893,     0.80886,     0.80876,     0.80838,     0.80872,     0.80855,     0.80839,\n",
       "            0.80822,     0.80773,     0.80783,     0.80874,     0.80853,     0.80832,     0.80811,     0.80728,      0.8071,     0.80691,     0.80669,     0.80611,     0.80622,     0.80643,     0.80677,     0.80634,     0.80595,     0.80563,     0.80625,     0.80657,     0.80667,     0.80677,     0.80687,\n",
       "            0.80697,     0.80723,       0.808,     0.80851,     0.80898,     0.80935,     0.80894,     0.80869,     0.80878,     0.80886,     0.80895,     0.80903,     0.80912,     0.80942,     0.80955,     0.80968,     0.80981,     0.80953,     0.80922,     0.80942,     0.80961,     0.81029,     0.81052,\n",
       "            0.81026,     0.80993,     0.81017,     0.81074,     0.80964,     0.80946,     0.80902,     0.80875,     0.80854,     0.80877,     0.80898,      0.8087,     0.80842,     0.80857,     0.80907,     0.80789,     0.80698,     0.80676,     0.80655,     0.80649,     0.80669,     0.80689,      0.8065,\n",
       "            0.80583,     0.80532,     0.80513,     0.80494,     0.80474,      0.8044,     0.80406,     0.80474,     0.80395,     0.80251,     0.80176,     0.80132,     0.80061,     0.80085,     0.80056,     0.79986,      0.7999,     0.79959,     0.79928,      0.7998,      0.7996,     0.79905,     0.79899,\n",
       "            0.79864,      0.7983,     0.79807,     0.79784,     0.79761,      0.7977,     0.79784,     0.79797,     0.79821,     0.79667,     0.79704,     0.79764,     0.79715,     0.79736,     0.79755,     0.79719,     0.79681,     0.79546,     0.79474,     0.79465,     0.79429,     0.79191,     0.79153,\n",
       "            0.79186,     0.79125,     0.79086,     0.79051,     0.79077,     0.79043,     0.79007,     0.78953,     0.78901,     0.78875,     0.78903,     0.78935,     0.78862,     0.78795,     0.78775,     0.78755,     0.78747,      0.7878,     0.78671,     0.78623,     0.78598,     0.78627,      0.7854,\n",
       "            0.78518,     0.78495,     0.78458,     0.78419,     0.78394,     0.78356,     0.78325,     0.78258,     0.78096,     0.77994,     0.77936,     0.77898,     0.77866,      0.7781,      0.7772,     0.77659,      0.7759,     0.77623,     0.77594,     0.77598,     0.77619,     0.77577,     0.77487,\n",
       "            0.77398,     0.77341,     0.77262,     0.77099,     0.77182,     0.77123,     0.77059,     0.76921,      0.7684,       0.768,     0.76864,     0.76843,     0.76843,     0.76705,     0.76653,     0.76654,     0.76708,      0.7667,     0.76619,     0.76507,     0.76379,     0.76343,     0.76297,\n",
       "            0.76256,      0.7629,     0.76123,     0.75967,     0.75943,      0.7597,     0.75992,     0.76008,     0.76021,     0.76035,     0.76048,      0.7596,     0.75937,     0.75914,     0.75892,     0.75863,     0.75834,     0.75806,     0.75786,     0.75767,     0.75747,     0.75728,      0.7566,\n",
       "            0.75664,     0.75683,     0.75648,     0.75503,     0.75365,       0.753,     0.75322,      0.7532,     0.75227,     0.75185,     0.75117,     0.75027,     0.75088,     0.75048,     0.74831,     0.74708,     0.74618,     0.74553,     0.74512,      0.7453,     0.74547,     0.74435,     0.74282,\n",
       "            0.74263,     0.74076,     0.74171,     0.74007,     0.74035,     0.74009,     0.73879,     0.73825,     0.73776,     0.73794,     0.73782,     0.73701,     0.73601,     0.73454,     0.73384,       0.733,     0.73308,     0.73328,     0.73237,     0.73035,     0.72936,     0.72849,     0.72746,\n",
       "            0.72784,     0.72777,     0.72749,     0.72598,     0.72446,     0.72391,      0.7235,     0.72318,     0.72292,     0.72266,     0.72222,     0.72064,     0.71982,     0.71962,     0.72025,     0.72018,     0.71987,     0.71956,     0.71796,      0.7179,      0.7162,     0.71428,      0.7131,\n",
       "            0.71051,     0.70931,        0.71,     0.70961,     0.70923,     0.70864,     0.70774,     0.70743,     0.70443,     0.70343,      0.7019,     0.70071,     0.69945,     0.69817,     0.69753,     0.69557,     0.69405,     0.69315,      0.6917,     0.69134,     0.68992,     0.68928,      0.6886,\n",
       "            0.68837,     0.68812,     0.68802,     0.68588,     0.68405,     0.68359,      0.6823,     0.68124,     0.68096,     0.68068,     0.68039,     0.68008,     0.67978,      0.6785,     0.67503,     0.67545,     0.67573,     0.67387,     0.67183,     0.66991,     0.66613,     0.66515,     0.66376,\n",
       "            0.66068,      0.6572,     0.65639,     0.65242,     0.65084,     0.64777,     0.64669,      0.6452,     0.64254,     0.63929,     0.63821,     0.63459,     0.63238,     0.63047,     0.62902,     0.62411,      0.6222,     0.62071,     0.62072,     0.61888,     0.61593,      0.6101,     0.60865,\n",
       "            0.60674,      0.6063,     0.60478,     0.60314,     0.60037,     0.59932,      0.5989,     0.59846,     0.59597,      0.5934,     0.58943,     0.58802,     0.58351,     0.58169,     0.58007,     0.57698,     0.57472,     0.57067,     0.56748,     0.56601,     0.56156,     0.55823,     0.55322,\n",
       "            0.55206,     0.55155,      0.5494,     0.54656,     0.54537,     0.54378,     0.53944,     0.53669,     0.53252,     0.53028,      0.5292,     0.52571,     0.52277,     0.51935,     0.51839,      0.5171,     0.51602,     0.51408,     0.51143,     0.50913,     0.50532,     0.50247,     0.49961,\n",
       "            0.49535,     0.49387,     0.48973,     0.48516,     0.48134,     0.47282,     0.46938,     0.46408,     0.46173,     0.45654,     0.44827,     0.44399,     0.43675,     0.43259,     0.42749,     0.42146,       0.414,     0.41281,     0.40825,     0.40707,     0.40513,     0.40365,     0.39893,\n",
       "            0.39724,     0.39654,     0.39536,      0.3915,     0.38666,     0.38222,     0.37894,     0.37578,     0.36995,     0.36582,     0.36514,      0.3638,     0.36012,     0.35923,     0.35752,     0.35456,     0.35241,     0.34908,     0.34049,     0.33935,     0.33615,     0.33377,     0.33131,\n",
       "             0.3228,     0.31527,     0.31365,     0.31214,     0.30865,     0.30667,     0.30304,     0.29875,     0.29588,     0.29458,     0.28887,     0.28583,     0.28001,     0.27652,     0.27171,     0.26639,     0.26413,     0.26119,     0.25768,     0.25641,     0.25557,     0.25424,     0.25111,\n",
       "            0.24923,      0.2432,     0.24141,     0.23561,      0.2331,     0.23174,     0.22945,     0.22485,     0.21906,     0.21816,     0.21554,     0.20934,      0.2035,     0.20038,     0.19932,     0.19827,     0.19656,     0.19281,     0.18809,     0.18499,     0.17933,     0.17572,     0.16966,\n",
       "            0.16665,     0.16572,     0.16471,     0.16339,     0.16044,     0.15805,     0.15253,     0.15063,     0.14753,     0.14297,     0.13854,     0.12928,     0.12723,     0.12409,     0.12174,     0.11767,     0.11659,     0.11598,     0.11536,     0.11255,     0.11088,     0.11004,     0.10915,\n",
       "            0.10755,     0.10646,     0.10549,     0.10209,    0.097128,     0.09633,    0.095531,    0.092379,    0.090127,    0.084904,    0.081928,    0.080233,    0.078923,    0.077157,    0.073694,      0.0706,     0.06917,    0.063712,    0.062064,     0.06099,    0.058247,    0.057614,     0.05698,\n",
       "           0.056346,    0.055808,    0.055295,    0.054781,    0.054267,    0.047733,     0.04677,    0.045807,     0.04255,     0.04042,    0.036822,    0.036407,    0.035992,    0.035577,    0.035161,    0.034293,    0.033049,    0.031673,    0.029824,    0.025497,    0.022672,     0.02108,    0.019808,\n",
       "            0.01799,    0.016804,    0.015768,    0.014061,    0.011462,   0.0094545,   0.0077063,   0.0058153,   0.0034731,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.092346,    0.092391,     0.13649,     0.16893,     0.19354,     0.21453,     0.23161,     0.24797,     0.26181,     0.27472,     0.28735,     0.30014,      0.3108,     0.32193,     0.33125,     0.34097,     0.34797,     0.35349,     0.36138,     0.36883,     0.37577,     0.38293,     0.39023,\n",
       "            0.39677,     0.40159,     0.40502,     0.40986,      0.4155,     0.42136,     0.42904,     0.43249,     0.43689,     0.44053,     0.44667,     0.44957,     0.45421,     0.45792,      0.4624,     0.46772,     0.47106,     0.47656,      0.4805,     0.48495,     0.48942,     0.49482,     0.50006,\n",
       "            0.50462,     0.50851,     0.51018,     0.51366,     0.51624,      0.5192,     0.52121,     0.52293,     0.52632,     0.52876,     0.53151,       0.534,     0.53408,     0.53792,     0.54196,     0.54367,     0.54682,     0.55103,     0.55339,     0.55401,     0.55851,     0.56062,     0.56385,\n",
       "            0.56801,     0.56858,     0.57078,     0.57248,     0.57519,     0.57587,     0.57777,     0.57915,      0.5816,     0.58306,     0.58584,      0.5871,     0.58809,     0.59164,     0.59405,     0.59519,     0.59713,     0.59969,     0.60246,     0.60365,     0.60386,     0.60448,     0.60551,\n",
       "            0.60656,     0.60787,     0.61046,     0.61117,     0.61155,     0.61331,     0.61491,     0.61518,      0.6157,     0.61604,     0.61772,     0.61928,     0.62047,     0.62221,      0.6229,     0.62463,     0.62673,     0.62759,     0.62801,     0.62886,     0.63016,     0.63192,     0.63376,\n",
       "            0.63609,     0.63714,     0.63764,      0.6389,     0.64021,     0.64118,     0.64147,     0.64163,     0.64389,     0.64532,      0.6481,     0.64995,     0.65278,     0.65472,     0.65649,     0.65899,     0.66023,     0.66168,     0.66423,     0.66725,     0.66774,     0.66974,     0.67092,\n",
       "            0.67116,     0.67188,     0.67394,      0.6763,     0.67717,     0.68027,     0.68148,     0.68193,     0.68424,     0.68549,     0.68609,     0.68684,     0.68672,     0.68729,     0.68965,     0.68943,     0.69028,     0.69073,     0.69222,     0.69251,     0.69279,     0.69294,     0.69391,\n",
       "            0.69409,     0.69471,     0.69657,     0.69717,     0.69791,     0.69857,     0.70096,     0.70221,      0.7022,     0.70246,     0.70253,     0.70355,      0.7046,     0.70608,     0.70658,     0.70687,     0.70716,     0.70744,     0.70791,     0.70888,      0.7095,     0.71045,     0.71125,\n",
       "            0.71217,     0.71317,     0.71469,     0.71493,     0.71507,     0.71582,     0.71576,     0.71571,     0.71566,      0.7156,     0.71582,     0.71612,     0.71757,     0.71929,     0.72278,     0.72369,     0.72411,     0.72456,     0.72481,     0.72506,     0.72503,     0.72534,      0.7262,\n",
       "            0.72712,     0.72745,     0.72823,       0.729,     0.73205,     0.73346,     0.73459,     0.73488,      0.7348,     0.73472,     0.73461,     0.73528,     0.73638,     0.73775,     0.73917,     0.73941,     0.73965,     0.73967,     0.73954,     0.74017,     0.74034,     0.74022,     0.74114,\n",
       "            0.74274,     0.74284,     0.74406,     0.74439,     0.74453,     0.74516,     0.74611,      0.7466,     0.74712,     0.74805,     0.74993,     0.74984,     0.74995,     0.75035,     0.75091,     0.75165,     0.75253,     0.75451,     0.75528,     0.75606,     0.75696,     0.75727,     0.75808,\n",
       "            0.75827,     0.75847,     0.75866,     0.75943,     0.75932,     0.75921,     0.75994,     0.75987,      0.7598,     0.75972,     0.76062,     0.76085,     0.76108,     0.76193,     0.76239,     0.76386,     0.76435,     0.76533,     0.76584,     0.76714,     0.76809,     0.76957,     0.77156,\n",
       "            0.77206,     0.77231,     0.77217,      0.7724,     0.77282,     0.77346,     0.77495,      0.7759,     0.77619,     0.77662,      0.7778,     0.77796,      0.7795,     0.77974,     0.77997,     0.78031,     0.78113,     0.78166,     0.78236,     0.78272,      0.7833,     0.78527,     0.78532,\n",
       "            0.78522,     0.78575,     0.78778,     0.79013,     0.79025,     0.79019,     0.79013,      0.7906,     0.79169,     0.79194,     0.79219,     0.79235,     0.79228,      0.7922,     0.79208,     0.79184,     0.79163,      0.7916,       0.793,     0.79366,     0.79541,     0.79575,     0.79602,\n",
       "            0.79629,     0.79733,     0.79754,     0.79775,     0.79796,     0.79795,     0.79836,      0.7986,     0.79909,      0.7993,     0.79923,     0.79916,     0.80065,     0.80067,     0.80167,     0.80198,      0.8023,     0.80306,     0.80301,     0.80292,     0.80309,     0.80362,     0.80353,\n",
       "            0.80351,      0.8039,     0.80438,     0.80503,     0.80575,     0.80592,     0.80609,     0.80627,     0.80644,     0.80706,     0.80725,     0.80695,     0.80781,     0.80854,     0.80986,     0.81028,     0.81025,     0.81089,     0.81112,     0.81153,     0.81172,     0.81175,     0.81249,\n",
       "            0.81298,     0.81287,     0.81273,     0.81267,     0.81261,     0.81242,     0.81223,     0.81255,     0.81351,     0.81487,     0.81458,     0.81444,     0.81521,     0.81593,     0.81629,     0.81876,      0.8196,     0.81952,     0.81945,     0.82112,     0.82157,     0.82186,     0.82216,\n",
       "             0.8228,     0.82305,      0.8228,     0.82354,     0.82425,       0.825,     0.82559,      0.8261,      0.8271,     0.82831,     0.82888,     0.82966,     0.83019,      0.8301,     0.83023,     0.83128,     0.83179,     0.83169,      0.8316,     0.83134,     0.83189,     0.83207,     0.83195,\n",
       "            0.83184,     0.83163,     0.83294,      0.8335,     0.83544,     0.83672,     0.83738,     0.83759,      0.8378,     0.83801,     0.83822,     0.83824,     0.83816,     0.83807,     0.83784,     0.83771,     0.83908,     0.83961,        0.84,     0.84035,     0.84133,     0.84128,     0.84124,\n",
       "            0.84119,     0.84105,      0.8419,       0.844,     0.84394,     0.84388,     0.84382,      0.8436,     0.84355,     0.84349,     0.84343,     0.84327,     0.84366,     0.84411,     0.84525,     0.84514,     0.84503,     0.84503,      0.8464,      0.8471,     0.84732,     0.84754,     0.84775,\n",
       "            0.84797,     0.84855,     0.85026,     0.85138,     0.85242,     0.85325,     0.85316,     0.85315,     0.85334,     0.85353,     0.85372,     0.85392,     0.85411,     0.85615,     0.85644,     0.85673,     0.85702,     0.85706,     0.85711,     0.85754,     0.85798,      0.8595,     0.86003,\n",
       "            0.86009,      0.8601,     0.86065,     0.86213,     0.86227,     0.86278,     0.86267,     0.86261,     0.86261,     0.86313,     0.86363,     0.86357,      0.8635,     0.86412,     0.86561,     0.86533,     0.86511,     0.86505,       0.865,     0.86515,     0.86561,     0.86607,     0.86598,\n",
       "            0.86581,     0.86569,     0.86565,      0.8656,     0.86555,     0.86547,     0.86539,     0.86855,     0.86836,     0.86802,     0.86784,     0.86773,     0.86785,      0.8684,     0.86856,      0.8684,     0.86943,     0.86936,     0.86928,     0.87206,     0.87244,     0.87232,     0.87334,\n",
       "            0.87326,     0.87318,     0.87313,     0.87308,     0.87302,      0.8733,     0.87363,     0.87395,     0.87452,      0.8749,     0.87648,     0.87793,     0.87834,     0.87886,     0.87935,     0.87927,     0.87919,     0.87889,     0.87981,     0.88202,     0.88297,     0.88246,     0.88265,\n",
       "            0.88355,     0.88342,     0.88334,     0.88326,     0.88443,     0.88436,     0.88428,     0.88416,     0.88405,     0.88419,      0.8849,     0.88571,     0.88621,     0.88607,     0.88603,     0.88599,     0.88614,     0.88699,     0.88694,     0.88824,     0.88938,     0.89013,      0.8901,\n",
       "            0.89006,     0.89001,     0.88994,     0.89014,     0.89096,     0.89089,     0.89082,     0.89068,     0.89035,     0.89014,     0.89002,     0.88995,     0.88988,     0.88977,     0.88958,     0.89063,     0.89051,     0.89137,     0.89169,     0.89258,     0.89533,     0.89524,     0.89507,\n",
       "            0.89489,     0.89478,     0.89462,     0.89454,      0.8969,     0.89678,     0.89666,     0.89639,     0.89623,     0.89625,       0.898,     0.89871,     0.89941,      0.8997,      0.8996,     0.90025,     0.90222,     0.90215,     0.90206,     0.90185,     0.90161,     0.90154,     0.90145,\n",
       "            0.90149,     0.90244,      0.9024,     0.90211,     0.90314,      0.9039,     0.90453,       0.905,     0.90537,     0.90575,     0.90612,     0.90599,     0.90595,     0.90591,     0.90587,     0.90582,     0.90576,     0.90571,     0.90568,     0.90564,     0.90561,     0.90557,     0.90545,\n",
       "            0.90588,     0.90644,     0.90675,     0.90648,     0.90623,     0.90632,     0.90695,     0.90749,     0.90732,     0.90724,     0.90712,     0.90724,     0.90905,     0.91105,     0.91068,     0.91046,     0.91031,     0.91019,     0.91027,     0.91078,      0.9113,     0.91275,     0.91249,\n",
       "            0.91386,      0.9136,      0.9165,     0.91631,     0.91717,     0.91769,     0.91748,     0.91802,      0.9202,     0.92201,     0.92313,     0.92301,     0.92285,     0.92263,     0.92252,     0.92388,     0.92447,     0.92511,     0.92527,     0.92497,     0.92482,     0.92469,     0.92475,\n",
       "            0.92597,     0.92842,     0.93019,     0.93044,     0.93023,     0.93015,      0.9301,     0.93005,     0.93001,     0.92998,     0.92992,     0.93126,     0.93115,     0.93166,     0.93377,     0.93436,     0.93432,     0.93428,     0.93456,     0.93566,     0.93544,     0.93519,     0.93503,\n",
       "            0.93469,     0.93616,     0.93956,     0.93951,     0.93946,     0.93939,     0.93927,     0.94091,     0.94119,     0.94212,     0.94193,     0.94179,     0.94164,     0.94148,      0.9414,      0.9429,     0.94272,     0.94261,     0.94244,     0.94415,     0.94398,     0.94391,     0.94479,\n",
       "            0.94558,     0.94638,     0.94733,     0.94709,     0.94809,     0.94865,     0.94851,      0.9484,     0.94836,     0.94833,      0.9483,     0.94827,     0.94824,      0.9481,     0.94771,     0.95033,     0.95142,     0.95132,     0.95442,     0.95472,     0.95435,     0.95426,     0.95412,\n",
       "            0.95381,     0.95346,     0.95338,     0.95298,     0.95282,      0.9525,     0.95286,     0.95426,     0.95399,     0.95367,     0.95356,     0.95319,     0.95296,     0.95276,     0.95261,     0.95209,     0.95189,     0.95184,     0.95387,     0.95368,     0.95338,     0.95276,     0.95482,\n",
       "            0.95463,     0.95458,     0.95443,     0.95426,     0.95397,     0.95386,     0.95382,     0.95377,     0.95351,     0.95323,     0.95281,     0.95265,     0.95216,     0.95196,     0.95178,     0.95143,     0.95118,     0.95072,     0.95035,     0.95018,     0.94965,     0.94926,     0.94865,\n",
       "            0.95104,     0.95098,     0.95329,     0.95297,     0.95283,     0.95265,      0.9548,     0.95449,     0.95403,     0.95378,     0.95638,       0.956,     0.95568,      0.9553,      0.9552,     0.95505,     0.95493,     0.95471,     0.95441,     0.95703,     0.95954,     0.95928,     0.96195,\n",
       "            0.96153,     0.96138,     0.96096,      0.9605,     0.96326,     0.96242,     0.96269,     0.96487,     0.96803,     0.96758,     0.96683,     0.96643,     0.96574,     0.96533,     0.96482,      0.9642,     0.96342,     0.96329,     0.96279,     0.96266,     0.96644,     0.96629,     0.96581,\n",
       "            0.96564,     0.96556,     0.96544,     0.96503,      0.9645,     0.96401,     0.96364,     0.96768,     0.96708,     0.96664,     0.96656,     0.96642,     0.96601,     0.96591,     0.96572,     0.96539,     0.96514,     0.96475,     0.96371,     0.96357,     0.96317,     0.96286,     0.96254,\n",
       "             0.9614,     0.96035,     0.96012,      0.9599,     0.95938,     0.96155,      0.9642,     0.96947,     0.96913,     0.96897,     0.96828,     0.96789,     0.96714,     0.96668,     0.96601,     0.97198,     0.97171,     0.97135,     0.97092,     0.97076,     0.97065,     0.97048,     0.97736,\n",
       "            0.97717,     0.97654,     0.97634,      0.9757,     0.97541,     0.97525,     0.97498,     0.97441,     0.97367,     0.97355,      0.9732,     0.97234,     0.97148,       0.971,     0.97083,     0.97066,     0.97039,     0.96977,     0.97906,     0.97868,     0.97796,     0.97747,     0.97661,\n",
       "            0.97616,     0.97602,     0.97586,     0.97565,     0.97518,     0.97478,     0.97382,     0.97347,     0.97288,     0.97197,     0.97104,     0.96888,     0.96836,     0.96753,     0.96688,     0.98253,     0.98237,     0.98227,     0.98217,     0.98171,     0.98142,     0.98127,     0.98112,\n",
       "            0.98082,     0.98062,     0.98043,     0.97976,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98776,     0.98776,     0.97887,     0.97887,     0.96997,     0.96774,     0.96218,     0.95884,     0.95773,     0.95662,     0.95551,     0.95439,     0.95328,     0.94994,     0.94772,     0.94661,     0.94438,     0.94327,     0.94327,     0.94216,     0.94216,     0.94216,     0.94105,\n",
       "            0.93993,     0.93771,      0.9366,      0.9366,      0.9366,      0.9366,      0.9366,      0.9366,      0.9366,     0.93548,     0.93548,     0.93326,     0.93326,     0.93326,     0.93326,     0.93215,     0.93215,     0.93215,     0.93215,     0.93215,     0.93215,     0.93215,     0.93215,\n",
       "            0.93103,     0.92992,      0.9277,      0.9277,      0.9277,     0.92659,     0.92659,     0.92659,     0.92547,     0.92547,     0.92547,     0.92547,     0.92102,     0.92102,     0.92102,     0.92102,     0.92102,     0.91991,     0.91991,      0.9188,      0.9188,     0.91769,     0.91769,\n",
       "            0.91769,     0.91769,     0.91769,     0.91769,     0.91721,     0.91546,     0.91477,     0.91324,     0.91324,     0.91324,     0.91324,     0.91324,     0.91212,     0.91212,     0.91212,     0.91212,     0.91101,     0.91101,     0.91101,     0.91101,     0.91055,     0.90879,     0.90832,\n",
       "            0.90768,     0.90768,     0.90768,     0.90545,     0.90545,     0.90545,     0.90545,     0.90511,     0.90323,     0.90323,     0.90323,     0.90323,     0.90323,     0.90317,     0.90211,     0.90211,      0.9021,       0.901,       0.901,       0.901,       0.901,       0.901,       0.901,\n",
       "              0.901,       0.901,     0.89989,     0.89989,     0.89878,     0.89878,     0.89757,     0.89655,     0.89655,     0.89655,     0.89655,     0.89636,     0.89544,     0.89544,     0.89544,     0.89544,     0.89544,     0.89544,     0.89433,     0.89433,     0.89433,     0.89433,     0.89321,\n",
       "             0.8921,      0.8921,      0.8921,      0.8921,      0.8921,      0.8921,      0.8921,      0.8921,     0.89099,     0.89099,     0.89099,     0.89099,     0.88997,     0.88988,     0.88988,     0.88765,     0.88765,     0.88765,     0.88765,     0.88682,      0.8855,      0.8832,     0.88258,\n",
       "            0.88209,     0.88209,     0.88209,     0.88209,     0.88209,     0.88209,     0.88209,     0.88209,      0.8813,     0.87976,     0.87875,     0.87875,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,     0.87764,\n",
       "            0.87764,     0.87653,     0.87653,     0.87594,      0.8743,     0.87417,     0.87394,     0.87371,     0.87348,     0.87325,     0.87319,     0.87319,     0.87319,     0.87097,     0.87097,     0.87097,     0.87097,     0.87097,     0.87012,      0.8683,     0.86763,     0.86763,     0.86763,\n",
       "            0.86763,     0.86763,     0.86735,     0.86652,     0.86652,     0.86652,     0.86652,     0.86641,     0.86606,      0.8657,      0.8652,     0.86429,     0.86429,     0.86367,     0.86318,     0.86318,     0.86318,     0.86284,     0.86224,     0.86096,     0.85948,     0.85894,     0.85873,\n",
       "            0.85873,     0.85762,     0.85651,     0.85651,     0.85581,     0.85539,     0.85539,     0.85539,     0.85428,     0.85428,     0.85428,     0.85355,     0.85317,     0.85317,     0.85317,     0.85317,     0.85317,     0.85206,     0.85095,     0.85095,     0.85095,     0.85022,     0.84983,\n",
       "            0.84983,     0.84983,     0.84983,     0.84978,     0.84927,     0.84875,     0.84865,      0.8483,     0.84796,     0.84761,     0.84761,     0.84761,     0.84761,     0.84729,     0.84585,     0.84538,     0.84538,     0.84538,     0.84538,     0.84538,     0.84538,     0.84538,     0.84538,\n",
       "            0.84538,     0.84514,     0.84449,     0.84427,     0.84427,     0.84427,     0.84427,     0.84341,     0.84316,     0.84316,     0.84316,     0.84182,     0.84093,     0.84093,     0.84093,     0.84093,     0.83982,     0.83871,     0.83871,     0.83871,     0.83871,     0.83871,     0.83824,\n",
       "            0.83771,      0.8363,     0.83537,     0.83426,     0.83399,     0.83368,     0.83337,     0.83315,     0.83204,     0.83204,     0.83204,     0.83194,     0.83156,     0.83118,     0.83053,     0.82934,     0.82831,     0.82759,     0.82647,     0.82647,     0.82647,     0.82647,     0.82647,\n",
       "            0.82647,     0.82647,     0.82647,     0.82647,     0.82647,     0.82587,     0.82536,      0.8248,     0.82425,     0.82396,     0.82361,     0.82326,     0.82314,     0.82211,     0.82202,     0.82202,     0.82202,     0.82202,     0.82072,     0.82025,      0.8198,     0.81936,     0.81886,\n",
       "            0.81758,     0.81758,     0.81758,     0.81752,     0.81646,     0.81646,     0.81646,     0.81646,     0.81646,     0.81646,     0.81524,     0.81371,     0.81313,     0.81313,     0.81313,     0.81313,     0.81201,     0.81201,      0.8109,      0.8109,     0.81048,     0.80868,     0.80868,\n",
       "            0.80868,     0.80692,      0.8062,     0.80586,     0.80553,     0.80454,     0.80356,     0.80311,     0.80311,     0.80298,     0.80142,     0.80066,     0.79978,     0.79978,     0.79867,     0.79867,     0.79846,     0.79806,     0.79767,     0.79755,     0.79755,     0.79755,     0.79755,\n",
       "            0.79755,     0.79679,     0.79533,     0.79533,     0.79422,     0.79422,     0.79422,     0.79422,     0.79422,     0.79422,     0.79422,     0.79422,     0.79397,     0.79349,      0.7931,      0.7931,     0.79205,      0.7915,       0.791,     0.78953,     0.78865,     0.78814,     0.78745,\n",
       "            0.78686,     0.78568,     0.78532,     0.78532,     0.78498,      0.7842,      0.7842,      0.7842,      0.7842,      0.7842,      0.7842,     0.78392,     0.78349,     0.78296,     0.78164,      0.7809,     0.78087,     0.78028,     0.77976,     0.77875,     0.77854,     0.77828,     0.77801,\n",
       "            0.77774,     0.77694,     0.77642,      0.7763,     0.77597,     0.77564,      0.7753,     0.77397,     0.77367,     0.77336,     0.77301,     0.77208,     0.77197,     0.77197,     0.77163,     0.77095,     0.77032,     0.76974,     0.76974,     0.76974,     0.76974,     0.76974,     0.76974,\n",
       "            0.76974,     0.76974,     0.76974,     0.76974,     0.76974,     0.76974,     0.76908,     0.76863,     0.76863,     0.76863,     0.76863,     0.76863,     0.76863,     0.76752,     0.76752,     0.76752,     0.76752,       0.767,     0.76641,     0.76641,     0.76641,     0.76641,     0.76641,\n",
       "            0.76588,     0.76529,     0.76529,     0.76513,     0.76307,     0.76235,     0.76166,     0.76123,     0.76085,     0.76085,     0.76083,     0.76039,     0.75995,     0.75973,     0.75946,      0.7576,     0.75617,     0.75583,     0.75549,     0.75528,     0.75528,     0.75528,     0.75466,\n",
       "            0.75362,     0.75282,     0.75253,     0.75223,     0.75192,     0.75138,     0.75085,     0.74966,     0.74843,     0.74619,     0.74503,     0.74435,     0.74305,     0.74305,     0.74242,     0.74135,     0.74067,      0.7402,     0.73972,      0.7386,     0.73798,     0.73714,     0.73631,\n",
       "            0.73577,     0.73525,      0.7349,     0.73454,     0.73419,     0.73415,     0.73415,     0.73415,     0.73415,     0.73128,     0.73081,     0.73081,      0.7297,      0.7297,     0.72967,     0.72912,     0.72855,      0.7265,     0.72467,     0.72303,     0.72179,     0.71821,     0.71746,\n",
       "            0.71741,     0.71649,     0.71591,     0.71539,     0.71504,     0.71454,     0.71399,     0.71319,     0.71242,      0.7119,      0.7119,      0.7119,     0.71039,     0.70939,     0.70909,      0.7088,     0.70857,     0.70857,     0.70683,     0.70523,     0.70412,     0.70412,     0.70274,\n",
       "            0.70241,     0.70207,     0.70153,     0.70078,     0.69987,     0.69931,     0.69885,     0.69787,     0.69551,     0.69402,     0.69317,     0.69262,     0.69215,     0.69133,     0.69003,     0.68844,     0.68743,     0.68743,      0.6868,     0.68632,     0.68504,     0.68443,     0.68314,\n",
       "            0.68186,     0.68104,      0.6799,     0.67742,     0.67735,     0.67652,      0.6756,     0.67364,     0.67248,     0.67186,     0.67186,     0.67113,     0.67075,     0.66849,     0.66776,     0.66741,     0.66715,     0.66661,     0.66589,     0.66432,     0.66252,     0.66202,     0.66137,\n",
       "            0.66073,     0.66073,     0.65825,     0.65607,     0.65517,     0.65517,     0.65517,     0.65517,     0.65517,     0.65517,     0.65517,     0.65393,     0.65362,      0.6533,     0.65299,     0.65259,     0.65218,      0.6518,     0.65153,     0.65126,     0.65099,     0.65072,     0.64978,\n",
       "            0.64961,     0.64961,     0.64894,     0.64694,     0.64504,     0.64405,     0.64405,     0.64376,     0.64249,      0.6419,     0.64097,      0.6396,      0.6396,     0.63803,     0.63507,     0.63342,      0.6322,     0.63132,      0.6307,      0.6307,      0.6307,      0.6284,     0.62635,\n",
       "            0.62544,     0.62291,     0.62291,     0.62069,     0.62069,     0.62008,     0.61836,     0.61735,      0.6157,     0.61513,     0.61447,      0.6134,     0.61209,     0.61015,     0.60924,     0.60749,     0.60734,     0.60734,     0.60603,     0.60339,      0.6021,     0.60097,     0.59956,\n",
       "            0.59956,     0.59844,     0.59733,     0.59519,     0.59324,     0.59253,     0.59201,     0.59159,     0.59126,     0.59092,     0.59036,     0.58772,     0.58667,     0.58621,     0.58621,     0.58587,     0.58549,      0.5851,     0.58287,     0.58236,     0.58022,     0.57779,     0.57631,\n",
       "            0.57306,     0.57095,     0.57059,     0.57011,     0.56963,      0.5689,     0.56778,     0.56678,     0.56285,     0.56123,     0.55936,      0.5579,     0.55636,     0.55479,     0.55401,     0.55104,     0.54919,      0.5481,     0.54635,     0.54532,     0.54361,     0.54285,     0.54171,\n",
       "            0.54117,      0.5406,     0.54016,     0.53761,     0.53504,      0.5343,     0.53277,     0.53152,     0.53118,     0.53085,     0.53051,     0.53015,     0.52979,     0.52828,      0.5242,     0.52392,     0.52392,     0.52172,     0.51835,     0.51598,     0.51162,     0.51049,     0.50889,\n",
       "            0.50537,      0.5014,     0.50048,     0.49598,     0.49421,     0.49076,     0.48943,     0.48736,     0.48439,      0.4808,      0.4796,     0.47562,     0.47319,     0.47111,     0.46953,      0.4642,     0.46214,     0.46051,     0.46005,     0.45807,     0.45492,     0.44872,     0.44669,\n",
       "            0.44468,     0.44422,     0.44262,     0.44091,     0.43802,     0.43693,     0.43648,     0.43603,     0.43344,     0.43079,      0.4267,     0.42525,     0.42065,      0.4188,     0.41715,     0.41404,     0.41176,      0.4077,     0.40451,     0.40305,     0.39864,     0.39536,     0.39046,\n",
       "             0.3889,     0.38841,      0.3859,     0.38315,     0.38201,     0.38048,     0.37591,     0.37329,     0.36934,     0.36723,     0.36581,     0.36253,     0.35979,     0.35661,     0.35573,     0.35453,     0.35353,     0.35174,      0.3493,     0.34682,     0.34297,     0.34038,     0.33743,\n",
       "            0.33361,     0.33228,      0.3286,     0.32454,     0.32083,     0.31339,     0.31034,     0.30551,     0.30317,     0.29875,     0.29178,      0.2882,     0.28218,     0.27876,     0.27458,     0.26967,     0.26365,      0.2627,     0.25905,      0.2581,     0.25628,     0.25511,     0.25138,\n",
       "            0.25006,     0.24951,     0.24858,     0.24556,      0.2418,     0.23837,     0.23584,     0.23316,     0.22873,      0.2256,     0.22509,     0.22407,     0.22131,     0.22064,     0.21936,     0.21716,     0.21556,     0.21309,     0.20677,     0.20594,      0.2036,     0.20188,     0.20009,\n",
       "            0.19396,     0.18859,     0.18744,     0.18638,     0.18391,     0.18242,     0.17977,     0.17658,     0.17459,     0.17369,     0.16976,     0.16767,      0.1637,     0.16134,     0.15809,     0.15435,     0.15284,     0.15088,     0.14855,     0.14771,     0.14716,     0.14628,     0.14406,\n",
       "            0.14283,      0.1389,     0.13773,     0.13398,     0.13237,      0.1315,     0.13003,     0.12709,     0.12341,     0.12284,     0.12119,      0.1173,     0.11365,     0.11172,     0.11106,     0.11041,     0.10936,     0.10705,     0.10404,     0.10215,    0.098714,    0.096538,    0.092901,\n",
       "           0.091104,    0.090548,    0.089946,    0.089159,    0.087412,    0.085999,    0.082743,    0.081632,    0.079818,    0.077159,    0.074592,    0.069263,     0.06809,    0.066295,     0.06496,    0.062581,    0.061975,    0.061628,     0.06128,    0.059699,    0.058759,    0.058287,    0.057792,\n",
       "           0.056895,    0.056287,    0.055744,    0.053849,    0.051043,    0.050602,    0.050161,    0.048426,     0.04719,    0.044334,    0.042714,    0.041793,    0.041083,    0.040127,    0.038257,    0.036592,    0.035824,    0.032904,    0.032026,    0.031454,    0.029997,    0.029661,    0.029326,\n",
       "            0.02899,    0.028705,    0.028433,    0.028162,     0.02789,     0.02445,    0.023945,     0.02344,    0.021737,    0.020627,    0.018756,    0.018541,    0.018326,     0.01811,    0.017895,    0.017446,    0.016802,    0.016091,    0.015138,    0.012913,    0.011466,    0.010652,    0.010003,\n",
       "          0.0090766,   0.0084733,   0.0079468,   0.0070802,    0.005764,   0.0047497,   0.0038681,   0.0029161,   0.0017396,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.5550253280086177)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.52066])\n",
       "names: {0: 'Fall-Detected'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.8030888590595834), 'metrics/recall(B)': np.float64(0.8197997775305895), 'metrics/mAP50(B)': np.float64(0.8643474673505227), 'metrics/mAP50-95(B)': np.float64(0.5206562014150727), 'fitness': np.float64(0.5550253280086177)}\n",
       "save_dir: WindowsPath('runs/detect/train_lowmem3')\n",
       "speed: {'preprocess': 0.2853265850818602, 'inference': 17.805036707420676, 'loss': 0.003185205765856374, 'postprocess': 2.2390921023363264}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# حمّل آخر وزن محفوظ من التجربة السابقة\n",
    "model = YOLO('runs/detect/train_lowmem3/weights/last.pt')\n",
    "\n",
    "# استأنف التدريب (لاحظ أننا لا نحتاج لإعادة تحديد البيانات أو باقي الإعدادات لأنها محفوظة)\n",
    "model.train(resume=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5778de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using best.pt\n",
      "✅ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# المسار الكامل لمجلد الـ weights\n",
    "weights_dir = 'runs/detect/train_lowmem3/weights'\n",
    "\n",
    "# اختبر إذا best.pt موجود\n",
    "if os.path.exists(f'{weights_dir}/best.pt'):\n",
    "    weights_path = f'{weights_dir}/best.pt'\n",
    "    print('✅ Using best.pt')\n",
    "elif os.path.exists(f'{weights_dir}/last.pt'):\n",
    "    weights_path = f'{weights_dir}/last.pt'\n",
    "    print('⚠️ best.pt not found, using last.pt')\n",
    "else:\n",
    "    raise FileNotFoundError('❌ Neither best.pt nor last.pt found!')\n",
    "\n",
    "# حمّل النموذج\n",
    "model = YOLO(weights_path)\n",
    "print('✅ Model loaded successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb62393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1021-_jpg.rf.f614158e545e853dd32da630b11d0c0e.jpg: 416x416 1 Fall-Detected, 23.4ms\n",
      "image 2/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1022-_jpg.rf.5728f16ac2a94330d2e3d3c0e8b786d8.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 3/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1034-_jpg.rf.f10308af2ae6dbdffedfe7cdb64a4039.jpg: 416x416 1 Fall-Detected, 23.4ms\n",
      "image 4/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1035-_jpg.rf.a68dbc901e1ffcbd5d0971ee7912f282.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 5/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1040-_jpg.rf.59b798fbc620a0d46f83783bcb64723d.jpg: 416x416 (no detections), 22.5ms\n",
      "image 6/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1061-_jpg.rf.61a11a3281f12d2937cc71a2790f41a6.jpg: 416x416 1 Fall-Detected, 22.2ms\n",
      "image 7/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1070-_jpg.rf.9896d718b075955479493c86bfc49a8c.jpg: 416x416 1 Fall-Detected, 22.3ms\n",
      "image 8/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1081-_jpg.rf.9fb83f1ed986637521e1527fbfed3de1.jpg: 416x416 1 Fall-Detected, 22.8ms\n",
      "image 9/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-113-_jpg.rf.8765afefa5028f8cd67c26d3153c12c7.jpg: 416x416 1 Fall-Detected, 22.8ms\n",
      "image 10/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1134-_jpg.rf.764842213a3a02f2ab2a2e552e998ff5.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 11/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1176-_jpg.rf.ac7cc5fd665c4a18f03c64d952dba968.jpg: 416x416 (no detections), 22.9ms\n",
      "image 12/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1189-_jpg.rf.eea24686fe112b602ac176e6f0e5acea.jpg: 416x416 1 Fall-Detected, 23.5ms\n",
      "image 13/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1194-_jpg.rf.3ffeab5a3a0494ce241e041e23838f67.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 14/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-120-_jpg.rf.280ed0cd9d7f8a516b0a21d7fbb0678a.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 15/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1212-_jpg.rf.3dc924d18483ed29a151c8256ce3b377.jpg: 416x416 1 Fall-Detected, 22.3ms\n",
      "image 16/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1292-_jpg.rf.83d5efb85f0ee554503a9a4a80300ca4.jpg: 416x416 (no detections), 22.2ms\n",
      "image 17/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1298-_jpg.rf.a4f2330628b684b6007047b5ac5c5661.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 18/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-13-_jpg.rf.9f5e7f741b5cfbdc6a7324ea102004c1.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 19/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1346-_jpg.rf.d9b1f33de0c9106f295d64eea2e62948.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 20/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1369-_jpg.rf.33340277dc739e693daa9e84677c6c58.jpg: 416x416 1 Fall-Detected, 21.6ms\n",
      "image 21/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1405-_jpg.rf.8ef9a7e5cb996dcc2da479e6371594f9.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 22/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1410-_jpg.rf.5e25e09fed8076fcbd8079f61090e7de.jpg: 416x416 2 Fall-Detecteds, 25.2ms\n",
      "image 23/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1444-_jpg.rf.05e01cfe599d4fc37996333f2a28a99d.jpg: 416x416 1 Fall-Detected, 22.0ms\n",
      "image 24/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1457-_jpg.rf.e555ee0284d04d9e01004fbc879f35ad.jpg: 416x416 1 Fall-Detected, 21.9ms\n",
      "image 25/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1485-_jpg.rf.202616220ca4c2ab23e1c73cb9c9c539.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 26/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1498-_jpg.rf.ae1e767accd3f1d191ee5bb1eb0f1dfa.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 27/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-154-_jpg.rf.a6c9f439f09852cd0081e02e181963fb.jpg: 416x416 1 Fall-Detected, 23.2ms\n",
      "image 28/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1543-_jpg.rf.9d3fc2ae6c9d747b0988cfd241841e9c.jpg: 416x416 1 Fall-Detected, 22.0ms\n",
      "image 29/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-157-_jpg.rf.10a299eafe3602df2b91d7d14552d91b.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 30/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1589-_jpg.rf.f6a555baa10c3275135f132509a3f36f.jpg: 416x416 1 Fall-Detected, 23.6ms\n",
      "image 31/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1608-_jpg.rf.2fc049f40832468deb78949d252b61e7.jpg: 416x416 1 Fall-Detected, 21.6ms\n",
      "image 32/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-172-_jpg.rf.d01f6050103ff785e1830fdd56d1dfd8.jpg: 416x416 1 Fall-Detected, 22.0ms\n",
      "image 33/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1720-_jpg.rf.7809b9439be18447637c4ee315b151d8.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 34/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1739-_jpg.rf.0052f6e6880693fed3d04bcff3a70154.jpg: 416x416 1 Fall-Detected, 21.8ms\n",
      "image 35/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1741-_jpg.rf.53fb644ac52aa4e6ae867bf89a849ef9.jpg: 416x416 1 Fall-Detected, 22.2ms\n",
      "image 36/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1756-_jpg.rf.335b303c560567a399e9ad02291fce3b.jpg: 416x416 3 Fall-Detecteds, 22.2ms\n",
      "image 37/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1764-_jpg.rf.7737526e66bfe32426d6a1ce45b7d41e.jpg: 416x416 1 Fall-Detected, 23.9ms\n",
      "image 38/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1766-_jpg.rf.dc08ef7d5138d5f71eec8c7b0e359e76.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 39/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1780-_jpg.rf.2603514eefba78110ca45206e9c1a9d8.jpg: 416x416 1 Fall-Detected, 22.2ms\n",
      "image 40/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1791-_jpg.rf.7979d8bdc3e5f13d1483d27db3f8626e.jpg: 416x416 1 Fall-Detected, 22.3ms\n",
      "image 41/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1800-_jpg.rf.1ebeff6d125cfcb98ee2617f311f3ea4.jpg: 416x416 2 Fall-Detecteds, 22.8ms\n",
      "image 42/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1801-_jpg.rf.6f0b13c10095bc7fd839054628b48d45.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 43/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1804-_jpg.rf.36f3e5a364daa3295e5072a45e045867.jpg: 416x416 1 Fall-Detected, 22.1ms\n",
      "image 44/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1847-_jpg.rf.2f64fd457d008e5d8e621b1ea598dbd8.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 45/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1849-_jpg.rf.4339c81b7ec717f58d4e846523a0e1ad.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 46/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1853-_jpg.rf.d4983d732156ebddbe9ba9e9a63b692f.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 47/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1855-_jpg.rf.ee826f74f2a39df2810609f6563294cb.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 48/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1877-_jpg.rf.5d08046f22db1df635da0e791338dc3e.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 49/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1889-_jpg.rf.c82d16b7b81aebf7dcbd6ceadeba8890.jpg: 416x416 2 Fall-Detecteds, 23.1ms\n",
      "image 50/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1903-_jpg.rf.7778d7e610ab83db03ab31321cc71e7c.jpg: 416x416 (no detections), 23.8ms\n",
      "image 51/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-193-_jpg.rf.18fe94c0253f1cf0e225c1e07e69dac7.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 52/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1930-_jpg.rf.762a8fbc253d6e0736802569a84b1354.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 53/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1931-_jpg.rf.f38ccdc3761edbaedc6fcb1956c70419.jpg: 416x416 1 Fall-Detected, 22.3ms\n",
      "image 54/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1936-_jpg.rf.a67d3f249e45efacd70fbc576a6e867f.jpg: 416x416 2 Fall-Detecteds, 22.5ms\n",
      "image 55/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1943-_jpg.rf.494e57a0679f661e11ae3872b4a13d3b.jpg: 416x416 1 Fall-Detected, 23.1ms\n",
      "image 56/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1961-_jpg.rf.81eb3ad9d70855d54e99cc624e45c481.jpg: 416x416 1 Fall-Detected, 21.6ms\n",
      "image 57/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1993-_jpg.rf.6caeb54fdf941bd5611a39de7cde6fe6.jpg: 416x416 1 Fall-Detected, 22.2ms\n",
      "image 58/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1995-_jpg.rf.e4435bbe937671f6ae87a09ed3eaec37.jpg: 416x416 1 Fall-Detected, 21.9ms\n",
      "image 59/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-1998-_jpg.rf.1b308f4ba689aafec11d5934843629e2.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 60/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2001-_jpg.rf.273f6a289e3df986d585a380926592ac.jpg: 416x416 1 Fall-Detected, 23.2ms\n",
      "image 61/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2004-_jpg.rf.20a5c1f341b3c29a975ff009eac01f02.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 62/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2035-_jpg.rf.d57c19dcfee03f519adb1b2a9eedd53b.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 63/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2095-_jpg.rf.cd607031980fdeabe395de913937a947.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 64/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2096-_jpg.rf.902c7da503b45c3f58289d28a073bb20.jpg: 416x416 1 Fall-Detected, 22.9ms\n",
      "image 65/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2112-_jpg.rf.2edccd60e0d5f33b8f4a28f3587267bb.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 66/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2116-_jpg.rf.bda71bf15f5c013901da17bf2a14be88.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 67/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2171-_jpg.rf.47cd25b79b7e0b8c11007eb523c82f35.jpg: 416x416 1 Fall-Detected, 23.1ms\n",
      "image 68/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2172-_jpg.rf.a6b120680f1187749963f273c94525a5.jpg: 416x416 1 Fall-Detected, 22.7ms\n",
      "image 69/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2179-_jpg.rf.1a87ca06efcd722aa8a17db4aeb2a925.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 70/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-218-_jpg.rf.86d60b0180c87990f3f6c76de21fbd0a.jpg: 416x416 (no detections), 22.6ms\n",
      "image 71/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2232-_jpg.rf.e438a3561f326ce9c5a857c56d2f1821.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 72/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2242-_jpg.rf.1610961b5b19f4788ea2586d6c69a3c2.jpg: 416x416 2 Fall-Detecteds, 22.6ms\n",
      "image 73/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-229-_jpg.rf.a4b68c5f1f86cf7a817aea2392a6a46d.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 74/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2290-_jpg.rf.6b051c038cbc695a1c545e36e09e025e.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 75/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2296-_jpg.rf.b3b7f7bbe7dffc857af4c5956dd97492.jpg: 416x416 1 Fall-Detected, 22.7ms\n",
      "image 76/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-230-_jpg.rf.cf14af3ba25c74b599ef31f9a71daf33.jpg: 416x416 1 Fall-Detected, 22.5ms\n",
      "image 77/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2342-_jpg.rf.8faba5163bf9991285204dfb96dff2f5.jpg: 416x416 (no detections), 22.8ms\n",
      "image 78/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2354-_jpg.rf.f6cc8b22fe9a32963dc6a6dd0068fd80.jpg: 416x416 1 Fall-Detected, 22.4ms\n",
      "image 79/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2357-_jpg.rf.636ba523c9870b9c7f477ce51f1ee63e.jpg: 416x416 1 Fall-Detected, 21.5ms\n",
      "image 80/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2366-_jpg.rf.bada021473cf2494649bd12328761fea.jpg: 416x416 1 Fall-Detected, 22.7ms\n",
      "image 81/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2375-_jpg.rf.bcbbe136dea73d1b339bdd70525a7128.jpg: 416x416 1 Fall-Detected, 22.9ms\n",
      "image 82/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-239-_jpg.rf.f5affbb588946970c5438bc823e7dd06.jpg: 416x416 1 Fall-Detected, 24.2ms\n",
      "image 83/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2390-_jpg.rf.325f22d85d1613b05d47cf071c395e0b.jpg: 416x416 2 Fall-Detecteds, 23.7ms\n",
      "image 84/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2411-_jpg.rf.a88cbbaf4e142389e4554dc12f41b10c.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 85/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2415-_jpg.rf.7bca07a14f2992ee45d1ad9677200ccc.jpg: 416x416 1 Fall-Detected, 23.1ms\n",
      "image 86/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2501-_jpg.rf.ca0fa649b548844ab77b019619a4ca57.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 87/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2512-_jpg.rf.eddf97c59b36eee21d69a1c5e5238754.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 88/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2514-_jpg.rf.312f6424f1e334736014e3ea49c8c18d.jpg: 416x416 (no detections), 24.7ms\n",
      "image 89/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2520-_jpg.rf.3ceba2a7f7c85e9f8ec8e45450e4e569.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 90/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2525-_jpg.rf.a33ef052ec58c7da9693c4692a3ac49e.jpg: 416x416 2 Fall-Detecteds, 23.1ms\n",
      "image 91/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2549-_jpg.rf.dfb6aadbaf91e5e49a055ea21d265292.jpg: 416x416 1 Fall-Detected, 23.1ms\n",
      "image 92/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2584-_jpg.rf.b9e4c10b13ae0af3b0639e8594f94d2e.jpg: 416x416 1 Fall-Detected, 22.9ms\n",
      "image 93/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2592-_jpg.rf.2d9420afb27a749276f8c37f87f0717e.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 94/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2608-_jpg.rf.19c4d695824c7e55871b202574476132.jpg: 416x416 1 Fall-Detected, 23.2ms\n",
      "image 95/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2610-_jpg.rf.d8b81b5ba8e8891d5641cc1b2ee750b1.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 96/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2622-_jpg.rf.565811e534e699a25e78e7092e3be8cd.jpg: 416x416 (no detections), 23.9ms\n",
      "image 97/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2638-_jpg.rf.5c66bde1fd3461028f1769cc266022cc.jpg: 416x416 3 Fall-Detecteds, 23.7ms\n",
      "image 98/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2658-_jpg.rf.8255de252d4e324f2a367df9861f950d.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 99/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2664-_jpg.rf.78b28b422806e6a1f02d03bdcdc818cc.jpg: 416x416 (no detections), 23.7ms\n",
      "image 100/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2666-_jpg.rf.1c5393174ceea8922574aa80a17365f7.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 101/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2672-_jpg.rf.fa0458c96796af3d36a8f09d514c19a3.jpg: 416x416 1 Fall-Detected, 23.2ms\n",
      "image 102/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2710-_jpg.rf.f1f8f50ff0a0e852e0f2afbad356ebc7.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 103/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2724-_jpg.rf.8cf4355b497d854df40f05473ce66861.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 104/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2728-_jpg.rf.25822b63187929e39966d5ccc8ed9342.jpg: 416x416 1 Fall-Detected, 23.6ms\n",
      "image 105/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2735-_jpg.rf.dd457eaacbdb7342a3dca3219139cbec.jpg: 416x416 1 Fall-Detected, 23.0ms\n",
      "image 106/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2739-_jpg.rf.a505504a6efb2f956315e425ff81fcae.jpg: 416x416 2 Fall-Detecteds, 23.2ms\n",
      "image 107/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-274-_jpg.rf.3b2572b850c87b7e4e44e526a4206f37.jpg: 416x416 (no detections), 24.3ms\n",
      "image 108/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2742-_jpg.rf.ea78bd7cf366f118229ec27bcd323220.jpg: 416x416 1 Fall-Detected, 23.5ms\n",
      "image 109/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2772-_jpg.rf.01751a885e3075872113c15f5ad09088.jpg: 416x416 1 Fall-Detected, 22.6ms\n",
      "image 110/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2782-_jpg.rf.aac82d692bbb608519582819f8ebef65.jpg: 416x416 1 Fall-Detected, 23.4ms\n",
      "image 111/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2789-_jpg.rf.a2648d9c045c1dd30c728582a114f826.jpg: 416x416 (no detections), 22.4ms\n",
      "image 112/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2798-_jpg.rf.22756e273079aa13b4c5648181addc97.jpg: 416x416 (no detections), 23.2ms\n",
      "image 113/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2800-_jpg.rf.dbbd8c3e12c6c4cb45ce0aa99c7cc337.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 114/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2811-_jpg.rf.7f64912b331347f25d296b3ca252b1b4.jpg: 416x416 1 Fall-Detected, 23.7ms\n",
      "image 115/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2819-_jpg.rf.6113ba000111096bdf66dff3df48188b.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 116/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2833-_jpg.rf.8e39602731ec3b8625f8c46eb9b54c2f.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 117/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-284-_jpg.rf.66d0bbd2b4eb7651cbc4a61d399be891.jpg: 416x416 1 Fall-Detected, 23.9ms\n",
      "image 118/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2862-_jpg.rf.61ae22be27d27449ed8be878a770c9a1.jpg: 416x416 1 Fall-Detected, 23.9ms\n",
      "image 119/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2879-_jpg.rf.74469e0862425e099759beccef70f60c.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 120/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2895-_jpg.rf.d2469f8c72699973726c6abe55b75cdd.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 121/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2903-_jpg.rf.311abfa9b0bb2c18d769e89491f2c37a.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 122/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2910-_jpg.rf.f22c5dd587d87cb51d40ffc035476af0.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 123/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2925-_jpg.rf.c9933b25bf46518a39d94e967f8c190f.jpg: 416x416 1 Fall-Detected, 24.4ms\n",
      "image 124/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2950-_jpg.rf.938b277fdeb49e996aada62f93928a3c.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 125/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2981-_jpg.rf.fb5c900851394248a914bc58bd1a6261.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 126/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-2985-_jpg.rf.5ccfa6ec925efc38c7e293e1639d900a.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 127/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3002-_jpg.rf.97f717b76e59954171d39801069ef0d5.jpg: 416x416 (no detections), 25.6ms\n",
      "image 128/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3040-_jpg.rf.079be975881ed042c00072fc069237c6.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 129/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3043-_jpg.rf.dc135e26fd368d68b817b83ece3fa5eb.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 130/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-306-_jpg.rf.de10d351ea690494ae3bfa9d0adf35ae.jpg: 416x416 1 Fall-Detected, 24.2ms\n",
      "image 131/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3066-_jpg.rf.1068a6baf255ac21b5f781c38cf14136.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 132/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3082-_jpg.rf.f1420bfe2ef8bc54b91bc5396ff38d03.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 133/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3088-_jpg.rf.ae7e7e49d94613faa0780c4f2a0c172c.jpg: 416x416 (no detections), 24.0ms\n",
      "image 134/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3096-_jpg.rf.13bbd9042bd9324b5079b46ce9a1a0b0.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 135/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3098-_jpg.rf.9736d7377dbd27ad8fcb8bf747844d0e.jpg: 416x416 1 Fall-Detected, 23.9ms\n",
      "image 136/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3119-_jpg.rf.7441a473671e6c9eed336d55bbbcd144.jpg: 416x416 2 Fall-Detecteds, 22.9ms\n",
      "image 137/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3139-_jpg.rf.9e426ea389d13c4f728d107ca1bf38c8.jpg: 416x416 1 Fall-Detected, 23.3ms\n",
      "image 138/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3144-_jpg.rf.694e9a4b7bdff37832fb88fee78f4885.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 139/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-317-_jpg.rf.6e15856450af06d3c0641faa676bafe7.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 140/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3216-_jpg.rf.4048fd59accdf8000f951257d063dffd.jpg: 416x416 1 Fall-Detected, 23.8ms\n",
      "image 141/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3217-_jpg.rf.8a7f594ef1de8f8a9ac404b6d1f0c0c0.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 142/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3218-_jpg.rf.2c6b5606a745abda283cc27585be0aa3.jpg: 416x416 1 Fall-Detected, 24.2ms\n",
      "image 143/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-324-_jpg.rf.2cab804ae2f3c1745edccb066471262d.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 144/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3262-_jpg.rf.544346fc134ee55134da691c67b4946a.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 145/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3315-_jpg.rf.30c29ec9b01bd8284ddba3ee1df86801.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 146/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3317-_jpg.rf.b82b479d39369ac0b9660f8c86c454e1.jpg: 416x416 1 Fall-Detected, 23.1ms\n",
      "image 147/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3349-_jpg.rf.a60bffdff6a0f79510d321b74c8edcd8.jpg: 416x416 1 Fall-Detected, 24.3ms\n",
      "image 148/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-336-_jpg.rf.4935523d4141bab73a59141c8174c779.jpg: 416x416 1 Fall-Detected, 23.4ms\n",
      "image 149/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3362-_jpg.rf.114e998c7c61b0d4e20cc75cf4065058.jpg: 416x416 1 Fall-Detected, 23.5ms\n",
      "image 150/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3379-_jpg.rf.07c32ea227549048de4d34f65663768b.jpg: 416x416 1 Fall-Detected, 24.4ms\n",
      "image 151/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3395-_jpg.rf.8c7c13d784fad35a202c61ed03395888.jpg: 416x416 1 Fall-Detected, 23.6ms\n",
      "image 152/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-34-_jpg.rf.30a0f5324d5e5ea66b46ecba6f37c219.jpg: 416x416 (no detections), 23.7ms\n",
      "image 153/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3440-_jpg.rf.18b42bfbc1734bbf2ebf1e9b412e864a.jpg: 416x416 1 Fall-Detected, 24.0ms\n",
      "image 154/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3461-_jpg.rf.40c3d48c9390ff58edeba2f4f688d892.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 155/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-347-_jpg.rf.f75206ccf30afbedfa8a27c18f9f978f.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 156/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3477-_jpg.rf.846146b2496fc8d6c37269485205be85.jpg: 416x416 (no detections), 25.6ms\n",
      "image 157/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3481-_jpg.rf.e73786f2fdbae168a194710b401752fd.jpg: 416x416 2 Fall-Detecteds, 25.3ms\n",
      "image 158/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3503-_jpg.rf.ab419c9cd4b81db23d228fd1fa03e8c7.jpg: 416x416 (no detections), 25.2ms\n",
      "image 159/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3530-_jpg.rf.949e7c6b279ca83c02c1f44736c48703.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 160/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3533-_jpg.rf.ea2cb101c7dc6b9ee31f5acfe3785f83.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 161/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-354-_jpg.rf.76cff6c1b6c6eb9ecefc57004f6f10b9.jpg: 416x416 2 Fall-Detecteds, 25.6ms\n",
      "image 162/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3544-_jpg.rf.72ebcb0ff30f93c53da347f6e5105fec.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 163/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3567-_jpg.rf.343af20acb0926a780216bb161e191a3.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 164/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3570-_jpg.rf.0a5b2f1f79150b3fb00db4c9e45a8598.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 165/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3575-_jpg.rf.10278bab53f086466e1dd0270b5b7529.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 166/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3586-_jpg.rf.2a2c0150aae933a712be8a5cc306bdbc.jpg: 416x416 1 Fall-Detected, 24.4ms\n",
      "image 167/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3590-_jpg.rf.664a034dd79b0e75b9830019a1ba5737.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 168/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3592-_jpg.rf.1e45e6ecac1b622acc44a0ccb0f5768c.jpg: 416x416 (no detections), 26.5ms\n",
      "image 169/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3593-_jpg.rf.b5420c971862d55c39d108206d0ddb6e.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 170/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3598-_jpg.rf.fcad989a4c6c7647e8a3525418067520.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 171/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3609-_jpg.rf.4061640267de25df452b6d1b34f206b6.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 172/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3611-_jpg.rf.306ed8fe374d64c4fbb290001db231d0.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 173/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3614-_jpg.rf.bf7415a5aaa0ad8eeb848979135434ec.jpg: 416x416 2 Fall-Detecteds, 26.0ms\n",
      "image 174/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3624-_jpg.rf.fbb085f1783638730469810c12e4ed18.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 175/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3653-_jpg.rf.8716df11ffc66915f084edd289c89d39.jpg: 416x416 (no detections), 24.5ms\n",
      "image 176/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3678-_jpg.rf.37a4ee7cb767bbcb22ec23bbc9c71895.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 177/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3686-_jpg.rf.23949bddefce365848ef58ade265d15a.jpg: 416x416 2 Fall-Detecteds, 25.2ms\n",
      "image 178/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3688-_jpg.rf.1858812a09fa463e25d0e506d27835e9.jpg: 416x416 2 Fall-Detecteds, 25.0ms\n",
      "image 179/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3689-_jpg.rf.417ceada2bf71bc956c86efff39b7d4f.jpg: 416x416 2 Fall-Detecteds, 25.6ms\n",
      "image 180/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3695-_jpg.rf.b860c86008e104ec960b0cb4c8dc781d.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 181/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3697-_jpg.rf.61b05eea2bbf3e13d67c4ac92913ca6b.jpg: 416x416 2 Fall-Detecteds, 25.8ms\n",
      "image 182/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3706-_jpg.rf.b7691ca2350b01258b87e3886ff0ffc6.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 183/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3714-_jpg.rf.4b7b0d4dd5c376a074387e941324d770.jpg: 416x416 (no detections), 25.5ms\n",
      "image 184/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-372-_jpg.rf.b23d1185892ad006599a2573ba27d82c.jpg: 416x416 1 Fall-Detected, 26.4ms\n",
      "image 185/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3743-_jpg.rf.1a9833447262db1f470dd8e3922a9f36.jpg: 416x416 2 Fall-Detecteds, 25.4ms\n",
      "image 186/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3752-_jpg.rf.0abd8b131e147bd950b9c151ce226dd1.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 187/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3759-_jpg.rf.0f0ab2d54eb65268363e948e759f4442.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 188/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3796-_jpg.rf.ec59cf918a49c61527de62b803cbb8a7.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 189/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3803-_jpg.rf.64c5e3b7f5454c07533ad49b70979e63.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 190/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3810-_jpg.rf.07ec995a1de96a33101099cbc0faca01.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 191/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3848-_jpg.rf.7f9f7500ff1922eb1c9d8e693df71dbf.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 192/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3849-_jpg.rf.1e2703cbdc8e79200dfc225f3742ef68.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 193/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-386-_jpg.rf.af004881b3310e1dc614940f407943dd.jpg: 416x416 1 Fall-Detected, 24.1ms\n",
      "image 194/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3927-_jpg.rf.9858cfd44abdb233930b8bbdfa6ef6b6.jpg: 416x416 1 Fall-Detected, 26.4ms\n",
      "image 195/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3950-_jpg.rf.14d5a336d973ff2e3e02a812f2af8e55.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 196/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3955-_jpg.rf.f4270088b08d7fd1229039e3d0f0c392.jpg: 416x416 1 Fall-Detected, 24.1ms\n",
      "image 197/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3961-_jpg.rf.a738f67fab9629ee436be38c9d5aaab4.jpg: 416x416 1 Fall-Detected, 24.4ms\n",
      "image 198/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3974-_jpg.rf.980b271bb96e1b78548a683145d98b69.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 199/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-3998-_jpg.rf.b8cfc59512085a26df95fa72614ef2c2.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 200/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4033-_jpg.rf.10a95491c745c00569d8736d348bed27.jpg: 416x416 2 Fall-Detecteds, 28.2ms\n",
      "image 201/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4090-_jpg.rf.58988573d582adf8dd9867df3c29ac96.jpg: 416x416 (no detections), 24.3ms\n",
      "image 202/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4157-_jpg.rf.a565e09beb6d926e4c505b757d09b2ac.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 203/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4171-_jpg.rf.99d68075110d7425b07094dfc0b57b7c.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 204/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4180-_jpg.rf.65a2c6f301715f71e1d3f2d187426039.jpg: 416x416 1 Fall-Detected, 24.1ms\n",
      "image 205/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-430-_jpg.rf.71ae478df2b4a63fec9bc074617504b4.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 206/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4366-_jpg.rf.bdeee3d1290a8124d8b66c4cb505c05c.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 207/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4371-_jpg.rf.1516923b92745c64dffac804d520fd85.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 208/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4376-_jpg.rf.6d71ce8e92f840b1daa189b83ab81e9f.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 209/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4378-_jpg.rf.8d65cdbbaff5ff1d8479613577980f91.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 210/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4381-_jpg.rf.36658c75b356b8f6ea4251dae808c2ff.jpg: 416x416 1 Fall-Detected, 27.8ms\n",
      "image 211/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4405-_jpg.rf.3a70609696cb4ab65ff6cca065a36388.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 212/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4411-_jpg.rf.af937d47c08a1272dc6f3d8569563014.jpg: 416x416 1 Fall-Detected, 24.3ms\n",
      "image 213/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4459-_jpg.rf.aa81d76e7eda517f08b4ac4c272b9aaf.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 214/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4490-_jpg.rf.6a2b44a2d29f09c02bff0ed1ebb8e7e6.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 215/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4524-_jpg.rf.6bbb23de59003faf5d5b9bc09b4660ea.jpg: 416x416 (no detections), 27.7ms\n",
      "image 216/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4535-_jpg.rf.ef39a8575a3025e43685e0bbdfcf9367.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 217/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4549-_jpg.rf.189beb582ce63bda81fbe91a1f7be0bc.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 218/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4566-_jpg.rf.200a353916cf1927e12e33c6ce69eda8.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 219/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4669-_jpg.rf.d0935c4fa50f9e6dd5e62e056123cf3e.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 220/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4687-_jpg.rf.11358d1e338ced2bd2082436af93b2b7.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 221/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-469-_jpg.rf.3265a5ee6b8b874b222bf4a33f98dd86.jpg: 416x416 1 Fall-Detected, 25.1ms\n",
      "image 222/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4694-_jpg.rf.699ec00ed33e3e85b7047aefe0c641b3.jpg: 416x416 1 Fall-Detected, 26.6ms\n",
      "image 223/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-473-_jpg.rf.e4ebf1ff3799cd93176353ae1d30de4e.jpg: 416x416 2 Fall-Detecteds, 25.3ms\n",
      "image 224/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4746-_jpg.rf.bc3deb9513f0a30056266b3ad5e8ce33.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 225/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4754-_jpg.rf.e13c403030e0eed30ecbb7d930818775.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 226/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4761-_jpg.rf.bdc8ef85727fc4311f2d5a644ec3d926.jpg: 416x416 (no detections), 24.8ms\n",
      "image 227/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4765-_jpg.rf.8c4365cf14514f22cc3e02c290cfcbdd.jpg: 416x416 1 Fall-Detected, 27.9ms\n",
      "image 228/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4772-_jpg.rf.2288ab70e9a12de65dcb46ae0b150eb5.jpg: 416x416 1 Fall-Detected, 26.6ms\n",
      "image 229/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4779-_jpg.rf.bfb2400103f51ee8734cc02a0d070f62.jpg: 416x416 2 Fall-Detecteds, 25.3ms\n",
      "image 230/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4848-_jpg.rf.49da7225bacb2404bbd641ebe43dabe6.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 231/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4866-_jpg.rf.e7f0794b02d2c993ebaebb695e1777e8.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 232/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4873-_jpg.rf.3b21edb5891d926cb0b7b498d0c4dd2b.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 233/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4904-_jpg.rf.7701d6ca16ea9fb5b3f14631935c9df2.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 234/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4918-_jpg.rf.be277f3e9f517dce29f0004a230283e7.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 235/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-492-_jpg.rf.1b5dd3b55018d7e8c4671954aafa7cac.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 236/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4921-_jpg.rf.eee2150084972224b31dc6d79af8b7b5.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 237/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4924-_jpg.rf.a7266b9449172a8fc72cbb9788dd39b8.jpg: 416x416 1 Fall-Detected, 23.6ms\n",
      "image 238/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4941-_jpg.rf.927333c9357b6da23bc92683704893ca.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 239/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4942-_jpg.rf.18a02562e9fe7eff9f5b799d8498effe.jpg: 416x416 2 Fall-Detecteds, 24.7ms\n",
      "image 240/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4945-_jpg.rf.29f9c23b0157fe4178c0b6f80bdc7094.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 241/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4984-_jpg.rf.1e3643934213ce3c22ecec04d480dc44.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 242/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-4993-_jpg.rf.7063eaad07ef1b4df215a9c5f73dd0d8.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 243/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-500-_jpg.rf.722e851281acf444b5ef24773311212e.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 244/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5015-_jpg.rf.e346dd4a4585ebb98e660a7120626861.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 245/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5016-_jpg.rf.c2c8c3c716de05b2ba37de2279059975.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 246/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5026-_jpg.rf.1a5f6f6755fada1abaa95c16670f60d8.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 247/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5036-_jpg.rf.82146f85dc2febc02ce2982990c96f89.jpg: 416x416 (no detections), 24.6ms\n",
      "image 248/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-504-_jpg.rf.f1421e47410ce114e825f337fac07e95.jpg: 416x416 1 Fall-Detected, 24.1ms\n",
      "image 249/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5049-_jpg.rf.f09e587cc68a581a5b0515460b862401.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 250/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5055-_jpg.rf.3e2a0aa8ace94d374df43086102deb0c.jpg: 416x416 1 Fall-Detected, 26.8ms\n",
      "image 251/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5099-_jpg.rf.11e0e2f817fddf44539204f0d3564714.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 252/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5166-_jpg.rf.a5a3ef088056fa69608427deb7bd4cf5.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 253/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5183-_jpg.rf.ee0befe5c45502a45dae26daca567495.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 254/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5200-_jpg.rf.0980e3102d7213819736475c5532c6bf.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 255/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5251-_jpg.rf.5ca20e76fb6e2fccb80e5c26d7eee5a9.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 256/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-526-_jpg.rf.ce344a1cd41fcb140d2e6d1c447d12b9.jpg: 416x416 2 Fall-Detecteds, 27.3ms\n",
      "image 257/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5272-_jpg.rf.cd8eea99a7deb27f6ed7ea214b8be37e.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 258/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5278-_jpg.rf.70f9059ea6783eefd9e0d658bbdc1fdd.jpg: 416x416 1 Fall-Detected, 26.8ms\n",
      "image 259/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5306-_jpg.rf.163539abb312f0339dca9a25a0a2444b.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 260/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-533-_jpg.rf.4ba76a48ec677c7996102bf5a049ae44.jpg: 416x416 1 Fall-Detected, 26.7ms\n",
      "image 261/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5332-_jpg.rf.40bbc2cb1d99492584fdce9a5726b0f8.jpg: 416x416 1 Fall-Detected, 25.1ms\n",
      "image 262/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5338-_jpg.rf.a8edd69a8cf89657f5978848bfcba929.jpg: 416x416 (no detections), 25.3ms\n",
      "image 263/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5366-_jpg.rf.859888b499543782ce7756e36e2ed4ad.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 264/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5369-_jpg.rf.61a47e53e9974b0672bea0d053c7fa72.jpg: 416x416 3 Fall-Detecteds, 25.1ms\n",
      "image 265/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-545-_jpg.rf.6ca92078ce0766bc90f71a5c8b35dd1c.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 266/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5484-_jpg.rf.4d3c26bf06457ae80287024b3dc6ba34.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 267/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-556-_jpg.rf.ec11f3ebd3e38dddc9a42412ba83f36d.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 268/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-574-_jpg.rf.1ef62ee7fdfb64f31a05f7fe5b60251d.jpg: 416x416 1 Fall-Detected, 24.4ms\n",
      "image 269/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-576-_jpg.rf.fdc8c5d5a60c432a4353dfdd7e331982.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 270/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5841-_jpg.rf.5dcb1de7af9af06e1349ada9e09dfd15.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 271/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5854-_jpg.rf.28b1658ef034a69f88b2b83817f2b3e3.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 272/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5872-_jpg.rf.7ce3a71f093024d6b3a205de7dbfa485.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 273/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-588-_jpg.rf.80c53ea33a68d70d1b73deb224faf5eb.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 274/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5895-_jpg.rf.4b33e8070a32d1d10d991b221a1454cd.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 275/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5897-_jpg.rf.075ee7c0e781528b10eaedc13e012290.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 276/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5906-_jpg.rf.5c5651b88020cb422284f660c3bcdac3.jpg: 416x416 2 Fall-Detecteds, 24.7ms\n",
      "image 277/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5912-_jpg.rf.305a0e07ed1cc0e022ad5f89b2cb534f.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 278/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5917-_jpg.rf.a851447a1b9984d405115ad6c3b3dd1e.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 279/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5928-_jpg.rf.bbb670c9572fd88f2d65e0a770257c67.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 280/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5938-_jpg.rf.2c8a5f3096cb2456a71506a8b9a91397.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 281/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5947-_jpg.rf.945335f851af05c5f1db32e4281459a8.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 282/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5972-_jpg.rf.2d581d420bded24efd8972214593aabb.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 283/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5979-_jpg.rf.8994c218ffe7661d3606c82ad3a0710d.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 284/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5989-_jpg.rf.47670e9f60c54eb696806650105c1f47.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 285/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5997-_jpg.rf.dd2c8a44082ba4a9ebc362a9f4d7d810.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 286/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-5998-_jpg.rf.f536f86a6bd9c9006bb8f851b309fc0f.jpg: 416x416 1 Fall-Detected, 26.7ms\n",
      "image 287/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6053-_jpg.rf.1ec6869fbcb57c1c4ce2c6f5180dafe0.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 288/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6083-_jpg.rf.dde5447157af0b8f0b3e77d21011f31c.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 289/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6089-_jpg.rf.69163c57a4f63101820f146d1710258c.jpg: 416x416 2 Fall-Detecteds, 26.6ms\n",
      "image 290/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6099-_jpg.rf.ddef49f4e6df381565fb048135ca885f.jpg: 416x416 1 Fall-Detected, 27.2ms\n",
      "image 291/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6106-_jpg.rf.ea2b755db7d9b263df3cd33f6754c252.jpg: 416x416 1 Fall-Detected, 28.2ms\n",
      "image 292/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6115-_jpg.rf.0e5fa28a3ef6d0399cd2ea98e56e01e8.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 293/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-612-_jpg.rf.244c172e2fdf737139dd3f26d5fd412f.jpg: 416x416 1 Fall-Detected, 27.3ms\n",
      "image 294/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6121-_jpg.rf.6adf80756bc5cf0ff7617548994d916d.jpg: 416x416 1 Fall-Detected, 28.2ms\n",
      "image 295/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-613-_jpg.rf.335ff74c0ed909b9834a00f738f0b00b.jpg: 416x416 1 Fall-Detected, 27.4ms\n",
      "image 296/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6136-_jpg.rf.44b22506d7af11bd64c5551675c5e506.jpg: 416x416 1 Fall-Detected, 27.6ms\n",
      "image 297/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6143-_jpg.rf.6fece30fc20f59848fb6ec9009ff9205.jpg: 416x416 1 Fall-Detected, 26.9ms\n",
      "image 298/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6161-_jpg.rf.3be06b2fe420acb73f76a642239f8439.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 299/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6189-_jpg.rf.5df94851c428bfdebbe96fd8742cc261.jpg: 416x416 1 Fall-Detected, 27.8ms\n",
      "image 300/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6205-_jpg.rf.4dde2015485eb3309ba4fea14cb8387e.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 301/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6207-_jpg.rf.6b508d40d03f19d2bc6db963d23c8086.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 302/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6222-_jpg.rf.e21401484162915959b3b6e450f6d765.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "image 303/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6233-_jpg.rf.7fd7ea79d1596d8119ef4ad766f342f2.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "image 304/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6237-_jpg.rf.5285a394dd5deafaa1f4676732961208.jpg: 416x416 1 Fall-Detected, 28.6ms\n",
      "image 305/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6241-_jpg.rf.6135898e640d653f34cb17901de1e9c3.jpg: 416x416 1 Fall-Detected, 28.9ms\n",
      "image 306/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6255-_jpg.rf.4b4ad3c3802c1d99085a0eb7d1e07590.jpg: 416x416 1 Fall-Detected, 29.0ms\n",
      "image 307/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-626-_jpg.rf.f3d0cf839bb30fe49c6a18fa17d7278d.jpg: 416x416 1 Fall-Detected, 29.1ms\n",
      "image 308/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6272-_jpg.rf.475fea0354b1bc9c5293f17d2ef54e72.jpg: 416x416 1 Fall-Detected, 29.6ms\n",
      "image 309/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6287-_jpg.rf.57795071bf0303f78358cfe8022a7f49.jpg: 416x416 (no detections), 26.5ms\n",
      "image 310/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6329-_jpg.rf.162483f334b043227ecb9a5d1b892490.jpg: 416x416 (no detections), 26.3ms\n",
      "image 311/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6330-_jpg.rf.5a4dd968a4aaec2124f3f00103b55394.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 312/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6331-_jpg.rf.03b334036392280d158138375fbe43f0.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 313/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6336-_jpg.rf.7d266dc875c44fface86f67ddfd45cef.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 314/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6341-_jpg.rf.df944298fddee4fd6dbf57823e6bf748.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 315/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6351-_jpg.rf.137ce93021855900b8abc39b5441bd22.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 316/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6416-_jpg.rf.baa1a73ac6cd2187d84e8e7fee35bd4f.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 317/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-644-_jpg.rf.71c1732ff713a40cb6db7e2918a45bce.jpg: 416x416 1 Fall-Detected, 26.4ms\n",
      "image 318/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6481-_jpg.rf.6607514164d9cff3cad3548e0db36ce4.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 319/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6489-_jpg.rf.b9116df820189e2c7dc2004db7d9ae37.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 320/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6495-_jpg.rf.7c4b2aa107b6454fa3961846e45daa5e.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 321/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6517-_jpg.rf.57fdb285a243e361fae031326a96f1b4.jpg: 416x416 (no detections), 27.3ms\n",
      "image 322/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6518-_jpg.rf.e095e0feb73475aaef009c42e407e3c2.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 323/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6525-_jpg.rf.cea7bc3f2b9a53d4781a84fd256b1f64.jpg: 416x416 1 Fall-Detected, 26.9ms\n",
      "image 324/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-656-_jpg.rf.c63a728b7cc09aa0f7782261e31cf406.jpg: 416x416 2 Fall-Detecteds, 26.0ms\n",
      "image 325/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6573-_jpg.rf.887c6fc236940a88658c1cc6702c7222.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 326/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6578-_jpg.rf.714141543b38f4bce1c91b4153dbdbf7.jpg: 416x416 (no detections), 27.4ms\n",
      "image 327/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6588-_jpg.rf.cded2a87024518c5dd56fa82650a1771.jpg: 416x416 2 Fall-Detecteds, 27.4ms\n",
      "image 328/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6606-_jpg.rf.197d2e589a431e802cae960db1e5f334.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 329/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6617-_jpg.rf.b3e38319087d17d31707fa2878ded577.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 330/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6637-_jpg.rf.abdfe8a8b08a0a0719744b00dcc87521.jpg: 416x416 1 Fall-Detected, 27.6ms\n",
      "image 331/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6644-_jpg.rf.1e0b776ea22f93f6f3eea166fbb9b491.jpg: 416x416 2 Fall-Detecteds, 26.1ms\n",
      "image 332/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6660-_jpg.rf.40ec6565962c504c76458e0c2c48cf43.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 333/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6679-_jpg.rf.5aa17186af5653f4e342e07fefb29be6.jpg: 416x416 (no detections), 27.2ms\n",
      "image 334/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6684-_jpg.rf.7bee321d008dc559a827d0b9abaab332.jpg: 416x416 2 Fall-Detecteds, 27.7ms\n",
      "image 335/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6698-_jpg.rf.4d8ea015c0c463c0a27781ec6fd3cf33.jpg: 416x416 1 Fall-Detected, 27.4ms\n",
      "image 336/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6718-_jpg.rf.cc52ba6d32c7075410f7c69088809410.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "image 337/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6736-_jpg.rf.3468675997235ad1aefe45a6a4e525ce.jpg: 416x416 1 Fall-Detected, 29.1ms\n",
      "image 338/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6762-_jpg.rf.788e6054c75b7c23fcdfe2b3e8757c2a.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "image 339/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6766-_jpg.rf.9c2720fa6ec142016a88fbe9a7edd8a1.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 340/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6775-_jpg.rf.90f71a1b12d384ca9e0978a58035050f.jpg: 416x416 (no detections), 25.9ms\n",
      "image 341/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6783-_jpg.rf.8cbbccc5d65352cef7cc3a2f472b8495.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 342/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6793-_jpg.rf.f587b6cf19fdbbad2e3766f55918e7a3.jpg: 416x416 3 Fall-Detecteds, 25.9ms\n",
      "image 343/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6823-_jpg.rf.1dd4dfcbdfc543b2b98856dd87815f8d.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 344/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6829-_jpg.rf.2561a4a1b3962b8d9b53a63210fd9dde.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 345/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6864-_jpg.rf.64fe604a6ec0b144922bb7ac9269ed47.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 346/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6885-_jpg.rf.770ba674d10e1655ae49a40d0cc77e6d.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 347/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6887-_jpg.rf.fdfd63d875f0cafa0f684fb580550b49.jpg: 416x416 (no detections), 25.9ms\n",
      "image 348/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6892-_jpg.rf.a493dacb189048550c066cfff936a948.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 349/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6895-_jpg.rf.18bcbcbd492522da22acf1898f234f95.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 350/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6935-_jpg.rf.04ce6127ddca812d9f63313f826c1b8a.jpg: 416x416 1 Fall-Detected, 27.5ms\n",
      "image 351/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-694-_jpg.rf.a919453f9179d97c1a93333a37239a4d.jpg: 416x416 1 Fall-Detected, 26.4ms\n",
      "image 352/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6942-_jpg.rf.6ddbee2e67e3428c9d248e31c73136f2.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 353/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-6961-_jpg.rf.6051258144692f1c2f0682ad7e4966c8.jpg: 416x416 1 Fall-Detected, 27.5ms\n",
      "image 354/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7026-_jpg.rf.c05d913caf88ae7958ffef1aeb9b6751.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 355/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7032-_jpg.rf.cfa5a2da33f6c9edc69ceaece98c3903.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 356/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7051-_jpg.rf.7ce073373adef1ef04c87c801e7fab53.jpg: 416x416 2 Fall-Detecteds, 25.4ms\n",
      "image 357/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7076-_jpg.rf.8e50a59bb0955c8e6d3e663f20ccf99d.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 358/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7085-_jpg.rf.916627c0ec96ee7f0e3500256adbc396.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 359/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7096-_jpg.rf.28c76123b041fb26cc2f734af8b42e59.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 360/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7113-_jpg.rf.e8d0d44f0ed1e56d412ef1d21c30c928.jpg: 416x416 2 Fall-Detecteds, 25.9ms\n",
      "image 361/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7126-_jpg.rf.ae707ae418a0d21e33d601fed7cb1bb7.jpg: 416x416 1 Fall-Detected, 26.9ms\n",
      "image 362/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7179-_jpg.rf.bd6c992d5be1ce41249a0fbfdc6739b9.jpg: 416x416 2 Fall-Detecteds, 25.7ms\n",
      "image 363/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7210-_jpg.rf.ab3705680c0dc417bfcea99801f9e1d8.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 364/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7223-_jpg.rf.20cb06eeeca64d8a7a2e79185e13ed6a.jpg: 416x416 1 Fall-Detected, 26.8ms\n",
      "image 365/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7237-_jpg.rf.cfa17d9ff213a328d6c160d2feae211d.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 366/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7255-_jpg.rf.ca8b01284fe81821d554128a43190960.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 367/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7286-_jpg.rf.122e2092102b294878faad5614fad3a9.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 368/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7308-_jpg.rf.a0d4137c6b9aed4879c7c8610689bea4.jpg: 416x416 1 Fall-Detected, 27.8ms\n",
      "image 369/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7310-_jpg.rf.2c9e0896fab23ec7e7dfc194b8b8380d.jpg: 416x416 2 Fall-Detecteds, 25.7ms\n",
      "image 370/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7337-_jpg.rf.5d834a1b7641adce3841b81772352359.jpg: 416x416 2 Fall-Detecteds, 26.4ms\n",
      "image 371/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7343-_jpg.rf.21791db5962ce2729b41fabb247bdd5a.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 372/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7351-_jpg.rf.83e356bfca3d5bc46f263b907cd460d4.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 373/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7376-_jpg.rf.5864b892894965f93ef3819dfd2eec38.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 374/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7395-_jpg.rf.96d3bf9677a10da63d4345dc76782516.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 375/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7447-_jpg.rf.9d0db8ccb6c44f0cc571bb5cef8e2290.jpg: 416x416 1 Fall-Detected, 26.0ms\n",
      "image 376/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7450-_jpg.rf.4c6f0c2d4649fc050e18d800fc7d933a.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 377/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7485-_jpg.rf.202281ab49177afe4a9d21711616faf1.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 378/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7493-_jpg.rf.37c74f88f6b9e67cfffac9a18bbed628.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 379/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7495-_jpg.rf.ff5f297c0906824a59a6ffcc4a6d9f86.jpg: 416x416 2 Fall-Detecteds, 25.4ms\n",
      "image 380/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7520-_jpg.rf.e61ef5a6378fa6c0e8fb2186c11fefa3.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 381/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7521-_jpg.rf.ea91acf97231f1e3fa0cea657c4ca44c.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 382/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7552-_jpg.rf.f4def5e46d46379433b3aa4a1ba6f5b6.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 383/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7563-_jpg.rf.a066646f80f8e98a288ec041bf4176a4.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 384/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7620-_jpg.rf.95c41029b3cd707c5bee0d64761e2204.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 385/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7630-_jpg.rf.30a52d5511546accc51a92b0d0782bc0.jpg: 416x416 1 Fall-Detected, 27.9ms\n",
      "image 386/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7641-_jpg.rf.08f0afc08e55056610437596291793bf.jpg: 416x416 2 Fall-Detecteds, 25.4ms\n",
      "image 387/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7648-_jpg.rf.7b9a969aedf99052ece3901818738599.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 388/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7693-_jpg.rf.005b0b758890aff2e01beb76e3763adc.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 389/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7710-_jpg.rf.3bdcc2d7946bb4b89a0b89237a57c7eb.jpg: 416x416 1 Fall-Detected, 29.1ms\n",
      "image 390/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7733-_jpg.rf.65330c760ca52ab6b9364e896c8c8c81.jpg: 416x416 1 Fall-Detected, 26.2ms\n",
      "image 391/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7751-_jpg.rf.4b645552c95ce40de8afc736b72f8b2b.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 392/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-784-_jpg.rf.3241bd841de116da4a93c33e3b65ef70.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 393/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7873-_jpg.rf.ae39bf47fa65442f8acd93a4970478ce.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 394/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7876-_jpg.rf.8e71410452ed9d83cb6650269e8b1c27.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 395/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-7898-_jpg.rf.eb37dccbd6e2ae78735e5308823ca2e8.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 396/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-79-_jpg.rf.f4056473d12956fd691b226e778670cc.jpg: 416x416 (no detections), 25.7ms\n",
      "image 397/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8002-_jpg.rf.c5e85f4bd585d15abb44928dd9aa49ad.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 398/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8005-_jpg.rf.7672c20540c211843f2d9719246be795.jpg: 416x416 1 Fall-Detected, 25.1ms\n",
      "image 399/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8017-_jpg.rf.07a805c3585c3a8239f95d2bb4eacd65.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 400/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8056-_jpg.rf.3e864b7f5a62ef46c17dc4af8bbbf70e.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 401/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8073-_jpg.rf.4dcee84aae36a809e12361a30b04a110.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 402/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8090-_jpg.rf.d4ea53db336e641f9834fbc77bc9ca6f.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 403/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8101-_jpg.rf.6a40685968e2b8de3e19e8e55fde0793.jpg: 416x416 1 Fall-Detected, 25.3ms\n",
      "image 404/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8104-_jpg.rf.a0ba3e639578e47b86fd850f791db018.jpg: 416x416 2 Fall-Detecteds, 25.0ms\n",
      "image 405/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8152-_jpg.rf.531ac42dec2f641bfb51b5ce20a8bb61.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 406/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8173-_jpg.rf.a1dd072be848ed8f3c2b755f1ae7af99.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 407/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8177-_jpg.rf.3498d86607385ab87df72183b8fd838c.jpg: 416x416 1 Fall-Detected, 24.6ms\n",
      "image 408/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8181-_jpg.rf.1b4913173733a4f6e0a033d2e70fc7a6.jpg: 416x416 1 Fall-Detected, 24.8ms\n",
      "image 409/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8192-_jpg.rf.0df974a3d1c215dec955b3a55de044ef.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 410/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8217-_jpg.rf.e655b2f498a65d5330d0d151fe6d2fd9.jpg: 416x416 1 Fall-Detected, 26.4ms\n",
      "image 411/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8231-_jpg.rf.2aa39a6e9a109674b6f9d5e8b5104ef0.jpg: 416x416 (no detections), 24.5ms\n",
      "image 412/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8295-_jpg.rf.634ad3b2a0b266901a85e870313a9523.jpg: 416x416 1 Fall-Detected, 25.2ms\n",
      "image 413/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-83-_jpg.rf.ff1185dff9ba87a075be2922ca7bf4a9.jpg: 416x416 1 Fall-Detected, 26.1ms\n",
      "image 414/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8304-_jpg.rf.da33d3c616bd0cfeeab3fac88872fb52.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 415/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8342-_jpg.rf.a4b1ca3ee4837f0facf24db6f893a424.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 416/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8346-_jpg.rf.e4342ae0db67a94cd5e7737cd7c0d551.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 417/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8361-_jpg.rf.e9bbee88ee588915978b91f420b82aa0.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 418/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-845-_jpg.rf.ab9b45a7ec54b1d069560e97a3698fec.jpg: 416x416 1 Fall-Detected, 25.5ms\n",
      "image 419/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-851-_jpg.rf.313aff8374839af10d67971760f415cf.jpg: 416x416 1 Fall-Detected, 24.7ms\n",
      "image 420/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-861-_jpg.rf.7035490316af644146a73a60fbd39296.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 421/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8698-_jpg.rf.18f147d3c1fea9dd3c6a5f4f9f744f0d.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 422/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8704-_jpg.rf.89b9403ad534010416ed1b8934558c95.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 423/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8711-_jpg.rf.5112d69abd5ca5934e996749a48e7e82.jpg: 416x416 1 Fall-Detected, 24.5ms\n",
      "image 424/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8714-_jpg.rf.cf029b4b465e73d2963980ab4ff2038f.jpg: 416x416 1 Fall-Detected, 25.6ms\n",
      "image 425/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8739-_jpg.rf.c7ee887d1d61cb118e33bde98dcbccf2.jpg: 416x416 1 Fall-Detected, 25.1ms\n",
      "image 426/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8756-_jpg.rf.0ee7d0b0515e66a816b595e1414e555f.jpg: 416x416 1 Fall-Detected, 24.9ms\n",
      "image 427/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8759-_jpg.rf.1b31b3e681aeef1d8d114ef42d8e204e.jpg: 416x416 1 Fall-Detected, 25.0ms\n",
      "image 428/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-878-_jpg.rf.0e2741afaa72a0473510172bda00df53.jpg: 416x416 1 Fall-Detected, 25.9ms\n",
      "image 429/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8789-_jpg.rf.e7942190b01cbcc163bf58458e82a233.jpg: 416x416 2 Fall-Detecteds, 24.8ms\n",
      "image 430/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8793-_jpg.rf.ba667a0aec9a1cb86cc51e663d8bf5d2.jpg: 416x416 1 Fall-Detected, 25.4ms\n",
      "image 431/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8794-_jpg.rf.21dd3bb6042b6a2e50194a243bf55177.jpg: 416x416 1 Fall-Detected, 25.7ms\n",
      "image 432/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8803-_jpg.rf.4bdfe996796fa1186f6ae72c1dc4c564.jpg: 416x416 1 Fall-Detected, 26.3ms\n",
      "image 433/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8808-_jpg.rf.d48bbb1e1e52bb91e96956cb872bf0e1.jpg: 416x416 2 Fall-Detecteds, 26.0ms\n",
      "image 434/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8815-_jpg.rf.45b0773ef9a46a9b3309d6537db37fda.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "image 435/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8818-_jpg.rf.bed83c76439277febcc461618fe3d5a0.jpg: 416x416 1 Fall-Detected, 25.8ms\n",
      "image 436/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8822-_jpg.rf.214ab8ae50643c941b013484387447f4.jpg: 416x416 1 Fall-Detected, 27.1ms\n",
      "image 437/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8829-_jpg.rf.95021eef039dfd56f8cb88379820ffab.jpg: 416x416 1 Fall-Detected, 26.5ms\n",
      "image 438/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8843-_jpg.rf.16e0eabf0b6d5429d95f87b6c2e53f74.jpg: 416x416 1 Fall-Detected, 27.3ms\n",
      "image 439/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8902-_jpg.rf.c1761b08d9633c354489270109027686.jpg: 416x416 1 Fall-Detected, 26.6ms\n",
      "image 440/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8944-_jpg.rf.a7a13578326f0935f786d9f9587319b5.jpg: 416x416 1 Fall-Detected, 26.9ms\n",
      "image 441/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8945-_jpg.rf.f7cf94bc86c49c906865e65dd4f91864.jpg: 416x416 1 Fall-Detected, 27.2ms\n",
      "image 442/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-8959-_jpg.rf.c03f6f04e07b69aacb620e01dd44f8e4.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 443/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-900-_jpg.rf.b8df7190d5c2d6caee2127c003505f86.jpg: 416x416 1 Fall-Detected, 27.0ms\n",
      "image 444/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-908-_jpg.rf.49e1733407a6a7c353a1cb2f53b7313b.jpg: 416x416 1 Fall-Detected, 27.2ms\n",
      "image 445/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-934-_jpg.rf.53544eceb09aac1f1a175dd27c2f2e18.jpg: 416x416 2 Fall-Detecteds, 26.9ms\n",
      "image 446/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-935-_jpg.rf.cff831cd1b1248e9e0c1d33c139df281.jpg: 416x416 1 Fall-Detected, 27.4ms\n",
      "image 447/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-967-_jpg.rf.1830f0a4d49fab90ff0898958f957427.jpg: 416x416 (no detections), 28.1ms\n",
      "image 448/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-968-_jpg.rf.7ce2369f073fd8da81e58a2c9380cc6c.jpg: 416x416 1 Fall-Detected, 27.9ms\n",
      "image 449/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-979-_jpg.rf.512885c00d0b794a5753f7316119b42f.jpg: 416x416 2 Fall-Detecteds, 29.3ms\n",
      "image 450/450 C:\\Users\\User\\baby_monitor_ai\\Fall_Detection.v4\\test\\images\\people-983-_jpg.rf.745ab6b7545e15aa3738752cb732b829.jpg: 416x416 1 Fall-Detected, 28.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 3.2ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "✅ تم حفظ الصور المتوقعة مع الصناديق داخل مجلد runs/predict\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# تحميل النموذج\n",
    "model = YOLO('runs/detect/train_lowmem3/weights/best.pt')\n",
    "\n",
    "# مسار مجلد test images\n",
    "test_images_dir = 'C:/Users/User/baby_monitor_ai/Fall_Detection.v4/test/images'\n",
    "\n",
    "# تنفيذ التنبؤات\n",
    "results = model.predict(source=test_images_dir, save=True, conf=0.3)\n",
    "\n",
    "print(\"✅ تم حفظ الصور المتوقعة مع الصناديق داخل مجلد runs/predict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a103bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n",
      "⚠️ سقوط مكتشف!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import winsound  # لو كنت على ويندوز\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# تحميل النموذج\n",
    "model = YOLO('runs/detect/train_lowmem3/weights/best.pt')\n",
    "\n",
    "# مسار الفيديو\n",
    "video_path = 'bedFall.mp4'\n",
    "\n",
    "# فتح الفيديو\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ لم يتم فتح الفيديو!\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # تنبؤ على الإطار الحالي\n",
    "    results = model.predict(frame, conf=0.3, verbose=False)\n",
    "\n",
    "    # رسم الصناديق على الصورة\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # تحقق إذا في fall\n",
    "    fall_detected = any(results[0].boxes.cls.cpu().numpy() == 0)  # class_id 0 هو Fall-Detected\n",
    "\n",
    "    if fall_detected:\n",
    "        print(\"⚠️ سقوط مكتشف!\")\n",
    "        winsound.Beep(1000, 500)  # تردد 1000Hz لمدة 500ms\n",
    "\n",
    "    # عرض الفيديو\n",
    "    cv2.imshow('Fall Detection', annotated_frame)\n",
    "\n",
    "    # خروج عند الضغط على Q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# تنظيف\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7eec5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# تحميل نموذج HAAR مسبق التدريب لاكتشاف الوجوه\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_faces_in_video(video_path):\n",
    "    \"\"\"\n",
    "    تقوم هذه الدالة باكتشاف الوجوه في الفيديو باستخدام تقنية HAAR\n",
    "    \"\"\"\n",
    "    # فتح ملف الفيديو\n",
    "    cap = cv2.VideoCapture(\"barhom.mp4\")\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"خطأ في فتح ملف الفيديو\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        # قراءة إطار من الفيديو\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # تحويل الإطار إلى تدرجات الرمادي (مطلوب لتقنية HAAR)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # اكتشاف الوجوه باستخدام HAAR (تم تصحيح الأقواس هنا)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,    # حساسية تغير حجم الوجه\n",
    "            minNeighbors=5,     # عدد الجيران المطلوبة لاكتشاف الوجه\n",
    "            minSize=(30, 30)    # أصغر حجم للوجه المكتشف\n",
    "        )  # <-- تم إضافة القوسين المفقودين هنا\n",
    "        \n",
    "        # رسم مستطيل حول الوجوه المكتشفة\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "        \n",
    "        # عرض الإطار الناتج\n",
    "        cv2.imshow('HAAR Face Detection', frame)\n",
    "        \n",
    "        # إيقاف التشغيل بالضغط على زر 'q'\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # تحرير الموارد\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# استخدام الدالة (استبدل المسار بمسار فيديو الخاص بك)\n",
    "detect_faces_in_video('your_video.mp4')  # أو 0 للكاميرا المباشرة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2771f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Collecting Click>=6.0 (from face_recognition)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-20.0.0-cp310-cp310-win_amd64.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\baby_monitor_ai\\.venv\\lib\\site-packages (from face_recognition) (2.2.6)\n",
      "Collecting Pillow (from face_recognition)\n",
      "  Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\baby_monitor_ai\\.venv\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: face-recognition-models, dlib, Pillow, Click, face_recognition\n",
      "\n",
      "   ---------------------------------------- 0/5 [face-recognition-models]\n",
      "   ---------------------------------------- 0/5 [face-recognition-models]\n",
      "   ---------------------------------------- 0/5 [face-recognition-models]\n",
      "   ---------------------------------------- 0/5 [face-recognition-models]\n",
      "   ---------------------------------------- 0/5 [face-recognition-models]\n",
      "   -------- ------------------------------- 1/5 [dlib]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ---------------- ----------------------- 2/5 [Pillow]\n",
      "   ------------------------ --------------- 3/5 [Click]\n",
      "   ------------------------ --------------- 3/5 [Click]\n",
      "   ------------------------ --------------- 3/5 [Click]\n",
      "   -------------------------------- ------- 4/5 [face_recognition]\n",
      "   -------------------------------- ------- 4/5 [face_recognition]\n",
      "   ---------------------------------------- 5/5 [face_recognition]\n",
      "\n",
      "Successfully installed Click-8.2.1 Pillow-11.2.1 dlib-20.0.0 face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a4d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "# تحميل صورة الطفل (استبدلي المسار بصورة ابن المستخدم لما تصير متوفرة)\n",
    "known_image = face_recognition.load_image_file(\"child_sample.png\")\n",
    "known_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# فتح كاميرا الويب أو اختبار صورة جديدة\n",
    "cap = cv2.VideoCapture(0)  # استخدمي ملف فيديو بدلاً من 0 إذا بدك\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # التعرف على الوجوه الموجودة في الإطار\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces([known_encoding], face_encoding)\n",
    "\n",
    "        if matches[0]:\n",
    "            label = \"Baby Detected\"\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            label = \"Not the baby\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ff203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")  # استبدلي بالمسار الحقيقي لنموذجك\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.predict(source=frame, conf=0.5, verbose=False)\n",
    "    sharp_object_detected = False\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_name = r.names[int(box.cls)]\n",
    "            if cls_name in [\"knife\", \"scissors\", \"sharp\", \"blade\"]:\n",
    "                sharp_object_detected = True\n",
    "                break\n",
    "\n",
    "    with open(\"detection_state.json\", \"w\") as f:\n",
    "        json.dump({\"sharp\": sharp_object_detected}, f)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89861e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 تحميل النموذج\n",
      "✅ تم تحميل النموذج\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "🔪 تم كشف أداة حادة: scissors\n"
     ]
    }
   ],
   "source": [
    "# yolo_script.py\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"📦 تحميل النموذج\")\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "print(\"✅ تم تحميل النموذج\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ فشل في قراءة الكاميرا.\")\n",
    "        break\n",
    "\n",
    "    print(\"📸 تم التقاط فريم من الكاميرا\")\n",
    "\n",
    "    # حفظ الصورة الحالية لإرسالها للسكريبت الثاني\n",
    "    cv2.imwrite(\"current_frame.jpg\", frame)\n",
    "\n",
    "    # كشف الأدوات الحادة\n",
    "    results = model.predict(source=frame, conf=0.5, verbose=False)\n",
    "    sharp_detected = False\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls_name = r.names[int(box.cls)]\n",
    "            if cls_name.lower() in [\"knife\", \"scissors\", \"sharp\", \"blade\"]:\n",
    "                sharp_detected = True\n",
    "                print(f\"🔪 تم كشف أداة حادة: {cls_name}\")\n",
    "                break\n",
    "\n",
    "    # حفظ حالة وجود أداة حادة\n",
    "    with open(\"sharp_flag.txt\", \"w\") as f:\n",
    "        f.write(\"1\" if sharp_detected else \"0\")\n",
    "\n",
    "    # عرض\n",
    "    cv2.imshow(\"YOLO View\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab71b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧒 تحميل صورة الطفل للتعرف\n",
      "🎥 تشغيل الكاميرا لمتابعة الفريمات المحفوظة\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018319F6DC30>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AD0030>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A3AC370>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A3AD7F0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A3AFDF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A381EB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AD0DB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A383630>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AB7EB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AB5CB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AB6930>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018318AB5CB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A3704B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A379CB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A379330>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A3CCCB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A381EB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001831A371BB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340871BF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340871DF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340871FB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340871BF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872130>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872130>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408724B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340871B30>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408724B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408726B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872130>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872A70>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408729B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408727B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872AF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408729B0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340873030>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872430>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872EF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408725F0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872FB0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872E70>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872FF0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872F30>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340873570>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340873870>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340872430>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340873570>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408737F0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x00000183408725F0>, 1\n",
      "❌ خطأ في ترميز الوجه: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001831A3282B0>, array([[[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [197, 199, 194],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        [203, 203, 201],\n",
      "        ...,\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193],\n",
      "        [196, 198, 193]],\n",
      "\n",
      "       [[204, 204, 202],\n",
      "        [204, 204, 202],\n",
      "        [205, 205, 203],\n",
      "        ...,\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196],\n",
      "        [198, 198, 196]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 41,  53,  43],\n",
      "        [ 44,  57,  47],\n",
      "        [ 48,  62,  49],\n",
      "        ...,\n",
      "        [ 36,  27,  28],\n",
      "        [ 37,  28,  31],\n",
      "        [ 38,  29,  32]],\n",
      "\n",
      "       [[ 44,  61,  45],\n",
      "        [ 45,  63,  47],\n",
      "        [ 47,  65,  49],\n",
      "        ...,\n",
      "        [ 33,  27,  27],\n",
      "        [ 35,  29,  31],\n",
      "        [ 36,  30,  34]],\n",
      "\n",
      "       [[ 49,  68,  49],\n",
      "        [ 48,  69,  50],\n",
      "        [ 48,  69,  50],\n",
      "        ...,\n",
      "        [ 32,  28,  27],\n",
      "        [ 35,  29,  33],\n",
      "        [ 36,  30,  34]]], shape=(480, 640, 3), dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000018340873870>, 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ تنبيه: الطفل قريب من أداة حادة!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m         winsound\u001b[38;5;241m.\u001b[39mBeep(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# face_recog_script.py\n",
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "import winsound\n",
    "import os\n",
    "\n",
    "print(\"🧒 تحميل صورة الطفل للتعرف\")\n",
    "known_image = face_recognition.load_image_file(\"child_sample.png\")\n",
    "known_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "print(\"🎥 تشغيل الكاميرا لمتابعة الفريمات المحفوظة\")\n",
    "while True:\n",
    "    if os.path.exists(\"current_frame.jpg\"):\n",
    "        frame = cv2.imread(\"current_frame.jpg\")\n",
    "        if frame is None:\n",
    "            print(\"❌ لم يتمكن من تحميل الفريم.\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "        child_detected = False\n",
    "\n",
    "        if face_locations:\n",
    "            try:\n",
    "                face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "                for face_encoding in face_encodings:\n",
    "                    match = face_recognition.compare_faces([known_encoding], face_encoding)[0]\n",
    "                    if match:\n",
    "                        child_detected = True\n",
    "                        print(\"🧒 تم التعرف على الطفل\")\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ خطأ في ترميز الوجه: {e}\")\n",
    "        else:\n",
    "            print(\"😕 لا يوجد وجه في الفريم\")\n",
    "\n",
    "        # قراءة حالة وجود أداة حادة\n",
    "        sharp_detected = False\n",
    "        if os.path.exists(\"sharp_flag.txt\"):\n",
    "            with open(\"sharp_flag.txt\", \"r\") as f:\n",
    "                sharp_detected = f.read().strip() == \"1\"\n",
    "\n",
    "        if child_detected and sharp_detected:\n",
    "            print(\"⚠️ تنبيه: الطفل قريب من أداة حادة!\")\n",
    "            winsound.Beep(1000, 500)\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b4268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📆 تحميل نموذج YOLOv8 ...\n",
      "✅ تم تحميل النموذج\n",
      "🎥 تشغيل الكاميرا ...\n",
      "📸 فريم رقم 1\n",
      "📸 فريم رقم 2\n",
      "📸 فريم رقم 3\n",
      "📸 فريم رقم 4\n",
      "📸 فريم رقم 5\n",
      "📸 فريم رقم 6\n",
      "📸 فريم رقم 7\n",
      "📸 فريم رقم 8\n",
      "📸 فريم رقم 9\n",
      "📸 فريم رقم 10\n",
      "📸 فريم رقم 11\n",
      "📸 فريم رقم 12\n",
      "📸 فريم رقم 13\n",
      "📸 فريم رقم 14\n",
      "📸 فريم رقم 15\n",
      "📸 فريم رقم 16\n",
      "📸 فريم رقم 17\n",
      "📸 فريم رقم 18\n",
      "📸 فريم رقم 19\n",
      "📸 فريم رقم 20\n",
      "📸 فريم رقم 21\n",
      "📸 فريم رقم 22\n",
      "📸 فريم رقم 23\n",
      "📸 فريم رقم 24\n",
      "📸 فريم رقم 25\n",
      "📸 فريم رقم 26\n",
      "📸 فريم رقم 27\n",
      "📸 فريم رقم 28\n",
      "📸 فريم رقم 29\n",
      "📸 فريم رقم 30\n",
      "📸 فريم رقم 31\n",
      "📸 فريم رقم 32\n",
      "📸 فريم رقم 33\n",
      "📸 فريم رقم 34\n",
      "📸 فريم رقم 35\n",
      "📸 فريم رقم 36\n",
      "📸 فريم رقم 37\n",
      "📸 فريم رقم 38\n",
      "📸 فريم رقم 39\n",
      "📸 فريم رقم 40\n",
      "📸 فريم رقم 41\n",
      "📸 فريم رقم 42\n",
      "📸 فريم رقم 43\n",
      "📸 فريم رقم 44\n",
      "📸 فريم رقم 45\n",
      "📸 فريم رقم 46\n",
      "📸 فريم رقم 47\n",
      "📸 فريم رقم 48\n",
      "📸 فريم رقم 49\n",
      "📸 فريم رقم 50\n",
      "📸 فريم رقم 51\n",
      "📸 فريم رقم 52\n",
      "📸 فريم رقم 53\n",
      "📸 فريم رقم 54\n",
      "📸 فريم رقم 55\n",
      "📸 فريم رقم 56\n",
      "📸 فريم رقم 57\n",
      "📸 فريم رقم 58\n",
      "📸 فريم رقم 59\n",
      "📸 فريم رقم 60\n",
      "📸 فريم رقم 61\n",
      "📸 فريم رقم 62\n",
      "📸 فريم رقم 63\n",
      "📸 فريم رقم 64\n",
      "📸 فريم رقم 65\n",
      "📸 فريم رقم 66\n",
      "📸 فريم رقم 67\n",
      "📸 فريم رقم 68\n",
      "📸 فريم رقم 69\n",
      "📸 فريم رقم 70\n",
      "📸 فريم رقم 71\n",
      "📸 فريم رقم 72\n",
      "📸 فريم رقم 73\n",
      "📸 فريم رقم 74\n",
      "📸 فريم رقم 75\n",
      "📸 فريم رقم 76\n",
      "📸 فريم رقم 77\n",
      "📸 فريم رقم 78\n",
      "📸 فريم رقم 79\n",
      "📸 فريم رقم 80\n",
      "📸 فريم رقم 81\n",
      "📸 فريم رقم 82\n",
      "📸 فريم رقم 83\n",
      "📸 فريم رقم 84\n",
      "📸 فريم رقم 85\n",
      "📸 فريم رقم 86\n",
      "📸 فريم رقم 87\n",
      "📸 فريم رقم 88\n",
      "📸 فريم رقم 89\n",
      "📸 فريم رقم 90\n",
      "📸 فريم رقم 91\n",
      "📸 فريم رقم 92\n",
      "📸 فريم رقم 93\n",
      "📸 فريم رقم 94\n",
      "📸 فريم رقم 95\n",
      "📸 فريم رقم 96\n",
      "📸 فريم رقم 97\n",
      "📸 فريم رقم 98\n",
      "📸 فريم رقم 99\n",
      "📸 فريم رقم 100\n",
      "📸 فريم رقم 101\n",
      "📸 فريم رقم 102\n",
      "📸 فريم رقم 103\n",
      "📸 فريم رقم 104\n",
      "📸 فريم رقم 105\n",
      "📸 فريم رقم 106\n",
      "📸 فريم رقم 107\n",
      "📸 فريم رقم 108\n",
      "📸 فريم رقم 109\n",
      "📸 فريم رقم 110\n",
      "📸 فريم رقم 111\n",
      "📸 فريم رقم 112\n",
      "📸 فريم رقم 113\n",
      "📸 فريم رقم 114\n",
      "📸 فريم رقم 115\n",
      "📸 فريم رقم 116\n",
      "📸 فريم رقم 117\n",
      "📸 فريم رقم 118\n",
      "📸 فريم رقم 119\n",
      "📸 فريم رقم 120\n",
      "📸 فريم رقم 121\n",
      "📸 فريم رقم 122\n",
      "📸 فريم رقم 123\n",
      "📸 فريم رقم 124\n",
      "📸 فريم رقم 125\n",
      "📸 فريم رقم 126\n",
      "📸 فريم رقم 127\n",
      "📸 فريم رقم 128\n",
      "📸 فريم رقم 129\n",
      "📸 فريم رقم 130\n",
      "📸 فريم رقم 131\n",
      "📸 فريم رقم 132\n",
      "📸 فريم رقم 133\n",
      "📸 فريم رقم 134\n",
      "📸 فريم رقم 135\n",
      "📸 فريم رقم 136\n",
      "📸 فريم رقم 137\n",
      "📸 فريم رقم 138\n",
      "📸 فريم رقم 139\n",
      "📸 فريم رقم 140\n",
      "📸 فريم رقم 141\n",
      "📸 فريم رقم 142\n",
      "📸 فريم رقم 143\n",
      "📸 فريم رقم 144\n",
      "📸 فريم رقم 145\n",
      "📸 فريم رقم 146\n",
      "📸 فريم رقم 147\n",
      "📸 فريم رقم 148\n",
      "📸 فريم رقم 149\n",
      "📸 فريم رقم 150\n",
      "📸 فريم رقم 151\n",
      "📸 فريم رقم 152\n",
      "📸 فريم رقم 153\n",
      "📸 فريم رقم 154\n",
      "📸 فريم رقم 155\n",
      "📸 فريم رقم 156\n",
      "📸 فريم رقم 157\n",
      "📸 فريم رقم 158\n",
      "📸 فريم رقم 159\n",
      "📸 فريم رقم 160\n",
      "📸 فريم رقم 161\n",
      "📸 فريم رقم 162\n",
      "📸 فريم رقم 163\n",
      "📸 فريم رقم 164\n",
      "📸 فريم رقم 165\n",
      "📸 فريم رقم 166\n",
      "📸 فريم رقم 167\n",
      "📸 فريم رقم 168\n",
      "📸 فريم رقم 169\n",
      "📸 فريم رقم 170\n",
      "📸 فريم رقم 171\n",
      "📸 فريم رقم 172\n",
      "📸 فريم رقم 173\n",
      "📸 فريم رقم 174\n",
      "📸 فريم رقم 175\n",
      "📸 فريم رقم 176\n",
      "📸 فريم رقم 177\n",
      "📸 فريم رقم 178\n",
      "📸 فريم رقم 179\n",
      "📸 فريم رقم 180\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 📆 اسم مجلد حفظ الفريمات\n",
    "frames_dir = \"sharp_frames\"\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "# 📆 ملف JSON لحالة الكشف\n",
    "state_file = \"detection_state.json\"\n",
    "def update_detection_state(has_sharp_object):\n",
    "    state = {\n",
    "        \"sharp_detected\": has_sharp_object,\n",
    "        \"last_detected_time\": datetime.now().isoformat() if has_sharp_object else None\n",
    "    }\n",
    "    with open(state_file, \"w\") as f:\n",
    "        json.dump(state, f, indent=2)\n",
    "\n",
    "# 📖 تحميل النموذج المدرب\n",
    "print(\"📆 تحميل نموذج YOLOv8 ...\")\n",
    "model = YOLO(\"runs/detect/train_lowmem3/weights/best.pt\")\n",
    "print(\"✅ تم تحميل النموذج\")\n",
    "\n",
    "# 🎥 تشغيل الكاميرا\n",
    "print(\"🎥 تشغيل الكاميرا ...\")\n",
    "cap = cv2.VideoCapture(0)  # يمكن تغيير الرقم لمسار فيديو خارجي\n",
    "\n",
    "frame_count = 0\n",
    "sharp_detected = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ لم يتم التقاط فريم. يتم الإنهاء.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    print(f\"📸 فريم رقم {frame_count}\")\n",
    "\n",
    "    # ✨ تنفيذ التنبؤ\n",
    "    results = model.predict(frame, conf=0.5, verbose=False)\n",
    "\n",
    "    sharp_found = False\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                cls_name = r.names[int(box.cls)]\n",
    "                if cls_name.lower() in [\"knife\", \"scissors\", \"blade\", \"sharp\"]:\n",
    "                    sharp_found = True\n",
    "                    print(f\"🔪 تم كشف أداة حادة: {cls_name}\")\n",
    "\n",
    "                    # رسم الصندوق\n",
    "                    xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"{cls_name}\", (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    break\n",
    "\n",
    "    # 🔖 تحديث الحالة\n",
    "    update_detection_state(sharp_found)\n",
    "\n",
    "    # 📷 حفظ الفريم إذا وُجد أداة حادة\n",
    "    if sharp_found:\n",
    "        filename = os.path.join(frames_dir, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "    # 👁️ عرض الصورة\n",
    "    cv2.imshow(\"Sharp Object Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"🛑 تم الضغط على Q - إنهاء\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"✅ تم إنهاء السكربت\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334c10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحميل صورة الطفل وترميزها\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import winsound\n",
    "\n",
    "# تحميل صورة الطفل من مجلد الصور\n",
    "child_image_path = \"child_photos/photo_3.jpg\"\n",
    "known_image = face_recognition.load_image_file(child_image_path)\n",
    "known_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "print(\"✅ تم تحميل صورة الطفل وترميزها\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8651f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# المجلد الذي يتم فيه حفظ الفريمات\n",
    "frames_dir = \"Fall_Detection.v4/frames\"\n",
    "\n",
    "# الملف الذي يحوي نتيجة كشف الأدوات الحادة\n",
    "detection_state_path = \"detection_state.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8822d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851a3374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m processed_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[43mframes_dir\u001b[49m):\n\u001b[0;32m      5\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames_dir' is not defined"
     ]
    }
   ],
   "source": [
    "processed_frames = set()\n",
    "\n",
    "while True:\n",
    "    if not os.path.exists(frames_dir):\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "\n",
    "    frame_files = sorted([\n",
    "        f for f in os.listdir(frames_dir)\n",
    "        if f.endswith(\".jpg\") and f not in processed_frames\n",
    "    ])\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frames_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        print(f\"📸 معالجة {frame_file}\")\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        child_detected = False\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces([known_encoding], face_encoding)\n",
    "            if True in matches:\n",
    "                child_detected = True\n",
    "                print(\"🧒 تم التعرف على وجه الطفل\")\n",
    "                break\n",
    "\n",
    "        with open(detection_state_path, \"r\") as f:\n",
    "            detection_state = json.load(f)\n",
    "        sharp_detected = detection_state.get(\"sharp_detected\", False)\n",
    "\n",
    "        if child_detected and sharp_detected:\n",
    "            print(\"🚨 تنبيه: الطفل قريب من أداة حادة!\")\n",
    "            winsound.Beep(1000, 500)\n",
    "\n",
    "        processed_frames.add(frame_file)\n",
    "\n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63250195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 تحميل النموذج\n",
      "✅ تم تحميل النموذج\n",
      "🎥 تشغيل الكاميرا\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 2.1ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.1ms\n",
      "Speed: 2.3ms preprocess, 25.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.2ms preprocess, 21.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.7ms\n",
      "Speed: 1.8ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.7ms\n",
      "Speed: 1.3ms preprocess, 25.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.3ms preprocess, 21.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.2ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.2ms preprocess, 23.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.1ms\n",
      "Speed: 1.3ms preprocess, 19.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.4ms preprocess, 20.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.1ms\n",
      "Speed: 1.4ms preprocess, 19.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.5ms preprocess, 18.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 2.0ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.5ms preprocess, 18.7ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.2ms preprocess, 20.9ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 3.4ms preprocess, 22.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.6ms preprocess, 17.2ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.5ms preprocess, 16.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 1.2ms preprocess, 24.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.8ms\n",
      "Speed: 2.0ms preprocess, 22.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.3ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.8ms preprocess, 20.4ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.7ms preprocess, 17.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.2ms preprocess, 19.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 1.8ms preprocess, 20.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.5ms preprocess, 19.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.4ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.0ms\n",
      "Speed: 1.8ms preprocess, 21.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.3ms\n",
      "Speed: 1.3ms preprocess, 24.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.4ms preprocess, 21.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.4ms preprocess, 18.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.9ms\n",
      "Speed: 1.3ms preprocess, 25.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.4ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.5ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.3ms preprocess, 20.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.8ms\n",
      "Speed: 1.3ms preprocess, 21.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.8ms\n",
      "Speed: 1.9ms preprocess, 21.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 2.1ms preprocess, 21.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 2.1ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.4ms\n",
      "Speed: 1.6ms preprocess, 20.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.0ms\n",
      "Speed: 1.4ms preprocess, 21.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.7ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 1.6ms preprocess, 19.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.4ms preprocess, 20.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.7ms preprocess, 17.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.8ms preprocess, 18.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.4ms preprocess, 17.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.3ms preprocess, 20.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.8ms preprocess, 18.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 1.8ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 1.5ms preprocess, 19.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 1.3ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 1.5ms preprocess, 18.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 1.4ms preprocess, 19.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 1.7ms preprocess, 19.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.2ms preprocess, 21.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.8ms preprocess, 18.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.0ms\n",
      "Speed: 1.6ms preprocess, 20.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 1.5ms preprocess, 18.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 1.5ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.8ms preprocess, 20.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 1.5ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.8ms\n",
      "Speed: 1.5ms preprocess, 19.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.6ms\n",
      "Speed: 1.3ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.7ms\n",
      "Speed: 1.2ms preprocess, 22.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.6ms preprocess, 18.9ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.0ms\n",
      "Speed: 1.3ms preprocess, 23.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.9ms\n",
      "Speed: 1.3ms preprocess, 20.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 2.2ms preprocess, 24.3ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.9ms\n",
      "Speed: 2.4ms preprocess, 26.9ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 32.6ms\n",
      "Speed: 2.3ms preprocess, 32.6ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.8ms\n",
      "Speed: 2.1ms preprocess, 20.8ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.9ms\n",
      "Speed: 2.2ms preprocess, 26.9ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 2.1ms preprocess, 22.0ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.7ms preprocess, 21.7ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.3ms preprocess, 22.6ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.9ms\n",
      "Speed: 2.2ms preprocess, 28.9ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 1.4ms preprocess, 24.0ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.3ms\n",
      "Speed: 2.1ms preprocess, 25.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.9ms\n",
      "Speed: 2.2ms preprocess, 25.9ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 30.0ms\n",
      "Speed: 1.4ms preprocess, 30.0ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 28.2ms\n",
      "Speed: 2.3ms preprocess, 28.2ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 2.1ms preprocess, 23.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.3ms\n",
      "Speed: 2.2ms preprocess, 28.3ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.5ms\n",
      "Speed: 2.4ms preprocess, 26.5ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 2.3ms preprocess, 23.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 1.4ms preprocess, 24.0ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 27.8ms\n",
      "Speed: 2.3ms preprocess, 27.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.3ms\n",
      "Speed: 2.2ms preprocess, 28.3ms inference, 6.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.0ms\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.3ms\n",
      "Speed: 2.1ms preprocess, 26.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.0ms\n",
      "Speed: 2.3ms preprocess, 26.0ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.1ms\n",
      "Speed: 2.3ms preprocess, 25.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 2.5ms preprocess, 24.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.7ms\n",
      "Speed: 2.2ms preprocess, 29.7ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 2.2ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 2.4ms preprocess, 24.3ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.1ms\n",
      "Speed: 2.1ms preprocess, 25.1ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.2ms preprocess, 24.4ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.3ms\n",
      "Speed: 2.1ms preprocess, 27.3ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 28.3ms\n",
      "Speed: 2.4ms preprocess, 28.3ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.3ms preprocess, 24.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.0ms\n",
      "Speed: 2.3ms preprocess, 26.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.2ms\n",
      "Speed: 2.2ms preprocess, 29.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.2ms\n",
      "Speed: 2.3ms preprocess, 26.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.7ms\n",
      "Speed: 2.0ms preprocess, 26.7ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.9ms\n",
      "Speed: 2.0ms preprocess, 26.9ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.9ms\n",
      "Speed: 2.3ms preprocess, 28.9ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.8ms\n",
      "Speed: 1.6ms preprocess, 29.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.5ms\n",
      "Speed: 1.4ms preprocess, 29.5ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.2ms\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.7ms\n",
      "Speed: 1.4ms preprocess, 23.7ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.6ms preprocess, 19.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.8ms\n",
      "Speed: 1.3ms preprocess, 22.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.8ms preprocess, 16.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 2.1ms preprocess, 19.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.2ms preprocess, 19.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.7ms preprocess, 18.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.3ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.3ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.8ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.5ms preprocess, 18.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.1ms\n",
      "Speed: 2.1ms preprocess, 24.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 20.9ms\n",
      "Speed: 1.3ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.3ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.3ms preprocess, 21.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 22.3ms\n",
      "Speed: 1.3ms preprocess, 22.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 1.3ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.1ms\n",
      "Speed: 1.4ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.8ms preprocess, 23.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.3ms preprocess, 23.5ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.7ms preprocess, 21.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.0ms\n",
      "Speed: 1.7ms preprocess, 21.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.7ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.8ms\n",
      "Speed: 1.4ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.6ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.5ms preprocess, 18.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.2ms preprocess, 19.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.8ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.2ms preprocess, 21.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.7ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.5ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.4ms preprocess, 23.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.2ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.5ms preprocess, 18.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.2ms preprocess, 20.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.9ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.6ms preprocess, 18.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.5ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.7ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 36.3ms\n",
      "Speed: 2.4ms preprocess, 36.3ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.9ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 1.3ms preprocess, 22.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.2ms preprocess, 21.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.2ms preprocess, 20.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.4ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.4ms\n",
      "Speed: 1.3ms preprocess, 15.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 2.2ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.2ms preprocess, 22.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.4ms\n",
      "Speed: 1.5ms preprocess, 15.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 1.4ms preprocess, 21.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.4ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.0ms\n",
      "Speed: 1.3ms preprocess, 21.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 1.2ms preprocess, 21.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.2ms preprocess, 19.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.4ms preprocess, 18.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.3ms\n",
      "Speed: 1.7ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.2ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 2.1ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.5ms\n",
      "Speed: 1.2ms preprocess, 19.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.5ms\n",
      "Speed: 1.2ms preprocess, 22.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.6ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.8ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.8ms\n",
      "Speed: 2.3ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.6ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.3ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.8ms\n",
      "Speed: 1.3ms preprocess, 23.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.6ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 2.0ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.4ms preprocess, 18.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 2.3ms preprocess, 21.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.2ms preprocess, 19.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.2ms preprocess, 19.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.7ms preprocess, 20.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.2ms\n",
      "Speed: 1.7ms preprocess, 19.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.6ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.6ms preprocess, 17.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 2.3ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.7ms preprocess, 15.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.2ms preprocess, 18.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.5ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.4ms preprocess, 23.6ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.8ms\n",
      "Speed: 1.2ms preprocess, 22.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.2ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.6ms preprocess, 18.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.2ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.8ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.4ms preprocess, 20.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.9ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.2ms preprocess, 22.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.4ms preprocess, 19.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.3ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.3ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.2ms\n",
      "Speed: 1.5ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.6ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.8ms preprocess, 16.1ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.3ms preprocess, 19.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.8ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.8ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.2ms preprocess, 17.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.5ms preprocess, 19.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.5ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.7ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.6ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.5ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 2.0ms preprocess, 21.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.4ms preprocess, 20.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.8ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 31.1ms\n",
      "Speed: 2.4ms preprocess, 31.1ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.4ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 2.0ms preprocess, 22.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.8ms preprocess, 17.9ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.3ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.3ms preprocess, 23.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.8ms preprocess, 22.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.7ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 30.0ms\n",
      "Speed: 2.5ms preprocess, 30.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.4ms\n",
      "Speed: 1.3ms preprocess, 15.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.6ms preprocess, 21.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.4ms preprocess, 23.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.6ms preprocess, 18.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.4ms\n",
      "Speed: 1.9ms preprocess, 22.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.6ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.6ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.9ms preprocess, 16.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.5ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.8ms preprocess, 18.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.6ms preprocess, 19.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.7ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.8ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.6ms preprocess, 19.9ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.5ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 1.8ms preprocess, 21.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.7ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.8ms preprocess, 19.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.5ms preprocess, 18.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.2ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.7ms preprocess, 17.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.5ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.6ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.8ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.3ms preprocess, 23.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.4ms preprocess, 19.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.0ms\n",
      "Speed: 2.2ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 2.1ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.5ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.6ms preprocess, 16.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.5ms preprocess, 17.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.9ms preprocess, 20.4ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.3ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.6ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 2.1ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.3ms preprocess, 22.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.8ms preprocess, 16.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.4ms preprocess, 18.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 2.1ms preprocess, 23.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.1ms\n",
      "Speed: 1.2ms preprocess, 19.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.4ms\n",
      "Speed: 1.3ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.9ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.5ms\n",
      "Speed: 1.2ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.7ms\n",
      "Speed: 1.3ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.6ms\n",
      "Speed: 1.4ms preprocess, 19.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.2ms\n",
      "Speed: 2.1ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.2ms\n",
      "Speed: 2.1ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.8ms\n",
      "Speed: 1.3ms preprocess, 21.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.0ms\n",
      "Speed: 1.2ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.0ms\n",
      "Speed: 1.8ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.2ms\n",
      "Speed: 1.3ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 1.9ms preprocess, 21.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.8ms preprocess, 19.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 2.4ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 2.0ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.3ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.0ms\n",
      "Speed: 1.9ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.4ms\n",
      "Speed: 2.0ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.4ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.9ms\n",
      "Speed: 3.9ms preprocess, 21.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.0ms\n",
      "Speed: 2.6ms preprocess, 27.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.5ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.7ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 2.3ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.9ms preprocess, 16.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.5ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.7ms preprocess, 19.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.2ms preprocess, 21.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.3ms\n",
      "Speed: 1.2ms preprocess, 25.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.8ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.6ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.8ms preprocess, 16.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.9ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.5ms\n",
      "Speed: 1.9ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.0ms\n",
      "Speed: 1.3ms preprocess, 23.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 2.1ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.8ms\n",
      "Speed: 1.9ms preprocess, 18.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.4ms\n",
      "Speed: 1.3ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.6ms\n",
      "Speed: 1.8ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.6ms\n",
      "Speed: 2.3ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.5ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.9ms\n",
      "Speed: 1.7ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.6ms\n",
      "Speed: 1.6ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 1.5ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.7ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.6ms\n",
      "Speed: 1.7ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.6ms\n",
      "Speed: 2.3ms preprocess, 26.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.6ms\n",
      "Speed: 1.4ms preprocess, 19.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.2ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.9ms\n",
      "Speed: 1.4ms preprocess, 17.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.1ms\n",
      "Speed: 1.8ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 1.6ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.6ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.8ms\n",
      "Speed: 2.0ms preprocess, 22.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.4ms\n",
      "Speed: 2.1ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.0ms\n",
      "Speed: 1.1ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.3ms\n",
      "Speed: 1.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.3ms\n",
      "Speed: 1.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.4ms\n",
      "Speed: 1.5ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.0ms\n",
      "Speed: 1.9ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.2ms\n",
      "Speed: 1.8ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.3ms\n",
      "Speed: 1.4ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.6ms\n",
      "Speed: 1.7ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.3ms\n",
      "Speed: 1.2ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.8ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.5ms preprocess, 20.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.6ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.3ms preprocess, 19.4ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.8ms preprocess, 22.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.3ms preprocess, 20.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.0ms\n",
      "Speed: 1.3ms preprocess, 23.0ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.4ms preprocess, 19.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.2ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.2ms\n",
      "Speed: 1.9ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.2ms\n",
      "Speed: 1.2ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.6ms\n",
      "Speed: 1.9ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.3ms\n",
      "Speed: 2.0ms preprocess, 23.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 2.4ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.5ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.3ms preprocess, 23.1ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.6ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.5ms preprocess, 18.0ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.7ms preprocess, 21.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.6ms preprocess, 18.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.2ms preprocess, 18.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.4ms preprocess, 20.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.3ms\n",
      "Speed: 6.0ms preprocess, 27.3ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.6ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 1.2ms preprocess, 22.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.3ms preprocess, 24.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.6ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.3ms preprocess, 19.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 2.2ms preprocess, 17.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.8ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.4ms preprocess, 21.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.5ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.6ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.4ms preprocess, 20.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.9ms preprocess, 19.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.3ms preprocess, 22.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.7ms\n",
      "Speed: 1.9ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.5ms preprocess, 17.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.9ms\n",
      "Speed: 1.3ms preprocess, 21.9ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.5ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.6ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 4 Fall-Detecteds, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 4 Fall-Detecteds, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 4 Fall-Detecteds, 22.8ms\n",
      "Speed: 2.1ms preprocess, 22.8ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.9ms\n",
      "Speed: 1.6ms preprocess, 17.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.2ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.2ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.7ms preprocess, 22.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 2.1ms preprocess, 22.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.7ms preprocess, 17.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.6ms preprocess, 17.7ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.2ms\n",
      "Speed: 1.3ms preprocess, 18.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.9ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.2ms preprocess, 20.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.4ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.7ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.7ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 1.2ms preprocess, 22.9ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.0ms\n",
      "Speed: 2.1ms preprocess, 23.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.5ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 2.3ms preprocess, 18.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.2ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.8ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 1.8ms preprocess, 19.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.1ms\n",
      "Speed: 1.2ms preprocess, 20.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.8ms preprocess, 18.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 2.1ms preprocess, 18.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.0ms\n",
      "Speed: 1.9ms preprocess, 22.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.6ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.2ms preprocess, 23.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.5ms\n",
      "Speed: 2.2ms preprocess, 19.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.6ms\n",
      "Speed: 2.3ms preprocess, 21.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 1.2ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.8ms preprocess, 19.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.7ms preprocess, 20.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.2ms preprocess, 19.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.9ms preprocess, 22.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.5ms\n",
      "Speed: 1.9ms preprocess, 27.5ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.2ms preprocess, 21.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.2ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.2ms\n",
      "Speed: 1.2ms preprocess, 15.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.9ms preprocess, 17.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.0ms\n",
      "Speed: 1.3ms preprocess, 23.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.2ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.2ms preprocess, 24.6ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.5ms\n",
      "Speed: 2.3ms preprocess, 26.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.9ms preprocess, 21.1ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.6ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.4ms\n",
      "Speed: 3.4ms preprocess, 25.4ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.8ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.2ms preprocess, 18.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.2ms preprocess, 22.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.6ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.9ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.2ms preprocess, 19.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.8ms\n",
      "Speed: 2.1ms preprocess, 22.8ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.9ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.9ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.7ms\n",
      "Speed: 1.5ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.1ms\n",
      "Speed: 1.9ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.7ms preprocess, 18.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.2ms preprocess, 20.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.9ms preprocess, 23.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.8ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.7ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.5ms\n",
      "Speed: 1.2ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.2ms preprocess, 18.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.9ms\n",
      "Speed: 1.2ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.3ms preprocess, 20.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.4ms preprocess, 20.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 2.1ms preprocess, 20.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.8ms preprocess, 20.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.4ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.3ms preprocess, 19.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.6ms\n",
      "Speed: 2.2ms preprocess, 26.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.5ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.5ms\n",
      "Speed: 1.4ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.4ms\n",
      "Speed: 1.6ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.4ms preprocess, 18.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.6ms preprocess, 16.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.5ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.4ms\n",
      "Speed: 1.4ms preprocess, 15.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.2ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.8ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.2ms preprocess, 22.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.5ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.4ms preprocess, 15.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.0ms\n",
      "Speed: 1.8ms preprocess, 21.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 4.2ms preprocess, 23.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.4ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.7ms preprocess, 17.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.5ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.2ms preprocess, 16.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.9ms preprocess, 23.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.3ms preprocess, 20.6ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.7ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.9ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.5ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.2ms preprocess, 17.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 2.0ms preprocess, 19.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.9ms preprocess, 16.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 1.3ms preprocess, 22.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 2.1ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.4ms preprocess, 20.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.5ms preprocess, 19.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.5ms preprocess, 19.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.7ms preprocess, 20.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.6ms\n",
      "Speed: 2.2ms preprocess, 27.6ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.9ms\n",
      "Speed: 1.7ms preprocess, 15.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.2ms\n",
      "Speed: 2.9ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 1.3ms preprocess, 23.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.0ms\n",
      "Speed: 1.9ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.8ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.3ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 2.1ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.6ms\n",
      "Speed: 5.3ms preprocess, 25.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.7ms\n",
      "Speed: 1.3ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.4ms\n",
      "Speed: 1.5ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.1ms\n",
      "Speed: 1.4ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.4ms preprocess, 19.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.5ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.4ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.9ms preprocess, 20.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.5ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.8ms preprocess, 21.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 2.0ms preprocess, 24.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.2ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.8ms preprocess, 21.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.8ms\n",
      "Speed: 1.4ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.5ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.2ms\n",
      "Speed: 1.4ms preprocess, 19.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.5ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.5ms preprocess, 18.0ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.5ms\n",
      "Speed: 2.3ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.4ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.0ms\n",
      "Speed: 1.3ms preprocess, 22.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 1.3ms preprocess, 19.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.9ms\n",
      "Speed: 2.3ms preprocess, 23.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.7ms\n",
      "Speed: 1.4ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.8ms preprocess, 21.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.0ms\n",
      "Speed: 1.4ms preprocess, 24.0ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.2ms preprocess, 18.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.9ms\n",
      "Speed: 1.9ms preprocess, 21.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.6ms\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.5ms preprocess, 19.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 3 Fall-Detecteds, 19.3ms\n",
      "Speed: 1.7ms preprocess, 19.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.3ms\n",
      "Speed: 1.3ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.3ms\n",
      "Speed: 1.5ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.2ms preprocess, 17.8ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.9ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.3ms\n",
      "Speed: 1.9ms preprocess, 22.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.5ms preprocess, 19.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.3ms preprocess, 23.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.1ms\n",
      "Speed: 1.3ms preprocess, 19.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.5ms\n",
      "Speed: 2.1ms preprocess, 28.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.2ms preprocess, 18.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.4ms\n",
      "Speed: 2.1ms preprocess, 23.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.2ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 1.2ms preprocess, 23.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.3ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.2ms preprocess, 18.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.2ms\n",
      "Speed: 1.4ms preprocess, 19.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.2ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.5ms\n",
      "Speed: 2.2ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.0ms\n",
      "Speed: 1.4ms preprocess, 21.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.2ms preprocess, 20.6ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.5ms preprocess, 18.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.2ms preprocess, 18.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.6ms\n",
      "Speed: 1.3ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.5ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.6ms preprocess, 20.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.0ms\n",
      "Speed: 1.4ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.3ms preprocess, 18.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.6ms\n",
      "Speed: 1.5ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.2ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 4.1ms preprocess, 22.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 1.2ms preprocess, 24.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.2ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.7ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.7ms\n",
      "Speed: 1.2ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.8ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.4ms preprocess, 19.9ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.0ms\n",
      "Speed: 1.4ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.7ms\n",
      "Speed: 1.7ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.4ms\n",
      "Speed: 1.5ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.9ms\n",
      "Speed: 1.3ms preprocess, 26.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.0ms\n",
      "Speed: 1.9ms preprocess, 23.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.6ms preprocess, 19.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.4ms preprocess, 19.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.5ms preprocess, 19.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.8ms\n",
      "Speed: 1.2ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.6ms\n",
      "Speed: 1.2ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.5ms\n",
      "Speed: 1.3ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.2ms preprocess, 23.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.2ms preprocess, 22.3ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.7ms\n",
      "Speed: 1.2ms preprocess, 18.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.5ms\n",
      "Speed: 1.8ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.4ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.5ms preprocess, 16.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.5ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.5ms preprocess, 16.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.5ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.6ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.6ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.1ms\n",
      "Speed: 1.2ms preprocess, 22.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.2ms preprocess, 20.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.8ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.8ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.8ms\n",
      "Speed: 2.1ms preprocess, 21.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.2ms preprocess, 20.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.2ms\n",
      "Speed: 1.3ms preprocess, 18.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.0ms\n",
      "Speed: 1.7ms preprocess, 21.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.4ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.4ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.7ms preprocess, 20.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.6ms preprocess, 20.5ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.6ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.8ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.9ms preprocess, 17.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.3ms preprocess, 19.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.4ms\n",
      "Speed: 1.4ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.3ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.6ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.2ms preprocess, 23.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.2ms preprocess, 18.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.2ms preprocess, 19.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.6ms\n",
      "Speed: 1.6ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.2ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.8ms preprocess, 18.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.9ms preprocess, 19.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.5ms preprocess, 19.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.9ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.1ms\n",
      "Speed: 1.5ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.5ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.4ms\n",
      "Speed: 1.9ms preprocess, 21.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.9ms preprocess, 19.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 5.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.9ms preprocess, 17.1ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.4ms\n",
      "Speed: 1.3ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.1ms\n",
      "Speed: 2.0ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.6ms preprocess, 18.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.1ms\n",
      "Speed: 1.2ms preprocess, 23.1ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 1.7ms preprocess, 21.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.3ms\n",
      "Speed: 1.7ms preprocess, 20.3ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.3ms\n",
      "Speed: 1.3ms preprocess, 20.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.5ms preprocess, 20.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.7ms\n",
      "Speed: 1.8ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.3ms preprocess, 20.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.7ms\n",
      "Speed: 1.7ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.3ms\n",
      "Speed: 2.5ms preprocess, 28.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.8ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.4ms preprocess, 16.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 26.2ms\n",
      "Speed: 2.1ms preprocess, 26.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.2ms preprocess, 21.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.5ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.9ms\n",
      "Speed: 2.2ms preprocess, 23.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.8ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.9ms\n",
      "Speed: 1.8ms preprocess, 19.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.1ms\n",
      "Speed: 1.3ms preprocess, 25.1ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.3ms preprocess, 18.4ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.3ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.5ms preprocess, 18.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.6ms\n",
      "Speed: 1.8ms preprocess, 19.6ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.7ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.5ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.8ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.8ms preprocess, 21.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.4ms\n",
      "Speed: 1.3ms preprocess, 19.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.8ms preprocess, 20.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.6ms preprocess, 21.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.5ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.5ms preprocess, 24.4ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.6ms\n",
      "Speed: 1.5ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.5ms preprocess, 18.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.3ms\n",
      "Speed: 2.1ms preprocess, 27.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.9ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.7ms\n",
      "Speed: 1.2ms preprocess, 26.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.4ms preprocess, 19.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.5ms\n",
      "Speed: 2.1ms preprocess, 23.5ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.5ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.4ms preprocess, 20.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.6ms preprocess, 17.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 2.5ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.3ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.2ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.8ms preprocess, 20.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.4ms preprocess, 18.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.6ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.6ms preprocess, 17.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 1.4ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 1.4ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.2ms\n",
      "Speed: 2.3ms preprocess, 23.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.1ms\n",
      "Speed: 1.6ms preprocess, 20.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.9ms\n",
      "Speed: 2.0ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.0ms\n",
      "Speed: 2.1ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.3ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.6ms\n",
      "Speed: 1.3ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.3ms\n",
      "Speed: 1.4ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 2.0ms preprocess, 22.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.8ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.9ms\n",
      "Speed: 2.2ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.8ms\n",
      "Speed: 2.0ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.5ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.8ms\n",
      "Speed: 2.0ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.0ms\n",
      "Speed: 1.8ms preprocess, 23.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 2.1ms preprocess, 22.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.9ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.5ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.4ms preprocess, 16.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.6ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.3ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.2ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.9ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.5ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.8ms preprocess, 21.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 2.0ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.7ms preprocess, 22.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.0ms\n",
      "Speed: 1.8ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.5ms\n",
      "Speed: 1.2ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.1ms\n",
      "Speed: 1.9ms preprocess, 22.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.1ms\n",
      "Speed: 1.2ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.6ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 1.3ms preprocess, 23.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.7ms\n",
      "Speed: 1.4ms preprocess, 16.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.9ms preprocess, 21.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 2.0ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.3ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.5ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.9ms\n",
      "Speed: 1.8ms preprocess, 21.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.9ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 2.0ms preprocess, 17.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.7ms\n",
      "Speed: 1.4ms preprocess, 19.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 2.1ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.6ms\n",
      "Speed: 1.2ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.3ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.4ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.9ms preprocess, 20.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.1ms\n",
      "Speed: 1.3ms preprocess, 18.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.2ms preprocess, 20.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.9ms\n",
      "Speed: 5.0ms preprocess, 22.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 2.0ms preprocess, 20.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.0ms\n",
      "Speed: 1.3ms preprocess, 23.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.1ms\n",
      "Speed: 3.6ms preprocess, 28.1ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.9ms\n",
      "Speed: 2.4ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.9ms\n",
      "Speed: 1.2ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.3ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.5ms\n",
      "Speed: 1.4ms preprocess, 18.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.6ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 1.8ms preprocess, 20.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.2ms preprocess, 22.1ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.0ms\n",
      "Speed: 1.8ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.2ms preprocess, 16.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.4ms preprocess, 18.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.2ms preprocess, 17.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.2ms\n",
      "Speed: 2.2ms preprocess, 24.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.3ms\n",
      "Speed: 2.0ms preprocess, 19.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.8ms\n",
      "Speed: 1.3ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.5ms\n",
      "Speed: 1.4ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.8ms\n",
      "Speed: 1.3ms preprocess, 18.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.2ms\n",
      "Speed: 1.5ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.8ms\n",
      "Speed: 1.4ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.9ms\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.7ms\n",
      "Speed: 1.4ms preprocess, 18.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.7ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.9ms\n",
      "Speed: 1.1ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.6ms\n",
      "Speed: 1.0ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.5ms\n",
      "Speed: 1.6ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.0ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.8ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.1ms\n",
      "Speed: 1.1ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.3ms\n",
      "Speed: 1.1ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.7ms\n",
      "Speed: 1.3ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.4ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.4ms\n",
      "Speed: 2.2ms preprocess, 27.4ms inference, 6.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.7ms\n",
      "Speed: 1.8ms preprocess, 19.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.0ms\n",
      "Speed: 1.2ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.9ms\n",
      "Speed: 1.6ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.3ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.6ms\n",
      "Speed: 1.8ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.1ms\n",
      "Speed: 1.4ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.3ms preprocess, 18.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.4ms\n",
      "Speed: 1.4ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 1.7ms preprocess, 19.1ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.9ms\n",
      "Speed: 1.5ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.5ms preprocess, 18.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.7ms\n",
      "Speed: 2.0ms preprocess, 19.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.5ms\n",
      "Speed: 1.5ms preprocess, 17.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.9ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.4ms\n",
      "Speed: 1.4ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.0ms\n",
      "Speed: 1.3ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.9ms\n",
      "Speed: 1.4ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.4ms\n",
      "Speed: 2.3ms preprocess, 22.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.2ms\n",
      "Speed: 1.6ms preprocess, 20.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.0ms\n",
      "Speed: 1.4ms preprocess, 20.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.0ms\n",
      "Speed: 1.7ms preprocess, 20.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.9ms\n",
      "Speed: 2.2ms preprocess, 20.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.6ms\n",
      "Speed: 1.4ms preprocess, 20.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.6ms preprocess, 21.1ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.2ms\n",
      "Speed: 1.4ms preprocess, 21.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.4ms\n",
      "Speed: 1.3ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 24.4ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.9ms\n",
      "Speed: 1.3ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 20.8ms\n",
      "Speed: 1.4ms preprocess, 20.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.6ms preprocess, 21.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.3ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 2.3ms preprocess, 21.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.9ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 2.2ms preprocess, 22.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.3ms preprocess, 20.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 1.8ms preprocess, 20.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.5ms preprocess, 20.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 1.4ms preprocess, 20.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.1ms\n",
      "Speed: 1.7ms preprocess, 21.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.3ms preprocess, 21.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.4ms preprocess, 21.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.4ms preprocess, 21.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.4ms\n",
      "Speed: 1.5ms preprocess, 20.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.0ms\n",
      "Speed: 1.7ms preprocess, 21.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 19.1ms\n",
      "Speed: 1.4ms preprocess, 19.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.6ms\n",
      "Speed: 1.4ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 18.8ms\n",
      "Speed: 1.8ms preprocess, 18.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 23.9ms\n",
      "Speed: 1.3ms preprocess, 23.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 1.3ms preprocess, 20.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.7ms\n",
      "Speed: 1.6ms preprocess, 20.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.9ms\n",
      "Speed: 2.4ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 2.3ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.2ms\n",
      "Speed: 1.3ms preprocess, 23.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.2ms\n",
      "Speed: 1.2ms preprocess, 20.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.0ms\n",
      "Speed: 1.4ms preprocess, 19.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.7ms preprocess, 19.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 1.9ms preprocess, 23.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.3ms\n",
      "Speed: 2.0ms preprocess, 20.3ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.6ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.4ms preprocess, 19.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.3ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.9ms\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 2.2ms preprocess, 22.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 1.3ms preprocess, 23.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.8ms\n",
      "Speed: 1.9ms preprocess, 22.8ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 1.4ms preprocess, 24.4ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 22.3ms\n",
      "Speed: 1.3ms preprocess, 22.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.7ms preprocess, 22.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.4ms preprocess, 22.1ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.7ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 2 Fall-Detecteds, 21.5ms\n",
      "Speed: 1.3ms preprocess, 21.5ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.1ms\n",
      "Speed: 2.2ms preprocess, 27.1ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.7ms preprocess, 21.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.4ms\n",
      "Speed: 1.8ms preprocess, 21.4ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.4ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.2ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.3ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.6ms\n",
      "Speed: 1.6ms preprocess, 20.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.4ms\n",
      "Speed: 1.3ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.5ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.3ms preprocess, 17.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.3ms preprocess, 20.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.6ms\n",
      "Speed: 1.5ms preprocess, 19.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.4ms\n",
      "Speed: 1.4ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.0ms\n",
      "Speed: 1.3ms preprocess, 17.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.1ms\n",
      "Speed: 2.4ms preprocess, 27.1ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.7ms\n",
      "Speed: 1.4ms preprocess, 21.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.3ms preprocess, 19.2ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.6ms\n",
      "Speed: 1.7ms preprocess, 21.6ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.2ms\n",
      "Speed: 1.4ms preprocess, 28.2ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.4ms\n",
      "Speed: 2.3ms preprocess, 24.4ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.2ms\n",
      "Speed: 2.2ms preprocess, 27.2ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.9ms\n",
      "Speed: 1.4ms preprocess, 25.9ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 25.0ms\n",
      "Speed: 2.4ms preprocess, 25.0ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.2ms\n",
      "Speed: 2.6ms preprocess, 27.2ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 27.7ms\n",
      "Speed: 2.4ms preprocess, 27.7ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.1ms\n",
      "Speed: 2.2ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 29.1ms\n",
      "Speed: 2.8ms preprocess, 29.1ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.5ms\n",
      "Speed: 1.3ms preprocess, 19.5ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.4ms\n",
      "Speed: 1.4ms preprocess, 20.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.6ms\n",
      "Speed: 1.4ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 24.9ms\n",
      "Speed: 1.3ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 21.2ms\n",
      "Speed: 1.6ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 19.9ms\n",
      "Speed: 1.5ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.8ms\n",
      "Speed: 1.4ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.2ms\n",
      "Speed: 1.4ms preprocess, 19.2ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.4ms\n",
      "Speed: 1.3ms preprocess, 19.4ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.7ms\n",
      "Speed: 1.6ms preprocess, 17.7ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 21.2ms\n",
      "Speed: 1.9ms preprocess, 21.2ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 20.1ms\n",
      "Speed: 1.9ms preprocess, 20.1ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 17.2ms\n",
      "Speed: 1.6ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 18.3ms\n",
      "Speed: 1.6ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 (no detections), 20.8ms\n",
      "Speed: 1.3ms preprocess, 20.8ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "📸 تم التقاط فريم من الكاميرا\n",
      "\n",
      "0: 320x416 1 Fall-Detected, 19.9ms\n",
      "Speed: 1.8ms preprocess, 19.9ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "✅ تنبؤ YOLO تم\n",
      "🖼️ عرض الصورة\n",
      "🛑 تم الضغط على Q - إغلاق\n"
     ]
    }
   ],
   "source": [
    "# 📦 استيراد المكتبات\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import winsound\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 📁 مسار مجلد الفريمات ومكان حفظ حالة الكشف\n",
    "FRAMES_DIR = \"input_frames\"\n",
    "STATE_FILE = \"detection_state.json\"\n",
    "\n",
    "# ✅ تحميل النموذج المدرب\n",
    "print(\"📦 تحميل النموذج\")\n",
    "model = YOLO(\"runs/detect/train_lowmem3/weights/best.pt\")\n",
    "print(\"✅ تم تحميل النموذج\")\n",
    "\n",
    "# 🎥 تشغيل الكاميرا\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_id = 0\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ فشل في تشغيل الكاميرا\")\n",
    "    exit()\n",
    "\n",
    "print(\"🎥 تشغيل الكاميرا\")\n",
    "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ فشل في التقاط فريم من الكاميرا\")\n",
    "        break\n",
    "\n",
    "    print(\"📸 تم التقاط فريم من الكاميرا\")\n",
    "\n",
    "    # 🔎 كشف العناصر باستخدام YOLO\n",
    "    results = model(frame)\n",
    "    print(\"✅ تنبؤ YOLO تم\")\n",
    "\n",
    "    # 🧠 تحليل النتائجq\n",
    "    sharp_detected = False\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = result.names[cls_id]\n",
    "\n",
    "            if cls_name.lower() in [\"knife\", \"scissors\", \"blade\"]:\n",
    "                print(f\"🔪 تم كشف أداة حادة: {cls_name}\")\n",
    "                sharp_detected = True\n",
    "                break\n",
    "\n",
    "    # 💾 حفظ الفريم\n",
    "    frame_filename = os.path.join(FRAMES_DIR, f\"frame_{frame_id:05d}.jpg\")\n",
    "    cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    # 📝 تحديث ملف الحالة\n",
    "    with open(STATE_FILE, 'w') as f:\n",
    "        json.dump({\"frame\": frame_filename, \"sharp\": sharp_detected}, f)\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "    # عرض الصورة (اختياري)\n",
    "    cv2.imshow(\"YOLO Live Detection\", frame)\n",
    "    print(\"🖼️ عرض الصورة\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"🛑 تم الضغط على Q - إغلاق\")\n",
    "        break\n",
    "\n",
    "# ♻️ إغلاق كل شيء\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

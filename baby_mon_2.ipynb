{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92eec767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ø·ÙÙ„\n",
      "ğŸ¥ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m frame[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØªÙ…ÙŠÙŠØ²Ù‡Ø§\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, locations)\n\u001b[0;32m     42\u001b[0m child_detected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\baby_monitor_ai\\.venv\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\User\\baby_monitor_ai\\.venv\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø§Ù„Ø«Ø§Ù†ÙŠ: face_recognition Ù…Ù† Ø£Ø¬Ù„ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ Ø§Ù„Ø·ÙÙ„\n",
    "# Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ ØªØ´ØºÙŠÙ„Ù‡ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø¨Ø§ÙŠØ«ÙˆÙ† 3.10 ÙÙ‚Ø· (virtualenv)\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import winsound\n",
    "import json\n",
    "\n",
    "# Ù…Ø³Ø§Ø± ØµÙˆØ±Ø© ÙˆØ¬Ù‡ Ø§Ù„Ø·ÙÙ„\n",
    "known_image_path = \"child_photos/photo_3.jpg\"  # Ø¹Ø¯Ù„ÙŠ Ù…Ø³Ø§Ø± ØµÙˆØ±Ø© Ø§Ø¨Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø§Ø­Ù‚Ù‹Ø§\n",
    "\n",
    "print(\"ğŸ§’ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ø·ÙÙ„\")\n",
    "known_image = face_recognition.load_image_file(known_image_path)\n",
    "known_encodings = face_recognition.face_encodings(known_image)\n",
    "if not known_encodings:\n",
    "    print(\"âŒ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¬Ù‡ ÙÙŠ ØµÙˆØ±Ø© Ø§Ù„Ø·ÙÙ„!\")\n",
    "    exit()\n",
    "\n",
    "known_encoding = known_encodings[0]\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© ÙØ±ÙŠÙ…Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© (yolo ÙŠØ¶Ø¹Ù‡Ø§ ÙÙŠ input_frames)\n",
    "frames_dir = \"input_frames\"\n",
    "frame_files = sorted(os.listdir(frames_dir))\n",
    "\n",
    "print(\"ğŸ¥ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª\")\n",
    "\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(frames_dir, frame_file)\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is None:\n",
    "        print(f\"âŒ ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø©: {frame_path}\")\n",
    "        continue\n",
    "\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØªÙ…ÙŠÙŠØ²Ù‡Ø§\n",
    "    locations = face_recognition.face_locations(rgb_frame)\n",
    "    encodings = face_recognition.face_encodings(rgb_frame, locations)\n",
    "\n",
    "    child_detected = False\n",
    "    for encoding in encodings:\n",
    "        match = face_recognition.compare_faces([known_encoding], encoding, tolerance=0.45)[0]\n",
    "        if match:\n",
    "            child_detected = True\n",
    "            break\n",
    "\n",
    "    if child_detected:\n",
    "        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ù† JSON Ù„Ø±Ø¤ÙŠØ© Ù…Ø§Ø°Ø§ ÙŠÙƒØ´Ù YOLO\n",
    "        try:\n",
    "            with open(\"detection_state.json\", \"r\") as f:\n",
    "                state = json.load(f)\n",
    "                if state.get(\"sharp_object_detected\"):\n",
    "                    print(\"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø§Ù„Ø·ÙÙ„ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø£Ø¯Ø§Ø© Ø­Ø§Ø¯Ø©!\")\n",
    "                    winsound.Beep(1000, 500)\n",
    "        except Exception as e:\n",
    "            print(\"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© detection_state.json\", e)\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
